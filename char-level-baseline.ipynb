{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import torchvision as tv\n",
    "import jieba\n",
    "from gensim import models\n",
    "from gensim.models import Word2Vec\n",
    "import torchvision.transforms as transforms\n",
    "from torchvision.transforms import ToPILImage\n",
    "import torch\n",
    "show = ToPILImage() # 可以把Tensor转成Image，方便可视化\n",
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"\\ndata = pd.read_csv('../../data/df_sen_sub/train.csv')\\nlen(data['content_id'].unique()), len(list(data['content_id']))\\ncontent_ids = data['content_id'].unique()\\nsubjs = data['subject'].unique()\\ndf = {}\\ntext, subs, sentis = [], [], []\\nfor i in range(len(content_ids)):\\n    if i % 100 == 0:print(i)\\n    dd = data[data['content_id'] == content_ids[i]]\\n    text.append(dd.loc[dd.index.tolist()[0], 'content'])\\n    temp_subs, temp_senti = [], []\\n    for sub in subjs:\\n        temp_subs.append(sub)\\n        if len(dd[dd['subject'] == sub]) != 0:\\n            temp_senti.append(str(int(dd[dd['subject'] == sub]['sentiment_value'])))\\n        else:\\n            temp_senti.append('2')\\n    subs.append(','.join(temp_subs))\\n    sentis.append(','.join(temp_senti))\\ndf['content'] = text\\ndf['subjects'] = subs\\ndf['sentiments'] = sentis\\ndf = pd.DataFrame(df)\\ndf.to_csv('../../data/df_sen_sub/merge_train.csv', index = False)\\n#data = pd.read_csv('../../data/df_sen_sub/test_public.csv')\\n\""
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "'''\n",
    "data = pd.read_csv('../../data/df_sen_sub/train.csv')\n",
    "len(data['content_id'].unique()), len(list(data['content_id']))\n",
    "content_ids = data['content_id'].unique()\n",
    "subjs = data['subject'].unique()\n",
    "df = {}\n",
    "text, subs, sentis = [], [], []\n",
    "for i in range(len(content_ids)):\n",
    "    if i % 100 == 0:print(i)\n",
    "    dd = data[data['content_id'] == content_ids[i]]\n",
    "    text.append(dd.loc[dd.index.tolist()[0], 'content'])\n",
    "    temp_subs, temp_senti = [], []\n",
    "    for sub in subjs:\n",
    "        temp_subs.append(sub)\n",
    "        if len(dd[dd['subject'] == sub]) != 0:\n",
    "            temp_senti.append(str(int(dd[dd['subject'] == sub]['sentiment_value'])))\n",
    "        else:\n",
    "            temp_senti.append('2')\n",
    "    subs.append(','.join(temp_subs))\n",
    "    sentis.append(','.join(temp_senti))\n",
    "df['content'] = text\n",
    "df['subjects'] = subs\n",
    "df['sentiments'] = sentis\n",
    "df = pd.DataFrame(df)\n",
    "df.to_csv('../../data/df_sen_sub/merge_train.csv', index = False)\n",
    "#data = pd.read_csv('../../data/df_sen_sub/test_public.csv')\n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = pd.read_csv('../../data/df_sen_sub/merge_train.csv')\n",
    "data = data.fillna('')\n",
    "subs = list(data['subjects'])\n",
    "sentiments = list(data['sentiments'])\n",
    "content = list(data['content'])\n",
    "test_data = pd.read_csv('../../data/df_sen_sub/test_public.csv')\n",
    "test_data = test_data.fillna('')\n",
    "test_content = list(test_data['content'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('../../data/df_sen_sub/char_add_text.txt','w') as f:\n",
    "    f.write('\\n'.join(list(content) + list(test_content)  + list(subs)))\n",
    "# 迭代器，使用jieba将句子进行分词\n",
    "class Sentences(object):# 这个类可以根据实际情况重写，我已经将所有的文章进行分句，并整合到了一个文件里面\n",
    "    def __init__(self, dirname):\n",
    "        self.dirname = dirname # 句子所在文件，没句句子占一行\n",
    "        #jieba.load_userdict(\"wordBase.txt\") # 加载词库\n",
    "\n",
    "    def __iter__(self):\n",
    "        #for fname in os.listdir(self.dirname):\n",
    "        for line in open(self.dirname):\n",
    "                line = line.replace('\\n', '')\n",
    "                if line == '价格,配置,操控,舒适性,油耗,动力,内饰,安全性,空间,外观':\n",
    "                    yield line.split(',')\n",
    "                else:\n",
    "                    yield list(line)\n",
    "\n",
    "sentences = []\n",
    "def train_word2vec(folder_path, size=100):\n",
    "    global sentences\n",
    "    sentences = Sentences(folder_path) #生成分词后的句子，是一个二维数组\n",
    "\n",
    "    # size是词向量长度\n",
    "    # worker是线程数量，建议与物理线程数量一致\n",
    "    # min_count是指出现次数小于一定程度，就忽略，0表示不忽略\n",
    "    model = Word2Vec(sentences, size=size, workers=8, min_count=0)\n",
    "\n",
    "    # 训练结束就将模型保存起来\n",
    "    model.save(\"../../data/df_sen_sub/char_add_word2vec_model\")\n",
    "\n",
    "# 生成50维度的词向量模型\n",
    "train_word2vec(\"../../data/df_sen_sub/char_add_text.txt\",100)\n",
    "\n",
    "# 测试训练好的词向量模型，使用model[keyWord]即可获取keyword这个词的词向量\n",
    "model = Word2Vec.load(\"../../data/df_sen_sub/char_add_word2vec_model\")\n",
    "sentences = list(sentences)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/works/dl-tools/anaconda2/envs/yxvenv/lib/python3.6/site-packages/ipykernel/__main__.py:14: DeprecationWarning: Call to deprecated `__getitem__` (Method will be removed in 4.0.0, use self.wv.__getitem__() instead).\n",
      "/home/works/dl-tools/anaconda2/envs/yxvenv/lib/python3.6/site-packages/ipykernel/__main__.py:18: DeprecationWarning: Call to deprecated `__getitem__` (Method will be removed in 4.0.0, use self.wv.__getitem__() instead).\n",
      "/home/works/dl-tools/anaconda2/envs/yxvenv/lib/python3.6/site-packages/ipykernel/__main__.py:34: DeprecationWarning: Call to deprecated `__getitem__` (Method will be removed in 4.0.0, use self.wv.__getitem__() instead).\n",
      "/home/works/dl-tools/anaconda2/envs/yxvenv/lib/python3.6/site-packages/ipykernel/__main__.py:30: DeprecationWarning: Call to deprecated `__getitem__` (Method will be removed in 4.0.0, use self.wv.__getitem__() instead).\n",
      "/home/works/dl-tools/anaconda2/envs/yxvenv/lib/python3.6/site-packages/ipykernel/__main__.py:44: DeprecationWarning: Call to deprecated `__getitem__` (Method will be removed in 4.0.0, use self.wv.__getitem__() instead).\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(8290, 50, 100) (2364, 50, 100)\n"
     ]
    }
   ],
   "source": [
    "x_vecs = []\n",
    "x_test_vecs = []  \n",
    "ind = 0\n",
    "word2ind = {}\n",
    "pretrained = []\n",
    "senti_sen = []\n",
    "senti_test_sen = []\n",
    "for i in range(len(sentences) - len(content) + 1):\n",
    "    if i < len(content):\n",
    "        temp = []\n",
    "        t_s = []\n",
    "        for j in range(len(sentences[i])):\n",
    "            if sentences[i][j] not in word2ind:\n",
    "                pretrained.append(model[sentences[i][j]])\n",
    "                word2ind[sentences[i][j]] = ind\n",
    "                ind += 1\n",
    "            t_s.append(sentences[i][j])\n",
    "            temp.append(model[sentences[i][j]])\n",
    "        while len(temp) < 50:\n",
    "            temp.append([0.0] * 100)\n",
    "        if len(temp) > 50:\n",
    "            temp = temp[:50]\n",
    "        x_vecs.append(temp)\n",
    "        senti_sen.append(t_s[:50])\n",
    "    elif i != len(sentences) - len(content):\n",
    "        temp = []\n",
    "        t_s = []\n",
    "        for j in range(len(sentences[i])):\n",
    "            if sentences[i][j] not in word2ind:\n",
    "                pretrained.append(model[sentences[i][j]])\n",
    "                word2ind[sentences[i][j]] = ind\n",
    "                ind += 1\n",
    "            t_s.append(sentences[i][j])\n",
    "            temp.append(model[sentences[i][j]])\n",
    "        while len(temp) < 50:\n",
    "            temp.append([0.0] * 100)\n",
    "        if len(temp) > 50:\n",
    "            temp = temp[:50]\n",
    "        x_test_vecs.append(temp)\n",
    "        senti_test_sen.append(t_s[:50])  \n",
    "    else:\n",
    "        for j in range(len(sentences[i])):\n",
    "            if sentences[i][j] not in word2ind:\n",
    "                pretrained.append(model[sentences[i][j]])\n",
    "                word2ind[sentences[i][j]] = ind\n",
    "                ind += 1        \n",
    "x_vecs = np.array(x_vecs)\n",
    "x_test_vecs = np.array(x_test_vecs)\n",
    "print(x_vecs.shape, x_test_vecs.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(2875, 2865)"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(word2ind),word2ind['价格']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "#va, content_vecs, y\n",
    "pretrained.append([0.0] * 100)\n",
    "word2ind['null'] = 2875\n",
    "map_ = ['-1', '0', '1', '2']\n",
    "sub_set = {}\n",
    "for i in range(len(subs)):\n",
    "    subjs = subs[i].split(',')\n",
    "    sentis = sentiments[i].split(',')\n",
    "    for j in range(len(subjs)):\n",
    "        if subjs[j] not in sub_set:\n",
    "            sub_set[subjs[j]] = []\n",
    "        sub_set[subjs[j]].append(map_.index(sentis[j]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "pretrained = np.array(pretrained)\n",
    "han_x = []\n",
    "for i in range(len(senti_sen)):\n",
    "    temp = []\n",
    "    for j in range(len(senti_sen[i])):\n",
    "        temp.append(word2ind[senti_sen[i][j]])\n",
    "    while len(temp) < 50:\n",
    "        temp.append(2875)\n",
    "\n",
    "    temp = temp[:50]\n",
    "\n",
    "    han_x.append(temp)\n",
    "han_x = np.array(han_x)\n",
    "\n",
    "han_x_test = []\n",
    "for i in range(len(senti_test_sen)):\n",
    "    temp = []\n",
    "    for j in range(len(senti_test_sen[i])):\n",
    "        temp.append(word2ind[senti_test_sen[i][j]])\n",
    "    while len(temp) < 50:\n",
    "        temp.append(2875)\n",
    "\n",
    "    temp = temp[:50]\n",
    "\n",
    "    han_x_test.append(temp)\n",
    "han_x = np.array(han_x)\n",
    "han_x_test = np.array(han_x_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "'''\n",
    "class Net(nn.Module):\n",
    "    def __init__(self, pretrained, vocab_size):\n",
    "        super(Net, self).__init__()\n",
    "        self.bilstm = nn.LSTM(input_size = 100, hidden_size = 100, bidirectional = True) \n",
    "        #self.fc1   = nn.Linear(3750, 50) \n",
    "        #self.fc2   = nn.Linear(200, 50)\n",
    "        #self.fc3   = nn.Linear(200, 50)\n",
    "        #self.fc4   = nn.Linear(100, 3)\n",
    "        self.fctest   = nn.Linear(200, 3)\n",
    "        self.embeddings = nn.Embedding(vocab_size, 100)\n",
    "        pretrained_weight = np.array(pretrained)\n",
    "        self.embeddings.weight.data.copy_(torch.from_numpy(pretrained_weight))\n",
    "        \n",
    "    def forward(self, x, aspects): \n",
    "        x = self.embeddings(x)#batch,50,100\n",
    "        #va = self.embeddings(aspects[0])\n",
    "        #t_va = va.unsqueeze(0).expand(x.shape[0], x.shape[1], 100)\n",
    "        output, (hn, cn) =  self.bilstm(x.float())#batch,50,200\n",
    "        H, hN = output, output[:,-1,:]\n",
    "        #con = torch.cat((t_va, H), 2)\n",
    "        #t1 = F.max_pool2d(F.relu(con), (1, 4))\n",
    "        #con = t1.view(x.size()[0], -1)\n",
    "        #con = F.relu(self.fc1(con))\n",
    "        #alpha = con.unsqueeze(1)\n",
    "        #rr = torch.matmul(alpha,H).squeeze(1)\n",
    "        #yy = torch.cat((F.relu(self.fc2(rr)), F.relu(self.fc3(hN))), 1)\n",
    "        #x = self.fc4(yy)\n",
    "        x  = self.fctest(hN)\n",
    "        return x\n",
    "    \n",
    "\n",
    "net = Net(pretrained, len(pretrained))\n",
    "print(net)\n",
    "from torch import optim\n",
    "criterion = nn.CrossEntropyLoss() # 交叉熵损失函数\n",
    "optimizer = optim.SGD(net.parameters(), lr=0.005, momentum=0.9)\n",
    "'''\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "\n",
    "class Net(nn.Module):\n",
    "    def __init__(self, pretrained, vocab_size):\n",
    "        super(Net, self).__init__()\n",
    "        #self.rnn1 = nn.RNN(100, 100) \n",
    "        self.bilstm = nn.LSTM(input_size = 100, hidden_size = 100, bidirectional = True)\n",
    "        #self.fc1   = nn.Linear(1250, 120) \n",
    "        self.fch = nn.Linear(200, 100)\n",
    "        self.fcv = nn.Linear(100, 100)\n",
    "        self.fcw = nn.Linear(200, 1)\n",
    "        self.fcwp = nn.Linear(200,50)\n",
    "        self.fcwh = nn.Linear(200,50)\n",
    "        self.fc1   = nn.Linear(3750, 120) \n",
    "        self.fc2   = nn.Linear(120, 50)\n",
    "        self.fc3   = nn.Linear(50, 4)\n",
    "        self.embeddings = nn.Embedding(vocab_size, 100)\n",
    "        pretrained_weight = np.array(pretrained)\n",
    "        self.embeddings.weight.data.copy_(torch.from_numpy(pretrained_weight))\n",
    "        \n",
    "    def forward(self, x, aspects): \n",
    "        x = self.embeddings(x) #[4,50,100]\n",
    "        batch_size = x.shape[0]\n",
    "        N = x.shape[1]\n",
    "        output, (hn, cn) =  self.bilstm(x.float())  #[4,50,200]\n",
    "        hN = output[:,-1,:]\n",
    "        va = self.embeddings(aspects[0]) #[1, 100]\n",
    "        t_va = torch.matmul(torch.ones((x.shape[0],50, 1)), va)#[4, 50, 100]\n",
    "        t_va = t_va.reshape((-1, 100)) #[4*50, 100]\n",
    "        x = output.reshape((-1, 200)) #[4*50, 200]\n",
    "        x = torch.tanh(torch.cat((self.fch(x), self.fcv(t_va)), 1))\n",
    "        M = x.reshape((batch_size, N, -1)) #[4, 50, 200]\n",
    "        alpha = F.softmax(self.fcw(M)).reshape((batch_size, 1, -1))#[4,50]\n",
    "        rr = torch.matmul(alpha, output).reshape((batch_size, -1)) #[4, 200]\n",
    "        final = torch.tanh(self.fcwh(hN) + self.fcwp(rr))\n",
    "        x = self.fc3(final)   \n",
    "        return x\n",
    "    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Net(\n",
      "  (bilstm): LSTM(100, 100, bidirectional=True)\n",
      "  (fch): Linear(in_features=200, out_features=100, bias=True)\n",
      "  (fcv): Linear(in_features=100, out_features=100, bias=True)\n",
      "  (fcw): Linear(in_features=200, out_features=1, bias=True)\n",
      "  (fcwp): Linear(in_features=200, out_features=50, bias=True)\n",
      "  (fcwh): Linear(in_features=200, out_features=50, bias=True)\n",
      "  (fc1): Linear(in_features=3750, out_features=120, bias=True)\n",
      "  (fc2): Linear(in_features=120, out_features=50, bias=True)\n",
      "  (fc3): Linear(in_features=50, out_features=4, bias=True)\n",
      "  (embeddings): Embedding(2876, 100)\n",
      ")\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/works/dl-tools/anaconda2/envs/yxvenv/lib/python3.6/site-packages/ipykernel/__main__.py:73: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1,   200] loss: 0.337\n",
      "[1,   400] loss: 0.238\n",
      "[1,   600] loss: 0.185\n",
      "[1,   800] loss: 0.233\n",
      "[1,  1000] loss: 0.221\n",
      "[1,  1200] loss: 0.227\n",
      "[1,  1400] loss: 0.217\n",
      "[1,  1600] loss: 0.231\n",
      "[1,  1800] loss: 0.252\n",
      "[1,  2000] loss: 0.232\n",
      "-------------cur max is ::::----------96.0\n",
      "result of epoch 0accuracy is : 96 %\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/works/dl-tools/anaconda2/envs/yxvenv/lib/python3.6/site-packages/torch/serialization.py:241: UserWarning: Couldn't retrieve source code for container of type Net. It won't be checked for correctness upon loading.\n",
      "  \"type \" + obj.__name__ + \". It won't be checked \"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[2,   200] loss: 0.159\n",
      "[2,   400] loss: 0.175\n",
      "[2,   600] loss: 0.211\n",
      "[2,   800] loss: 0.192\n",
      "[2,  1000] loss: 0.223\n",
      "[2,  1200] loss: 0.225\n",
      "[2,  1400] loss: 0.204\n",
      "[2,  1600] loss: 0.171\n",
      "[2,  1800] loss: 0.222\n",
      "[2,  2000] loss: 0.186\n",
      "result of epoch 1accuracy is : 96 %\n",
      "[3,   200] loss: 0.191\n",
      "[3,   400] loss: 0.182\n",
      "[3,   600] loss: 0.198\n",
      "[3,   800] loss: 0.179\n",
      "[3,  1000] loss: 0.187\n",
      "[3,  1200] loss: 0.171\n",
      "[3,  1400] loss: 0.164\n",
      "[3,  1600] loss: 0.227\n",
      "[3,  1800] loss: 0.141\n",
      "[3,  2000] loss: 0.203\n",
      "result of epoch 2accuracy is : 96 %\n",
      "[4,   200] loss: 0.190\n",
      "[4,   400] loss: 0.191\n",
      "[4,   600] loss: 0.165\n",
      "[4,   800] loss: 0.177\n",
      "[4,  1000] loss: 0.148\n",
      "[4,  1200] loss: 0.163\n",
      "[4,  1400] loss: 0.180\n",
      "[4,  1600] loss: 0.180\n",
      "[4,  1800] loss: 0.229\n",
      "[4,  2000] loss: 0.153\n",
      "result of epoch 3accuracy is : 96 %\n",
      "[5,   200] loss: 0.144\n",
      "[5,   400] loss: 0.167\n",
      "[5,   600] loss: 0.177\n",
      "[5,   800] loss: 0.193\n",
      "[5,  1000] loss: 0.162\n",
      "[5,  1200] loss: 0.176\n",
      "[5,  1400] loss: 0.156\n",
      "[5,  1600] loss: 0.180\n",
      "[5,  1800] loss: 0.139\n",
      "[5,  2000] loss: 0.198\n",
      "result of epoch 4accuracy is : 96 %\n",
      "[6,   200] loss: 0.162\n",
      "[6,   400] loss: 0.175\n",
      "[6,   600] loss: 0.159\n",
      "[6,   800] loss: 0.176\n",
      "[6,  1000] loss: 0.172\n",
      "[6,  1200] loss: 0.190\n",
      "[6,  1400] loss: 0.167\n",
      "[6,  1600] loss: 0.148\n",
      "[6,  1800] loss: 0.137\n",
      "[6,  2000] loss: 0.153\n",
      "result of epoch 5accuracy is : 96 %\n",
      "[7,   200] loss: 0.155\n",
      "[7,   400] loss: 0.124\n",
      "[7,   600] loss: 0.172\n",
      "[7,   800] loss: 0.160\n",
      "[7,  1000] loss: 0.150\n",
      "[7,  1200] loss: 0.180\n",
      "[7,  1400] loss: 0.162\n",
      "[7,  1600] loss: 0.153\n",
      "[7,  1800] loss: 0.196\n",
      "[7,  2000] loss: 0.147\n",
      "result of epoch 6accuracy is : 96 %\n",
      "[8,   200] loss: 0.130\n",
      "[8,   400] loss: 0.163\n",
      "[8,   600] loss: 0.155\n",
      "[8,   800] loss: 0.188\n",
      "[8,  1000] loss: 0.149\n",
      "[8,  1200] loss: 0.122\n",
      "[8,  1400] loss: 0.159\n",
      "[8,  1600] loss: 0.156\n",
      "[8,  1800] loss: 0.160\n",
      "[8,  2000] loss: 0.181\n",
      "result of epoch 7accuracy is : 96 %\n",
      "[9,   200] loss: 0.155\n",
      "[9,   400] loss: 0.145\n",
      "[9,   600] loss: 0.152\n",
      "[9,   800] loss: 0.188\n",
      "[9,  1000] loss: 0.166\n",
      "[9,  1200] loss: 0.168\n",
      "[9,  1400] loss: 0.127\n",
      "[9,  1600] loss: 0.146\n",
      "[9,  1800] loss: 0.130\n",
      "[9,  2000] loss: 0.141\n",
      "result of epoch 8accuracy is : 96 %\n",
      "[10,   200] loss: 0.152\n",
      "[10,   400] loss: 0.132\n",
      "[10,   600] loss: 0.130\n",
      "[10,   800] loss: 0.160\n",
      "[10,  1000] loss: 0.136\n",
      "[10,  1200] loss: 0.123\n",
      "[10,  1400] loss: 0.156\n",
      "[10,  1600] loss: 0.134\n",
      "[10,  1800] loss: 0.162\n",
      "[10,  2000] loss: 0.153\n",
      "result of epoch 9accuracy is : 96 %\n",
      "[11,   200] loss: 0.157\n",
      "[11,   400] loss: 0.152\n",
      "[11,   600] loss: 0.130\n",
      "[11,   800] loss: 0.156\n",
      "[11,  1000] loss: 0.116\n",
      "[11,  1200] loss: 0.167\n",
      "[11,  1400] loss: 0.107\n",
      "[11,  1600] loss: 0.144\n",
      "[11,  1800] loss: 0.148\n",
      "[11,  2000] loss: 0.132\n",
      "result of epoch 10accuracy is : 96 %\n",
      "[12,   200] loss: 0.129\n",
      "[12,   400] loss: 0.164\n",
      "[12,   600] loss: 0.135\n",
      "[12,   800] loss: 0.156\n",
      "[12,  1000] loss: 0.132\n",
      "[12,  1200] loss: 0.111\n",
      "[12,  1400] loss: 0.151\n",
      "[12,  1600] loss: 0.124\n",
      "[12,  1800] loss: 0.110\n",
      "[12,  2000] loss: 0.144\n",
      "result of epoch 11accuracy is : 96 %\n",
      "[13,   200] loss: 0.139\n",
      "[13,   400] loss: 0.148\n",
      "[13,   600] loss: 0.138\n",
      "[13,   800] loss: 0.083\n",
      "[13,  1000] loss: 0.119\n",
      "[13,  1200] loss: 0.158\n",
      "[13,  1400] loss: 0.138\n",
      "[13,  1600] loss: 0.117\n",
      "[13,  1800] loss: 0.132\n",
      "[13,  2000] loss: 0.129\n",
      "result of epoch 12accuracy is : 96 %\n",
      "[14,   200] loss: 0.145\n",
      "[14,   400] loss: 0.114\n",
      "[14,   600] loss: 0.140\n",
      "[14,   800] loss: 0.129\n",
      "[14,  1000] loss: 0.145\n",
      "[14,  1200] loss: 0.130\n",
      "[14,  1400] loss: 0.118\n",
      "[14,  1600] loss: 0.116\n",
      "[14,  1800] loss: 0.077\n",
      "[14,  2000] loss: 0.158\n",
      "result of epoch 13accuracy is : 96 %\n",
      "[15,   200] loss: 0.091\n",
      "[15,   400] loss: 0.130\n",
      "[15,   600] loss: 0.103\n",
      "[15,   800] loss: 0.123\n",
      "[15,  1000] loss: 0.139\n",
      "[15,  1200] loss: 0.130\n",
      "[15,  1400] loss: 0.136\n",
      "[15,  1600] loss: 0.100\n",
      "[15,  1800] loss: 0.138\n",
      "[15,  2000] loss: 0.122\n",
      "result of epoch 14accuracy is : 95 %\n",
      "[16,   200] loss: 0.120\n",
      "[16,   400] loss: 0.109\n",
      "[16,   600] loss: 0.098\n",
      "[16,   800] loss: 0.130\n",
      "[16,  1000] loss: 0.134\n",
      "[16,  1200] loss: 0.115\n",
      "[16,  1400] loss: 0.115\n",
      "[16,  1600] loss: 0.134\n",
      "[16,  1800] loss: 0.118\n",
      "[16,  2000] loss: 0.113\n",
      "result of epoch 15accuracy is : 96 %\n",
      "[17,   200] loss: 0.095\n",
      "[17,   400] loss: 0.110\n",
      "[17,   600] loss: 0.103\n",
      "[17,   800] loss: 0.111\n",
      "[17,  1000] loss: 0.112\n",
      "[17,  1200] loss: 0.129\n",
      "[17,  1400] loss: 0.115\n",
      "[17,  1600] loss: 0.110\n",
      "[17,  1800] loss: 0.124\n",
      "[17,  2000] loss: 0.129\n",
      "result of epoch 16accuracy is : 96 %\n",
      "[18,   200] loss: 0.095\n",
      "[18,   400] loss: 0.121\n",
      "[18,   600] loss: 0.089\n",
      "[18,   800] loss: 0.117\n",
      "[18,  1000] loss: 0.092\n",
      "[18,  1200] loss: 0.117\n",
      "[18,  1400] loss: 0.091\n",
      "[18,  1600] loss: 0.112\n",
      "[18,  1800] loss: 0.141\n",
      "[18,  2000] loss: 0.095\n",
      "result of epoch 17accuracy is : 93 %\n",
      "[19,   200] loss: 0.115\n",
      "[19,   400] loss: 0.124\n",
      "[19,   600] loss: 0.107\n",
      "[19,   800] loss: 0.113\n",
      "[19,  1000] loss: 0.097\n",
      "[19,  1200] loss: 0.107\n",
      "[19,  1400] loss: 0.096\n",
      "[19,  1600] loss: 0.100\n",
      "[19,  1800] loss: 0.099\n",
      "[19,  2000] loss: 0.111\n",
      "result of epoch 18accuracy is : 96 %\n",
      "[20,   200] loss: 0.101\n",
      "[20,   400] loss: 0.106\n",
      "[20,   600] loss: 0.092\n",
      "[20,   800] loss: 0.092\n",
      "[20,  1000] loss: 0.104\n",
      "[20,  1200] loss: 0.102\n",
      "[20,  1400] loss: 0.115\n",
      "[20,  1600] loss: 0.083\n",
      "[20,  1800] loss: 0.105\n",
      "[20,  2000] loss: 0.116\n",
      "result of epoch 19accuracy is : 95 %\n",
      "key价格\n",
      "Finished Training\n",
      "Net(\n",
      "  (bilstm): LSTM(100, 100, bidirectional=True)\n",
      "  (fch): Linear(in_features=200, out_features=100, bias=True)\n",
      "  (fcv): Linear(in_features=100, out_features=100, bias=True)\n",
      "  (fcw): Linear(in_features=200, out_features=1, bias=True)\n",
      "  (fcwp): Linear(in_features=200, out_features=50, bias=True)\n",
      "  (fcwh): Linear(in_features=200, out_features=50, bias=True)\n",
      "  (fc1): Linear(in_features=3750, out_features=120, bias=True)\n",
      "  (fc2): Linear(in_features=120, out_features=50, bias=True)\n",
      "  (fc3): Linear(in_features=50, out_features=4, bias=True)\n",
      "  (embeddings): Embedding(2876, 100)\n",
      ")\n",
      "[1,   200] loss: 0.372\n",
      "[1,   400] loss: 0.283\n",
      "[1,   600] loss: 0.243\n",
      "[1,   800] loss: 0.210\n",
      "[1,  1000] loss: 0.269\n",
      "[1,  1200] loss: 0.222\n",
      "[1,  1400] loss: 0.231\n",
      "[1,  1600] loss: 0.244\n",
      "[1,  1800] loss: 0.256\n",
      "[1,  2000] loss: 0.230\n",
      "-------------cur max is ::::----------90.0\n",
      "result of epoch 0accuracy is : 90 %\n",
      "[2,   200] loss: 0.201\n",
      "[2,   400] loss: 0.218\n",
      "[2,   600] loss: 0.209\n",
      "[2,   800] loss: 0.241\n",
      "[2,  1000] loss: 0.191\n",
      "[2,  1200] loss: 0.208\n",
      "[2,  1400] loss: 0.203\n",
      "[2,  1600] loss: 0.204\n",
      "[2,  1800] loss: 0.210\n",
      "[2,  2000] loss: 0.226\n",
      "-------------cur max is ::::----------91.0\n",
      "result of epoch 1accuracy is : 91 %\n",
      "[3,   200] loss: 0.181\n",
      "[3,   400] loss: 0.186\n",
      "[3,   600] loss: 0.197\n",
      "[3,   800] loss: 0.220\n",
      "[3,  1000] loss: 0.206\n",
      "[3,  1200] loss: 0.186\n",
      "[3,  1400] loss: 0.150\n",
      "[3,  1600] loss: 0.209\n",
      "[3,  1800] loss: 0.181\n",
      "[3,  2000] loss: 0.223\n",
      "result of epoch 2accuracy is : 91 %\n",
      "[4,   200] loss: 0.180\n",
      "[4,   400] loss: 0.202\n",
      "[4,   600] loss: 0.157\n",
      "[4,   800] loss: 0.156\n",
      "[4,  1000] loss: 0.193\n",
      "[4,  1200] loss: 0.186\n",
      "[4,  1400] loss: 0.234\n",
      "[4,  1600] loss: 0.176\n",
      "[4,  1800] loss: 0.171\n",
      "[4,  2000] loss: 0.135\n",
      "result of epoch 3accuracy is : 91 %\n",
      "[5,   200] loss: 0.194\n",
      "[5,   400] loss: 0.202\n",
      "[5,   600] loss: 0.173\n",
      "[5,   800] loss: 0.126\n",
      "[5,  1000] loss: 0.148\n",
      "[5,  1200] loss: 0.170\n",
      "[5,  1400] loss: 0.183\n",
      "[5,  1600] loss: 0.162\n",
      "[5,  1800] loss: 0.176\n",
      "[5,  2000] loss: 0.201\n",
      "result of epoch 4accuracy is : 91 %\n",
      "[6,   200] loss: 0.145\n",
      "[6,   400] loss: 0.165\n",
      "[6,   600] loss: 0.171\n",
      "[6,   800] loss: 0.141\n",
      "[6,  1000] loss: 0.165\n",
      "[6,  1200] loss: 0.136\n",
      "[6,  1400] loss: 0.189\n",
      "[6,  1600] loss: 0.184\n",
      "[6,  1800] loss: 0.139\n",
      "[6,  2000] loss: 0.177\n",
      "result of epoch 5accuracy is : 91 %\n",
      "[7,   200] loss: 0.155\n",
      "[7,   400] loss: 0.191\n",
      "[7,   600] loss: 0.200\n",
      "[7,   800] loss: 0.129\n",
      "[7,  1000] loss: 0.163\n",
      "[7,  1200] loss: 0.144\n",
      "[7,  1400] loss: 0.171\n",
      "[7,  1600] loss: 0.134\n",
      "[7,  1800] loss: 0.131\n",
      "[7,  2000] loss: 0.133\n",
      "result of epoch 6accuracy is : 91 %\n",
      "[8,   200] loss: 0.169\n",
      "[8,   400] loss: 0.136\n",
      "[8,   600] loss: 0.172\n",
      "[8,   800] loss: 0.134\n",
      "[8,  1000] loss: 0.146\n",
      "[8,  1200] loss: 0.124\n",
      "[8,  1400] loss: 0.158\n",
      "[8,  1600] loss: 0.163\n",
      "[8,  1800] loss: 0.150\n",
      "[8,  2000] loss: 0.135\n",
      "result of epoch 7accuracy is : 91 %\n",
      "[9,   200] loss: 0.155\n",
      "[9,   400] loss: 0.130\n",
      "[9,   600] loss: 0.110\n",
      "[9,   800] loss: 0.102\n",
      "[9,  1000] loss: 0.151\n",
      "[9,  1200] loss: 0.131\n",
      "[9,  1400] loss: 0.128\n",
      "[9,  1600] loss: 0.167\n",
      "[9,  1800] loss: 0.157\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[9,  2000] loss: 0.163\n",
      "result of epoch 8accuracy is : 91 %\n",
      "[10,   200] loss: 0.136\n",
      "[10,   400] loss: 0.122\n",
      "[10,   600] loss: 0.132\n",
      "[10,   800] loss: 0.130\n",
      "[10,  1000] loss: 0.143\n",
      "[10,  1200] loss: 0.125\n",
      "[10,  1400] loss: 0.155\n",
      "[10,  1600] loss: 0.151\n",
      "[10,  1800] loss: 0.153\n",
      "[10,  2000] loss: 0.120\n",
      "result of epoch 9accuracy is : 91 %\n",
      "[11,   200] loss: 0.143\n",
      "[11,   400] loss: 0.129\n",
      "[11,   600] loss: 0.134\n",
      "[11,   800] loss: 0.168\n",
      "[11,  1000] loss: 0.097\n",
      "[11,  1200] loss: 0.135\n",
      "[11,  1400] loss: 0.136\n",
      "[11,  1600] loss: 0.133\n",
      "[11,  1800] loss: 0.108\n",
      "[11,  2000] loss: 0.120\n",
      "result of epoch 10accuracy is : 91 %\n",
      "[12,   200] loss: 0.132\n",
      "[12,   400] loss: 0.103\n",
      "[12,   600] loss: 0.122\n",
      "[12,   800] loss: 0.103\n",
      "[12,  1000] loss: 0.116\n",
      "[12,  1200] loss: 0.122\n",
      "[12,  1400] loss: 0.135\n",
      "[12,  1600] loss: 0.127\n",
      "[12,  1800] loss: 0.128\n",
      "[12,  2000] loss: 0.168\n",
      "result of epoch 11accuracy is : 91 %\n",
      "[13,   200] loss: 0.107\n",
      "[13,   400] loss: 0.105\n",
      "[13,   600] loss: 0.101\n",
      "[13,   800] loss: 0.133\n",
      "[13,  1000] loss: 0.116\n",
      "[13,  1200] loss: 0.159\n",
      "[13,  1400] loss: 0.116\n",
      "[13,  1600] loss: 0.101\n",
      "[13,  1800] loss: 0.115\n",
      "[13,  2000] loss: 0.120\n",
      "result of epoch 12accuracy is : 91 %\n",
      "[14,   200] loss: 0.111\n",
      "[14,   400] loss: 0.114\n",
      "[14,   600] loss: 0.113\n",
      "[18,   600] loss: 0.122\n",
      "[18,   800] loss: 0.083\n",
      "[18,  1000] loss: 0.102\n",
      "[18,  1200] loss: 0.096\n",
      "[18,  1400] loss: 0.089\n",
      "[18,  1600] loss: 0.081\n",
      "[18,  1800] loss: 0.098\n",
      "[18,  2000] loss: 0.086\n",
      "result of epoch 17accuracy is : 91 %\n",
      "[19,   200] loss: 0.091\n",
      "[19,   400] loss: 0.113\n",
      "[19,   600] loss: 0.100\n",
      "[19,   800] loss: 0.090\n",
      "[19,  1000] loss: 0.084\n",
      "[19,  1200] loss: 0.105\n",
      "[19,  1400] loss: 0.073\n",
      "[19,  1600] loss: 0.093\n",
      "[19,  1800] loss: 0.103\n",
      "[19,  2000] loss: 0.097\n",
      "result of epoch 18accuracy is : 91 %\n",
      "[20,   200] loss: 0.073\n",
      "[20,   400] loss: 0.101\n",
      "[20,   600] loss: 0.073\n",
      "[20,   800] loss: 0.101\n",
      "[20,  1000] loss: 0.101\n",
      "[20,  1200] loss: 0.110\n",
      "[20,  1400] loss: 0.067\n",
      "[20,  1600] loss: 0.068\n",
      "[20,  1800] loss: 0.130\n",
      "[20,  2000] loss: 0.082\n",
      "result of epoch 19accuracy is : 91 %\n",
      "key配置\n",
      "Finished Training\n",
      "Net(\n",
      "  (bilstm): LSTM(100, 100, bidirectional=True)\n",
      "  (fch): Linear(in_features=200, out_features=100, bias=True)\n",
      "  (fcv): Linear(in_features=100, out_features=100, bias=True)\n",
      "  (fcw): Linear(in_features=200, out_features=1, bias=True)\n",
      "  (fcwp): Linear(in_features=200, out_features=50, bias=True)\n",
      "  (fcwh): Linear(in_features=200, out_features=50, bias=True)\n",
      "  (fc1): Linear(in_features=3750, out_features=120, bias=True)\n",
      "  (fc2): Linear(in_features=120, out_features=50, bias=True)\n",
      "  (fc3): Linear(in_features=50, out_features=4, bias=True)\n",
      "  (embeddings): Embedding(2876, 100)\n",
      ")\n",
      "[1,   200] loss: 0.441\n",
      "[1,   400] loss: 0.344\n",
      "[1,   600] loss: 0.301\n",
      "[1,   800] loss: 0.269\n",
      "[1,  1000] loss: 0.315\n",
      "[1,  1200] loss: 0.307\n",
      "[1,  1400] loss: 0.309\n",
      "[1,  1600] loss: 0.296\n",
      "[1,  1800] loss: 0.282\n",
      "[1,  2000] loss: 0.261\n",
      "-------------cur max is ::::----------89.0\n",
      "result of epoch 0accuracy is : 89 %\n",
      "[2,   200] loss: 0.270\n",
      "[2,   400] loss: 0.234\n",
      "[2,   600] loss: 0.279\n",
      "[2,   800] loss: 0.283\n",
      "[2,  1000] loss: 0.266\n",
      "[2,  1200] loss: 0.247\n",
      "[2,  1400] loss: 0.264\n",
      "[2,  1600] loss: 0.264\n",
      "[2,  1800] loss: 0.278\n",
      "[2,  2000] loss: 0.289\n",
      "result of epoch 1accuracy is : 87 %\n",
      "[3,   200] loss: 0.265\n",
      "[3,   400] loss: 0.245\n",
      "[3,   600] loss: 0.276\n",
      "[3,   800] loss: 0.248\n",
      "[3,  1000] loss: 0.265\n",
      "[3,  1200] loss: 0.298\n",
      "[3,  1400] loss: 0.260\n",
      "[3,  1600] loss: 0.255\n",
      "[3,  1800] loss: 0.216\n",
      "[3,  2000] loss: 0.274\n",
      "result of epoch 2accuracy is : 89 %\n",
      "[4,   200] loss: 0.270\n",
      "[4,   400] loss: 0.262\n",
      "[4,   600] loss: 0.201\n",
      "[4,   800] loss: 0.231\n",
      "[4,  1000] loss: 0.252\n",
      "[4,  1200] loss: 0.256\n",
      "[4,  1400] loss: 0.254\n",
      "[4,  1600] loss: 0.250\n",
      "[4,  1800] loss: 0.238\n",
      "[4,  2000] loss: 0.284\n",
      "result of epoch 3accuracy is : 86 %\n",
      "[5,   200] loss: 0.217\n",
      "[5,   400] loss: 0.239\n",
      "[5,   600] loss: 0.203\n",
      "[5,   800] loss: 0.265\n",
      "[5,  1000] loss: 0.229\n",
      "[5,  1200] loss: 0.268\n",
      "[5,  1400] loss: 0.263\n",
      "[5,  1600] loss: 0.248\n",
      "[5,  1800] loss: 0.252\n",
      "[5,  2000] loss: 0.233\n",
      "result of epoch 4accuracy is : 89 %\n",
      "[6,   200] loss: 0.256\n",
      "[6,   400] loss: 0.202\n",
      "[6,   600] loss: 0.256\n",
      "[6,   800] loss: 0.227\n",
      "[6,  1000] loss: 0.278\n",
      "[6,  1200] loss: 0.261\n",
      "[6,  1400] loss: 0.207\n",
      "[6,  1600] loss: 0.225\n",
      "[6,  1800] loss: 0.236\n",
      "[6,  2000] loss: 0.224\n",
      "result of epoch 5accuracy is : 89 %\n",
      "[7,   200] loss: 0.244\n",
      "[7,   400] loss: 0.261\n",
      "[7,   600] loss: 0.216\n",
      "[7,   800] loss: 0.209\n",
      "[7,  1000] loss: 0.222\n",
      "[7,  1200] loss: 0.189\n",
      "[7,  1400] loss: 0.243\n",
      "[7,  1600] loss: 0.263\n",
      "[7,  1800] loss: 0.207\n",
      "[7,  2000] loss: 0.255\n",
      "result of epoch 6accuracy is : 89 %\n",
      "[8,   200] loss: 0.250\n",
      "[8,   400] loss: 0.215\n",
      "[8,   600] loss: 0.223\n",
      "[8,   800] loss: 0.221\n",
      "[8,  1000] loss: 0.231\n",
      "[8,  1200] loss: 0.201\n",
      "[8,  1400] loss: 0.250\n",
      "[8,  1600] loss: 0.240\n",
      "[8,  1800] loss: 0.216\n",
      "[8,  2000] loss: 0.211\n",
      "result of epoch 7accuracy is : 87 %\n",
      "[9,   200] loss: 0.223\n",
      "[9,   400] loss: 0.243\n",
      "[9,   600] loss: 0.237\n",
      "[9,   800] loss: 0.210\n",
      "[9,  1000] loss: 0.191\n",
      "[9,  1200] loss: 0.261\n",
      "[9,  1400] loss: 0.200\n",
      "[9,  1600] loss: 0.183\n",
      "[9,  1800] loss: 0.202\n",
      "[9,  2000] loss: 0.218\n",
      "result of epoch 8accuracy is : 89 %\n",
      "[10,   200] loss: 0.230\n",
      "[10,   400] loss: 0.230\n",
      "[10,   600] loss: 0.215\n",
      "[10,   800] loss: 0.213\n",
      "[10,  1000] loss: 0.199\n",
      "[10,  1200] loss: 0.212\n",
      "[10,  1400] loss: 0.189\n",
      "[10,  1600] loss: 0.202\n",
      "[10,  1800] loss: 0.207\n",
      "[10,  2000] loss: 0.201\n",
      "result of epoch 9accuracy is : 89 %\n",
      "[11,   200] loss: 0.189\n",
      "[11,   400] loss: 0.189\n",
      "[11,   600] loss: 0.185\n",
      "[11,   800] loss: 0.183\n",
      "[11,  1000] loss: 0.229\n",
      "[11,  1200] loss: 0.184\n",
      "[11,  1400] loss: 0.197\n",
      "[11,  1600] loss: 0.226\n",
      "[11,  1800] loss: 0.228\n",
      "[11,  2000] loss: 0.219\n",
      "result of epoch 10accuracy is : 87 %\n",
      "[12,   200] loss: 0.185\n",
      "[12,   400] loss: 0.201\n",
      "[12,   600] loss: 0.199\n",
      "[12,   800] loss: 0.215\n",
      "[12,  1000] loss: 0.198\n",
      "[12,  1200] loss: 0.193\n",
      "[12,  1400] loss: 0.195\n",
      "[12,  1600] loss: 0.162\n",
      "[12,  1800] loss: 0.226\n",
      "[12,  2000] loss: 0.233\n",
      "result of epoch 11accuracy is : 87 %\n",
      "[13,   200] loss: 0.166\n",
      "[13,   400] loss: 0.201\n",
      "[13,   600] loss: 0.170\n",
      "[13,   800] loss: 0.204\n",
      "[13,  1000] loss: 0.196\n",
      "[13,  1200] loss: 0.189\n",
      "[13,  1400] loss: 0.202\n",
      "[13,  1600] loss: 0.214\n",
      "[13,  1800] loss: 0.180\n",
      "[13,  2000] loss: 0.187\n",
      "result of epoch 12accuracy is : 87 %\n",
      "[14,   200] loss: 0.181\n",
      "[14,   400] loss: 0.196\n",
      "[14,   600] loss: 0.169\n",
      "[14,   800] loss: 0.182\n",
      "[14,  1000] loss: 0.186\n",
      "[14,  1200] loss: 0.212\n",
      "[14,  1400] loss: 0.203\n",
      "[14,  1600] loss: 0.192\n",
      "[14,  1800] loss: 0.176\n",
      "[14,  2000] loss: 0.174\n",
      "result of epoch 13accuracy is : 89 %\n",
      "[15,   200] loss: 0.180\n",
      "[15,   400] loss: 0.194\n",
      "[15,   600] loss: 0.161\n",
      "[15,   800] loss: 0.162\n",
      "[15,  1000] loss: 0.165\n",
      "[15,  1200] loss: 0.174\n",
      "[15,  1400] loss: 0.189\n",
      "[15,  1600] loss: 0.194\n",
      "[15,  1800] loss: 0.178\n",
      "[15,  2000] loss: 0.189\n",
      "result of epoch 14accuracy is : 86 %\n",
      "[16,   200] loss: 0.176\n",
      "[16,   400] loss: 0.207\n",
      "[16,   600] loss: 0.192\n",
      "[16,   800] loss: 0.139\n",
      "[16,  1000] loss: 0.148\n",
      "[16,  1200] loss: 0.185\n",
      "[16,  1400] loss: 0.177\n",
      "[16,  1600] loss: 0.170\n",
      "[16,  1800] loss: 0.160\n",
      "[16,  2000] loss: 0.199\n",
      "result of epoch 15accuracy is : 89 %\n",
      "[17,   200] loss: 0.179\n",
      "[17,   400] loss: 0.131\n",
      "[17,   600] loss: 0.152\n",
      "[17,   800] loss: 0.200\n",
      "[17,  1000] loss: 0.184\n",
      "[17,  1200] loss: 0.161\n",
      "[17,  1400] loss: 0.191\n",
      "[17,  1600] loss: 0.140\n",
      "[17,  1800] loss: 0.176\n",
      "[17,  2000] loss: 0.150\n",
      "result of epoch 16accuracy is : 87 %\n",
      "[18,   200] loss: 0.163\n",
      "[18,   400] loss: 0.173\n",
      "[18,   600] loss: 0.173\n",
      "[18,   800] loss: 0.159\n",
      "[18,  1000] loss: 0.162\n",
      "[18,  1200] loss: 0.162\n",
      "[18,  1400] loss: 0.163\n",
      "[18,  1600] loss: 0.127\n",
      "[18,  1800] loss: 0.167\n",
      "[18,  2000] loss: 0.159\n",
      "result of epoch 17accuracy is : 86 %\n",
      "[19,   200] loss: 0.167\n",
      "[19,   400] loss: 0.174\n",
      "[19,   600] loss: 0.147\n",
      "[19,   800] loss: 0.135\n",
      "[19,  1000] loss: 0.125\n",
      "[19,  1200] loss: 0.166\n",
      "[19,  1400] loss: 0.178\n",
      "[19,  1600] loss: 0.136\n",
      "[19,  1800] loss: 0.151\n",
      "[19,  2000] loss: 0.175\n",
      "result of epoch 18accuracy is : 87 %\n",
      "[20,   200] loss: 0.162\n",
      "[20,   400] loss: 0.136\n",
      "[20,   600] loss: 0.148\n",
      "[20,   800] loss: 0.147\n",
      "[20,  1000] loss: 0.189\n",
      "[20,  1200] loss: 0.155\n",
      "[20,  1400] loss: 0.154\n",
      "[20,  1600] loss: 0.142\n",
      "[20,  1800] loss: 0.159\n",
      "[20,  2000] loss: 0.124\n",
      "result of epoch 19accuracy is : 87 %\n",
      "key操控\n",
      "Finished Training\n",
      "Net(\n",
      "  (bilstm): LSTM(100, 100, bidirectional=True)\n",
      "  (fch): Linear(in_features=200, out_features=100, bias=True)\n",
      "  (fcv): Linear(in_features=100, out_features=100, bias=True)\n",
      "  (fcw): Linear(in_features=200, out_features=1, bias=True)\n",
      "  (fcwp): Linear(in_features=200, out_features=50, bias=True)\n",
      "  (fcwh): Linear(in_features=200, out_features=50, bias=True)\n",
      "  (fc1): Linear(in_features=3750, out_features=120, bias=True)\n",
      "  (fc2): Linear(in_features=120, out_features=50, bias=True)\n",
      "  (fc3): Linear(in_features=50, out_features=4, bias=True)\n",
      "  (embeddings): Embedding(2876, 100)\n",
      ")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1,   200] loss: 0.425\n",
      "[1,   400] loss: 0.293\n",
      "[1,   600] loss: 0.287\n",
      "[1,   800] loss: 0.279\n",
      "[1,  1000] loss: 0.303\n",
      "[1,  1200] loss: 0.324\n",
      "[1,  1400] loss: 0.318\n",
      "[1,  1600] loss: 0.294\n",
      "[1,  1800] loss: 0.273\n",
      "[1,  2000] loss: 0.309\n",
      "-------------cur max is ::::----------87.0\n",
      "result of epoch 0accuracy is : 87 %\n",
      "[2,   200] loss: 0.300\n",
      "[2,   400] loss: 0.236\n",
      "[2,   600] loss: 0.281\n",
      "[2,   800] loss: 0.260\n",
      "[2,  1000] loss: 0.250\n",
      "[2,  1200] loss: 0.244\n",
      "[2,  1400] loss: 0.277\n",
      "[2,  1600] loss: 0.236\n",
      "[2,  1800] loss: 0.243\n",
      "[2,  2000] loss: 0.294\n",
      "-------------cur max is ::::----------90.0\n",
      "result of epoch 1accuracy is : 90 %\n",
      "[3,   200] loss: 0.235\n",
      "[3,   400] loss: 0.292\n",
      "[3,   600] loss: 0.250\n",
      "[3,   800] loss: 0.243\n",
      "[3,  1000] loss: 0.265\n",
      "[3,  1200] loss: 0.291\n",
      "[3,  1400] loss: 0.255\n",
      "[3,  1600] loss: 0.214\n",
      "[3,  1800] loss: 0.227\n",
      "[3,  2000] loss: 0.175\n",
      "result of epoch 2accuracy is : 90 %\n",
      "[4,   200] loss: 0.264\n",
      "[4,   400] loss: 0.219\n",
      "[4,   600] loss: 0.245\n",
      "[4,   800] loss: 0.227\n",
      "[4,  1000] loss: 0.268\n",
      "[4,  1200] loss: 0.251\n",
      "[4,  1400] loss: 0.210\n",
      "[4,  1600] loss: 0.234\n",
      "[4,  1800] loss: 0.234\n",
      "[4,  2000] loss: 0.219\n",
      "-------------cur max is ::::----------91.0\n",
      "result of epoch 3accuracy is : 91 %\n",
      "[5,   200] loss: 0.230\n",
      "[5,   400] loss: 0.199\n",
      "[5,   600] loss: 0.217\n",
      "[5,   800] loss: 0.234\n",
      "[5,  1000] loss: 0.255\n",
      "[5,  1200] loss: 0.229\n",
      "[5,  1400] loss: 0.217\n",
      "[5,  1600] loss: 0.229\n",
      "[5,  1800] loss: 0.237\n",
      "[5,  2000] loss: 0.226\n",
      "result of epoch 4accuracy is : 89 %\n",
      "[6,   200] loss: 0.207\n",
      "[6,   400] loss: 0.251\n",
      "[6,   600] loss: 0.220\n",
      "[6,   800] loss: 0.200\n",
      "[6,  1000] loss: 0.194\n",
      "[6,  1200] loss: 0.234\n",
      "[6,  1400] loss: 0.235\n",
      "[6,  1600] loss: 0.204\n",
      "[6,  1800] loss: 0.237\n",
      "[6,  2000] loss: 0.209\n",
      "result of epoch 5accuracy is : 90 %\n",
      "[7,   200] loss: 0.226\n",
      "[7,   400] loss: 0.209\n",
      "[7,   600] loss: 0.228\n",
      "[7,   800] loss: 0.181\n",
      "[7,  1000] loss: 0.197\n",
      "[7,  1200] loss: 0.224\n",
      "[7,  1400] loss: 0.181\n",
      "[7,  1600] loss: 0.180\n",
      "[7,  1800] loss: 0.234\n",
      "[7,  2000] loss: 0.219\n",
      "result of epoch 6accuracy is : 90 %\n",
      "[8,   200] loss: 0.204\n",
      "[8,   400] loss: 0.225\n",
      "[8,   600] loss: 0.211\n",
      "[8,   800] loss: 0.197\n",
      "[8,  1000] loss: 0.158\n",
      "[8,  1200] loss: 0.214\n",
      "[8,  1400] loss: 0.173\n",
      "[8,  1600] loss: 0.191\n",
      "[8,  1800] loss: 0.181\n",
      "[8,  2000] loss: 0.230\n",
      "-------------cur max is ::::----------92.0\n",
      "result of epoch 7accuracy is : 92 %\n",
      "[9,   200] loss: 0.176\n",
      "[9,   400] loss: 0.214\n",
      "[9,   600] loss: 0.187\n",
      "[9,   800] loss: 0.184\n",
      "[9,  1000] loss: 0.182\n",
      "[9,  1200] loss: 0.180\n",
      "[9,  1400] loss: 0.180\n",
      "[9,  1600] loss: 0.182\n",
      "[9,  1800] loss: 0.211\n",
      "[9,  2000] loss: 0.210\n",
      "result of epoch 8accuracy is : 87 %\n",
      "[10,   200] loss: 0.206\n",
      "[10,   400] loss: 0.192\n",
      "[10,   600] loss: 0.170\n",
      "[10,   800] loss: 0.212\n",
      "[10,  1000] loss: 0.198\n",
      "[10,  1200] loss: 0.154\n",
      "[10,  1400] loss: 0.184\n",
      "[10,  1600] loss: 0.180\n",
      "[10,  1800] loss: 0.160\n",
      "[10,  2000] loss: 0.214\n",
      "result of epoch 9accuracy is : 91 %\n",
      "[11,   200] loss: 0.169\n",
      "[11,   400] loss: 0.187\n",
      "[11,   600] loss: 0.172\n",
      "[11,   800] loss: 0.182\n",
      "[11,  1000] loss: 0.191\n",
      "[11,  1200] loss: 0.159\n",
      "[11,  1400] loss: 0.155\n",
      "[11,  1600] loss: 0.191\n",
      "[11,  1800] loss: 0.186\n",
      "[11,  2000] loss: 0.212\n",
      "result of epoch 10accuracy is : 90 %\n",
      "[12,   200] loss: 0.193\n",
      "[12,   400] loss: 0.191\n",
      "[12,   600] loss: 0.147\n",
      "[12,   800] loss: 0.202\n",
      "[12,  1000] loss: 0.171\n",
      "[12,  1200] loss: 0.189\n",
      "[12,  1400] loss: 0.140\n",
      "[12,  1600] loss: 0.152\n",
      "[12,  1800] loss: 0.149\n",
      "[12,  2000] loss: 0.167\n",
      "result of epoch 11accuracy is : 89 %\n",
      "[13,   200] loss: 0.183\n",
      "[13,   400] loss: 0.167\n",
      "[13,   600] loss: 0.139\n",
      "[13,   800] loss: 0.169\n",
      "[13,  1000] loss: 0.158\n",
      "[13,  1200] loss: 0.160\n",
      "[13,  1400] loss: 0.170\n",
      "[13,  1600] loss: 0.172\n",
      "[13,  1800] loss: 0.190\n",
      "[13,  2000] loss: 0.160\n",
      "result of epoch 12accuracy is : 90 %\n",
      "[14,   200] loss: 0.138\n",
      "[14,   400] loss: 0.149\n",
      "[14,   600] loss: 0.167\n",
      "[14,   800] loss: 0.193\n",
      "[14,  1000] loss: 0.143\n",
      "[14,  1200] loss: 0.175\n",
      "[14,  1400] loss: 0.140\n",
      "[14,  1600] loss: 0.181\n",
      "[14,  1800] loss: 0.163\n",
      "[14,  2000] loss: 0.156\n",
      "result of epoch 13accuracy is : 89 %\n",
      "[15,   200] loss: 0.173\n",
      "[15,   400] loss: 0.141\n",
      "[15,   600] loss: 0.161\n",
      "[15,   800] loss: 0.153\n",
      "[15,  1000] loss: 0.162\n",
      "[15,  1200] loss: 0.127\n",
      "[15,  1400] loss: 0.164\n",
      "[15,  1600] loss: 0.154\n",
      "[15,  1800] loss: 0.139\n",
      "[15,  2000] loss: 0.169\n",
      "result of epoch 14accuracy is : 89 %\n",
      "[16,   200] loss: 0.168\n",
      "[16,   400] loss: 0.161\n",
      "[16,   600] loss: 0.142\n",
      "[16,   800] loss: 0.134\n",
      "[16,  1000] loss: 0.146\n",
      "[16,  1200] loss: 0.132\n",
      "[16,  1400] loss: 0.156\n",
      "[16,  1600] loss: 0.175\n",
      "[16,  1800] loss: 0.160\n",
      "[16,  2000] loss: 0.125\n",
      "result of epoch 15accuracy is : 89 %\n",
      "[17,   200] loss: 0.162\n",
      "[17,   400] loss: 0.159\n",
      "[17,   600] loss: 0.124\n",
      "[17,   800] loss: 0.155\n",
      "[17,  1000] loss: 0.124\n",
      "[17,  1200] loss: 0.134\n",
      "[17,  1400] loss: 0.173\n",
      "[17,  1600] loss: 0.117\n",
      "[17,  1800] loss: 0.137\n",
      "[17,  2000] loss: 0.133\n",
      "result of epoch 16accuracy is : 90 %\n",
      "[18,   200] loss: 0.142\n",
      "[18,   400] loss: 0.141\n",
      "[18,   600] loss: 0.135\n",
      "[18,   800] loss: 0.150\n",
      "[18,  1000] loss: 0.135\n",
      "[18,  1200] loss: 0.156\n",
      "[18,  1400] loss: 0.139\n",
      "[18,  1600] loss: 0.138\n",
      "[18,  1800] loss: 0.117\n",
      "[18,  2000] loss: 0.128\n",
      "result of epoch 17accuracy is : 90 %\n",
      "[19,   200] loss: 0.118\n",
      "[19,   400] loss: 0.141\n",
      "[19,   600] loss: 0.147\n",
      "[19,   800] loss: 0.147\n",
      "[19,  1000] loss: 0.131\n",
      "[19,  1200] loss: 0.123\n",
      "[19,  1400] loss: 0.136\n",
      "[19,  1600] loss: 0.124\n",
      "[19,  1800] loss: 0.124\n",
      "[19,  2000] loss: 0.149\n",
      "result of epoch 18accuracy is : 89 %\n",
      "[20,   200] loss: 0.130\n",
      "[20,   400] loss: 0.134\n",
      "[20,   600] loss: 0.137\n",
      "[20,   800] loss: 0.151\n",
      "[20,  1000] loss: 0.114\n",
      "[20,  1200] loss: 0.126\n",
      "[20,  1400] loss: 0.125\n",
      "[20,  1600] loss: 0.109\n",
      "[20,  1800] loss: 0.125\n",
      "[20,  2000] loss: 0.128\n",
      "result of epoch 19accuracy is : 90 %\n",
      "key舒适性\n",
      "Finished Training\n",
      "Net(\n",
      "  (bilstm): LSTM(100, 100, bidirectional=True)\n",
      "  (fch): Linear(in_features=200, out_features=100, bias=True)\n",
      "  (fcv): Linear(in_features=100, out_features=100, bias=True)\n",
      "  (fcw): Linear(in_features=200, out_features=1, bias=True)\n",
      "  (fcwp): Linear(in_features=200, out_features=50, bias=True)\n",
      "  (fcwh): Linear(in_features=200, out_features=50, bias=True)\n",
      "  (fc1): Linear(in_features=3750, out_features=120, bias=True)\n",
      "  (fc2): Linear(in_features=120, out_features=50, bias=True)\n",
      "  (fc3): Linear(in_features=50, out_features=4, bias=True)\n",
      "  (embeddings): Embedding(2876, 100)\n",
      ")\n",
      "[1,   200] loss: 0.397\n",
      "[1,   400] loss: 0.171\n",
      "[1,   600] loss: 0.210\n",
      "[1,   800] loss: 0.232\n",
      "[1,  1000] loss: 0.232\n",
      "[1,  1200] loss: 0.217\n",
      "[1,  1400] loss: 0.216\n",
      "[1,  1600] loss: 0.221\n",
      "[1,  1800] loss: 0.197\n",
      "[1,  2000] loss: 0.184\n",
      "-------------cur max is ::::----------100.0\n",
      "result of epoch 0accuracy is : 100 %\n",
      "[2,   200] loss: 0.158\n",
      "[2,   400] loss: 0.203\n",
      "[2,   600] loss: 0.221\n",
      "[2,   800] loss: 0.203\n",
      "[2,  1000] loss: 0.185\n",
      "[2,  1200] loss: 0.223\n",
      "[2,  1400] loss: 0.180\n",
      "[2,  1600] loss: 0.153\n",
      "[2,  1800] loss: 0.196\n",
      "[2,  2000] loss: 0.197\n",
      "result of epoch 1accuracy is : 100 %\n",
      "[3,   200] loss: 0.166\n",
      "[3,   400] loss: 0.175\n",
      "[3,   600] loss: 0.182\n",
      "[3,   800] loss: 0.185\n",
      "[3,  1000] loss: 0.188\n",
      "[3,  1200] loss: 0.178\n",
      "[3,  1400] loss: 0.185\n",
      "[3,  1600] loss: 0.184\n",
      "[3,  1800] loss: 0.211\n",
      "[3,  2000] loss: 0.198\n",
      "result of epoch 2accuracy is : 98 %\n",
      "[4,   200] loss: 0.151\n",
      "[4,   400] loss: 0.148\n",
      "[4,   600] loss: 0.219\n",
      "[4,   800] loss: 0.215\n",
      "[4,  1000] loss: 0.180\n",
      "[4,  1200] loss: 0.139\n",
      "[4,  1400] loss: 0.198\n",
      "[4,  1600] loss: 0.168\n",
      "[4,  1800] loss: 0.169\n",
      "[4,  2000] loss: 0.166\n",
      "result of epoch 3accuracy is : 97 %\n",
      "[5,   200] loss: 0.184\n",
      "[5,   400] loss: 0.143\n",
      "[5,   600] loss: 0.148\n",
      "[5,   800] loss: 0.178\n",
      "[5,  1000] loss: 0.164\n",
      "[5,  1200] loss: 0.198\n",
      "[5,  1400] loss: 0.163\n",
      "[5,  1600] loss: 0.198\n",
      "[5,  1800] loss: 0.158\n",
      "[5,  2000] loss: 0.162\n",
      "result of epoch 4accuracy is : 98 %\n",
      "[6,   200] loss: 0.144\n",
      "[6,   400] loss: 0.145\n",
      "[6,   600] loss: 0.176\n",
      "[6,   800] loss: 0.186\n",
      "[6,  1000] loss: 0.153\n",
      "[6,  1200] loss: 0.169\n",
      "[6,  1400] loss: 0.163\n",
      "[6,  1600] loss: 0.147\n",
      "[6,  1800] loss: 0.174\n",
      "[6,  2000] loss: 0.171\n",
      "result of epoch 5accuracy is : 97 %\n",
      "[7,   200] loss: 0.132\n",
      "[7,   400] loss: 0.190\n",
      "[7,   600] loss: 0.162\n",
      "[7,   800] loss: 0.202\n",
      "[7,  1000] loss: 0.133\n",
      "[7,  1200] loss: 0.131\n",
      "[7,  1400] loss: 0.154\n",
      "[7,  1600] loss: 0.150\n",
      "[7,  1800] loss: 0.158\n",
      "[7,  2000] loss: 0.175\n",
      "result of epoch 6accuracy is : 98 %\n",
      "[8,   200] loss: 0.169\n",
      "[8,   400] loss: 0.168\n",
      "[8,   600] loss: 0.131\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[8,   800] loss: 0.135\n",
      "[8,  1000] loss: 0.137\n",
      "[8,  1200] loss: 0.164\n",
      "[8,  1400] loss: 0.159\n",
      "[8,  1600] loss: 0.130\n",
      "[8,  1800] loss: 0.134\n",
      "[8,  2000] loss: 0.189\n",
      "result of epoch 7accuracy is : 97 %\n",
      "[9,   200] loss: 0.157\n",
      "[9,   400] loss: 0.143\n",
      "[9,   600] loss: 0.137\n",
      "[9,   800] loss: 0.157\n",
      "[9,  1000] loss: 0.130\n",
      "[9,  1200] loss: 0.144\n",
      "[9,  1400] loss: 0.115\n",
      "[9,  1600] loss: 0.155\n",
      "[9,  1800] loss: 0.152\n",
      "[9,  2000] loss: 0.145\n",
      "result of epoch 8accuracy is : 97 %\n",
      "[10,   200] loss: 0.118\n",
      "[10,   400] loss: 0.129\n",
      "[10,   600] loss: 0.168\n",
      "[10,   800] loss: 0.129\n",
      "[10,  1000] loss: 0.165\n",
      "[10,  1200] loss: 0.114\n",
      "[10,  1400] loss: 0.159\n",
      "[10,  1600] loss: 0.126\n",
      "[10,  1800] loss: 0.157\n",
      "[10,  2000] loss: 0.111\n",
      "result of epoch 9accuracy is : 97 %\n",
      "[11,   200] loss: 0.133\n",
      "[11,   400] loss: 0.127\n",
      "[11,   600] loss: 0.134\n",
      "[11,   800] loss: 0.134\n",
      "[11,  1000] loss: 0.125\n",
      "[11,  1200] loss: 0.141\n",
      "[11,  1400] loss: 0.129\n",
      "[11,  1600] loss: 0.138\n",
      "[11,  1800] loss: 0.135\n",
      "[11,  2000] loss: 0.136\n",
      "result of epoch 10accuracy is : 97 %\n",
      "[12,   200] loss: 0.130\n",
      "[12,   400] loss: 0.122\n",
      "[12,   600] loss: 0.124\n",
      "[12,   800] loss: 0.120\n",
      "[12,  1000] loss: 0.123\n",
      "[12,  1200] loss: 0.123\n",
      "[12,  1400] loss: 0.160\n",
      "[12,  1600] loss: 0.118\n",
      "[12,  1800] loss: 0.109\n",
      "[12,  2000] loss: 0.140\n",
      "result of epoch 11accuracy is : 98 %\n",
      "[13,   200] loss: 0.134\n",
      "[13,   400] loss: 0.110\n",
      "[13,   600] loss: 0.122\n",
      "[13,   800] loss: 0.101\n",
      "[13,  1000] loss: 0.091\n",
      "[13,  1200] loss: 0.123\n",
      "[13,  1400] loss: 0.155\n",
      "[13,  1600] loss: 0.126\n",
      "[13,  1800] loss: 0.136\n",
      "[13,  2000] loss: 0.137\n",
      "result of epoch 12accuracy is : 98 %\n",
      "[14,   200] loss: 0.150\n",
      "[14,   400] loss: 0.105\n",
      "[14,   600] loss: 0.132\n",
      "[14,   800] loss: 0.133\n",
      "[14,  1000] loss: 0.105\n",
      "[14,  1200] loss: 0.085\n",
      "[14,  1400] loss: 0.119\n",
      "[14,  1600] loss: 0.118\n",
      "[14,  1800] loss: 0.110\n",
      "[14,  2000] loss: 0.117\n",
      "result of epoch 13accuracy is : 98 %\n",
      "[15,   200] loss: 0.111\n",
      "[15,   400] loss: 0.120\n",
      "[15,   600] loss: 0.106\n",
      "[15,   800] loss: 0.096\n",
      "[15,  1000] loss: 0.116\n",
      "[15,  1200] loss: 0.127\n",
      "[15,  1400] loss: 0.104\n",
      "[15,  1600] loss: 0.117\n",
      "[15,  1800] loss: 0.125\n",
      "[15,  2000] loss: 0.102\n",
      "result of epoch 14accuracy is : 98 %\n",
      "[16,   200] loss: 0.093\n",
      "[16,   400] loss: 0.113\n",
      "[16,   600] loss: 0.114\n",
      "[16,   800] loss: 0.098\n",
      "[16,  1000] loss: 0.113\n",
      "[16,  1200] loss: 0.098\n",
      "[16,  1400] loss: 0.105\n",
      "[16,  1600] loss: 0.113\n",
      "[16,  1800] loss: 0.097\n",
      "[16,  2000] loss: 0.122\n",
      "result of epoch 15accuracy is : 98 %\n",
      "[17,   200] loss: 0.124\n",
      "[17,   400] loss: 0.074\n",
      "[17,   600] loss: 0.073\n",
      "[17,   800] loss: 0.101\n",
      "[17,  1000] loss: 0.107\n",
      "[17,  1200] loss: 0.119\n",
      "[17,  1400] loss: 0.122\n",
      "[17,  1600] loss: 0.079\n",
      "[17,  1800] loss: 0.121\n",
      "[17,  2000] loss: 0.098\n",
      "result of epoch 16accuracy is : 98 %\n",
      "[18,   200] loss: 0.127\n",
      "[18,   400] loss: 0.104\n",
      "[18,   600] loss: 0.075\n",
      "[18,   800] loss: 0.095\n",
      "[18,  1000] loss: 0.096\n",
      "[18,  1200] loss: 0.078\n",
      "[18,  1400] loss: 0.098\n",
      "[18,  1600] loss: 0.114\n",
      "[18,  1800] loss: 0.084\n",
      "[18,  2000] loss: 0.098\n",
      "result of epoch 17accuracy is : 98 %\n",
      "[19,   200] loss: 0.088\n",
      "[19,   400] loss: 0.117\n",
      "[19,   600] loss: 0.087\n",
      "[19,   800] loss: 0.099\n",
      "[19,  1000] loss: 0.108\n",
      "[19,  1200] loss: 0.086\n",
      "[19,  1400] loss: 0.092\n",
      "[19,  1600] loss: 0.121\n",
      "[19,  1800] loss: 0.082\n",
      "[19,  2000] loss: 0.068\n",
      "result of epoch 18accuracy is : 98 %\n",
      "[20,   200] loss: 0.062\n",
      "[20,   400] loss: 0.093\n",
      "[20,   600] loss: 0.095\n",
      "[20,   800] loss: 0.125\n",
      "[20,  1000] loss: 0.070\n",
      "[20,  1200] loss: 0.079\n",
      "[20,  1400] loss: 0.087\n",
      "[20,  1600] loss: 0.100\n",
      "[20,  1800] loss: 0.097\n",
      "[20,  2000] loss: 0.070\n",
      "result of epoch 19accuracy is : 98 %\n",
      "key油耗\n",
      "Finished Training\n",
      "Net(\n",
      "  (bilstm): LSTM(100, 100, bidirectional=True)\n",
      "  (fch): Linear(in_features=200, out_features=100, bias=True)\n",
      "  (fcv): Linear(in_features=100, out_features=100, bias=True)\n",
      "  (fcw): Linear(in_features=200, out_features=1, bias=True)\n",
      "  (fcwp): Linear(in_features=200, out_features=50, bias=True)\n",
      "  (fcwh): Linear(in_features=200, out_features=50, bias=True)\n",
      "  (fc1): Linear(in_features=3750, out_features=120, bias=True)\n",
      "  (fc2): Linear(in_features=120, out_features=50, bias=True)\n",
      "  (fc3): Linear(in_features=50, out_features=4, bias=True)\n",
      "  (embeddings): Embedding(2876, 100)\n",
      ")\n",
      "[1,   200] loss: 0.695\n",
      "[1,   400] loss: 0.600\n",
      "[1,   600] loss: 0.556\n",
      "[1,   800] loss: 0.538\n",
      "[1,  1000] loss: 0.485\n",
      "[1,  1200] loss: 0.625\n",
      "[1,  1400] loss: 0.584\n",
      "[1,  1600] loss: 0.520\n",
      "[1,  1800] loss: 0.532\n",
      "[1,  2000] loss: 0.478\n",
      "-------------cur max is ::::----------79.0\n",
      "result of epoch 0accuracy is : 79 %\n",
      "[2,   200] loss: 0.480\n",
      "[2,   400] loss: 0.473\n",
      "[2,   600] loss: 0.539\n",
      "[2,   800] loss: 0.534\n",
      "[2,  1000] loss: 0.492\n",
      "[2,  1200] loss: 0.493\n",
      "[2,  1400] loss: 0.503\n",
      "[2,  1600] loss: 0.501\n",
      "[2,  1800] loss: 0.461\n",
      "[2,  2000] loss: 0.479\n",
      "result of epoch 1accuracy is : 79 %\n",
      "[3,   200] loss: 0.482\n",
      "[3,   400] loss: 0.492\n",
      "[3,   600] loss: 0.506\n",
      "[3,   800] loss: 0.456\n",
      "[3,  1000] loss: 0.478\n",
      "[3,  1200] loss: 0.460\n",
      "[3,  1400] loss: 0.465\n",
      "[3,  1600] loss: 0.471\n",
      "[3,  1800] loss: 0.487\n",
      "[3,  2000] loss: 0.471\n",
      "result of epoch 2accuracy is : 79 %\n",
      "[4,   200] loss: 0.490\n",
      "[4,   400] loss: 0.443\n",
      "[4,   600] loss: 0.440\n",
      "[4,   800] loss: 0.427\n",
      "[4,  1000] loss: 0.483\n",
      "[4,  1200] loss: 0.421\n",
      "[4,  1400] loss: 0.504\n",
      "[4,  1600] loss: 0.463\n",
      "[4,  1800] loss: 0.493\n",
      "[4,  2000] loss: 0.457\n",
      "-------------cur max is ::::----------80.0\n",
      "result of epoch 3accuracy is : 80 %\n",
      "[5,   200] loss: 0.437\n",
      "[5,   400] loss: 0.451\n",
      "[5,   600] loss: 0.436\n",
      "[5,   800] loss: 0.462\n",
      "[5,  1000] loss: 0.464\n",
      "[5,  1200] loss: 0.444\n",
      "[5,  1400] loss: 0.428\n",
      "[5,  1600] loss: 0.452\n",
      "[5,  1800] loss: 0.428\n",
      "[5,  2000] loss: 0.484\n",
      "result of epoch 4accuracy is : 79 %\n",
      "[6,   200] loss: 0.477\n",
      "[6,   400] loss: 0.413\n",
      "[6,   600] loss: 0.423\n",
      "[6,   800] loss: 0.419\n",
      "[6,  1000] loss: 0.446\n",
      "[6,  1200] loss: 0.390\n",
      "[6,  1400] loss: 0.400\n",
      "[6,  1600] loss: 0.433\n",
      "[6,  1800] loss: 0.504\n",
      "[6,  2000] loss: 0.471\n",
      "result of epoch 5accuracy is : 79 %\n",
      "[7,   200] loss: 0.430\n",
      "[7,   400] loss: 0.395\n",
      "[7,   600] loss: 0.438\n",
      "[7,   800] loss: 0.456\n",
      "[7,  1000] loss: 0.422\n",
      "[7,  1200] loss: 0.477\n",
      "[7,  1400] loss: 0.418\n",
      "[7,  1600] loss: 0.423\n",
      "[7,  1800] loss: 0.423\n",
      "[7,  2000] loss: 0.428\n",
      "result of epoch 6accuracy is : 79 %\n",
      "[8,   200] loss: 0.366\n",
      "[8,   400] loss: 0.453\n",
      "[8,   600] loss: 0.440\n",
      "[8,   800] loss: 0.402\n",
      "[8,  1000] loss: 0.398\n",
      "[8,  1200] loss: 0.401\n",
      "[8,  1400] loss: 0.449\n",
      "[8,  1600] loss: 0.371\n",
      "[8,  1800] loss: 0.420\n",
      "[8,  2000] loss: 0.455\n",
      "result of epoch 7accuracy is : 80 %\n",
      "[9,   200] loss: 0.395\n",
      "[9,   400] loss: 0.392\n",
      "[9,   600] loss: 0.394\n",
      "[9,   800] loss: 0.410\n",
      "[9,  1000] loss: 0.387\n",
      "[9,  1200] loss: 0.385\n",
      "[9,  1400] loss: 0.453\n",
      "[9,  1600] loss: 0.408\n",
      "[9,  1800] loss: 0.384\n",
      "[9,  2000] loss: 0.450\n",
      "result of epoch 8accuracy is : 80 %\n",
      "[10,   200] loss: 0.388\n",
      "[10,   400] loss: 0.430\n",
      "[10,   600] loss: 0.381\n",
      "[10,   800] loss: 0.417\n",
      "[10,  1000] loss: 0.391\n",
      "[10,  1200] loss: 0.350\n",
      "[10,  1400] loss: 0.402\n",
      "[10,  1600] loss: 0.386\n",
      "[10,  1800] loss: 0.391\n",
      "[10,  2000] loss: 0.413\n",
      "result of epoch 9accuracy is : 78 %\n",
      "[11,   200] loss: 0.372\n",
      "[11,   400] loss: 0.342\n",
      "[11,   600] loss: 0.372\n",
      "[11,   800] loss: 0.402\n",
      "[11,  1000] loss: 0.342\n",
      "[11,  1200] loss: 0.433\n",
      "[11,  1400] loss: 0.377\n",
      "[11,  1600] loss: 0.326\n",
      "[11,  1800] loss: 0.416\n",
      "[11,  2000] loss: 0.448\n",
      "result of epoch 10accuracy is : 79 %\n",
      "[12,   200] loss: 0.374\n",
      "[12,   400] loss: 0.403\n",
      "[12,   600] loss: 0.334\n",
      "[12,   800] loss: 0.362\n",
      "[12,  1000] loss: 0.368\n",
      "[12,  1200] loss: 0.419\n",
      "[12,  1400] loss: 0.410\n",
      "[12,  1600] loss: 0.357\n",
      "[12,  1800] loss: 0.367\n",
      "[12,  2000] loss: 0.386\n",
      "result of epoch 11accuracy is : 80 %\n",
      "[13,   200] loss: 0.347\n",
      "[13,   400] loss: 0.338\n",
      "[13,   600] loss: 0.344\n",
      "[13,   800] loss: 0.352\n",
      "[13,  1000] loss: 0.353\n",
      "[13,  1200] loss: 0.399\n",
      "[13,  1400] loss: 0.368\n",
      "[13,  1600] loss: 0.418\n",
      "[13,  1800] loss: 0.355\n",
      "[13,  2000] loss: 0.374\n",
      "result of epoch 12accuracy is : 78 %\n",
      "[14,   200] loss: 0.343\n",
      "[14,   400] loss: 0.356\n",
      "[14,   600] loss: 0.357\n",
      "[14,   800] loss: 0.368\n",
      "[14,  1000] loss: 0.326\n",
      "[14,  1200] loss: 0.366\n",
      "[14,  1400] loss: 0.368\n",
      "[14,  1600] loss: 0.354\n",
      "[14,  1800] loss: 0.382\n",
      "[14,  2000] loss: 0.383\n",
      "result of epoch 13accuracy is : 78 %\n",
      "[15,   200] loss: 0.332\n",
      "[15,   400] loss: 0.346\n",
      "[15,   600] loss: 0.381\n",
      "[15,   800] loss: 0.374\n",
      "[15,  1000] loss: 0.359\n",
      "[15,  1200] loss: 0.325\n",
      "[15,  1400] loss: 0.320\n",
      "[15,  1600] loss: 0.378\n",
      "[15,  1800] loss: 0.318\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[15,  2000] loss: 0.365\n",
      "result of epoch 14accuracy is : 78 %\n",
      "[16,   200] loss: 0.335\n",
      "[16,   400] loss: 0.347\n",
      "[16,   600] loss: 0.375\n",
      "[16,   800] loss: 0.337\n",
      "[16,  1000] loss: 0.341\n",
      "[16,  1200] loss: 0.310\n",
      "[16,  1400] loss: 0.332\n",
      "[16,  1600] loss: 0.346\n",
      "[16,  1800] loss: 0.398\n",
      "[16,  2000] loss: 0.330\n",
      "result of epoch 15accuracy is : 79 %\n",
      "[17,   200] loss: 0.377\n",
      "[17,   400] loss: 0.344\n",
      "[17,   600] loss: 0.341\n",
      "[17,   800] loss: 0.288\n",
      "[17,  1000] loss: 0.313\n",
      "[17,  1200] loss: 0.337\n",
      "[17,  1400] loss: 0.311\n",
      "[17,  1600] loss: 0.347\n",
      "[17,  1800] loss: 0.337\n",
      "[17,  2000] loss: 0.359\n",
      "result of epoch 16accuracy is : 79 %\n",
      "[18,   200] loss: 0.353\n",
      "[18,   400] loss: 0.303\n",
      "[18,   600] loss: 0.336\n",
      "[18,   800] loss: 0.334\n",
      "[18,  1000] loss: 0.318\n",
      "[18,  1200] loss: 0.320\n",
      "[18,  1400] loss: 0.291\n",
      "[18,  1600] loss: 0.305\n",
      "[18,  1800] loss: 0.344\n",
      "[18,  2000] loss: 0.346\n",
      "result of epoch 17accuracy is : 80 %\n",
      "[19,   200] loss: 0.388\n",
      "[19,   400] loss: 0.331\n",
      "[19,   600] loss: 0.298\n",
      "[19,   800] loss: 0.260\n",
      "[19,  1000] loss: 0.338\n",
      "[19,  1200] loss: 0.322\n",
      "[19,  1400] loss: 0.322\n",
      "[19,  1600] loss: 0.291\n",
      "[19,  1800] loss: 0.292\n",
      "[19,  2000] loss: 0.307\n",
      "result of epoch 18accuracy is : 80 %\n",
      "[20,   200] loss: 0.285\n",
      "[20,   400] loss: 0.294\n",
      "[20,   600] loss: 0.299\n",
      "[20,   800] loss: 0.351\n",
      "[20,  1000] loss: 0.304\n",
      "[20,  1200] loss: 0.311\n",
      "[20,  1400] loss: 0.282\n",
      "[20,  1600] loss: 0.323\n",
      "[20,  1800] loss: 0.260\n",
      "[20,  2000] loss: 0.363\n",
      "result of epoch 19accuracy is : 80 %\n",
      "key动力\n",
      "Finished Training\n",
      "Net(\n",
      "  (bilstm): LSTM(100, 100, bidirectional=True)\n",
      "  (fch): Linear(in_features=200, out_features=100, bias=True)\n",
      "  (fcv): Linear(in_features=100, out_features=100, bias=True)\n",
      "  (fcw): Linear(in_features=200, out_features=1, bias=True)\n",
      "  (fcwp): Linear(in_features=200, out_features=50, bias=True)\n",
      "  (fcwh): Linear(in_features=200, out_features=50, bias=True)\n",
      "  (fc1): Linear(in_features=3750, out_features=120, bias=True)\n",
      "  (fc2): Linear(in_features=120, out_features=50, bias=True)\n",
      "  (fc3): Linear(in_features=50, out_features=4, bias=True)\n",
      "  (embeddings): Embedding(2876, 100)\n",
      ")\n",
      "[1,   200] loss: 0.322\n",
      "[1,   400] loss: 0.216\n",
      "[1,   600] loss: 0.199\n",
      "[1,   800] loss: 0.126\n",
      "[1,  1000] loss: 0.193\n",
      "[1,  1200] loss: 0.161\n",
      "[1,  1400] loss: 0.172\n",
      "[1,  1600] loss: 0.145\n",
      "[1,  1800] loss: 0.161\n",
      "[1,  2000] loss: 0.155\n",
      "-------------cur max is ::::----------96.0\n",
      "result of epoch 0accuracy is : 96 %\n",
      "[2,   200] loss: 0.145\n",
      "[2,   400] loss: 0.127\n",
      "[2,   600] loss: 0.150\n",
      "[2,   800] loss: 0.137\n",
      "[2,  1000] loss: 0.118\n",
      "[2,  1200] loss: 0.146\n",
      "[2,  1400] loss: 0.108\n",
      "[2,  1600] loss: 0.135\n",
      "[2,  1800] loss: 0.179\n",
      "[2,  2000] loss: 0.123\n",
      "-------------cur max is ::::----------97.0\n",
      "result of epoch 1accuracy is : 97 %\n",
      "[3,   200] loss: 0.135\n",
      "[3,   400] loss: 0.120\n",
      "[3,   600] loss: 0.137\n",
      "[3,   800] loss: 0.147\n",
      "[3,  1000] loss: 0.126\n",
      "[3,  1200] loss: 0.108\n",
      "[3,  1400] loss: 0.150\n",
      "[3,  1600] loss: 0.122\n",
      "[3,  1800] loss: 0.123\n",
      "[3,  2000] loss: 0.107\n",
      "result of epoch 2accuracy is : 97 %\n",
      "[4,   200] loss: 0.135\n",
      "[4,   400] loss: 0.118\n",
      "[4,   600] loss: 0.135\n",
      "[4,   800] loss: 0.102\n",
      "[4,  1000] loss: 0.122\n",
      "[4,  1200] loss: 0.114\n",
      "[4,  1400] loss: 0.124\n",
      "[4,  1600] loss: 0.107\n",
      "[4,  1800] loss: 0.108\n",
      "[4,  2000] loss: 0.156\n",
      "result of epoch 3accuracy is : 97 %\n",
      "[5,   200] loss: 0.102\n",
      "[5,   400] loss: 0.115\n",
      "[5,   600] loss: 0.122\n",
      "[5,   800] loss: 0.113\n",
      "[5,  1000] loss: 0.115\n",
      "[5,  1200] loss: 0.085\n",
      "[5,  1400] loss: 0.109\n",
      "[5,  1600] loss: 0.148\n",
      "[5,  1800] loss: 0.120\n",
      "[5,  2000] loss: 0.111\n",
      "result of epoch 4accuracy is : 97 %\n",
      "[6,   200] loss: 0.101\n",
      "[6,   400] loss: 0.098\n",
      "[6,   600] loss: 0.102\n",
      "[6,   800] loss: 0.114\n",
      "[6,  1000] loss: 0.132\n",
      "[6,  1200] loss: 0.105\n",
      "[6,  1400] loss: 0.081\n",
      "[6,  1600] loss: 0.116\n",
      "[6,  1800] loss: 0.117\n",
      "[6,  2000] loss: 0.133\n",
      "result of epoch 5accuracy is : 97 %\n",
      "[7,   200] loss: 0.109\n",
      "[7,   400] loss: 0.098\n",
      "[7,   600] loss: 0.095\n",
      "[7,   800] loss: 0.110\n",
      "[7,  1000] loss: 0.094\n",
      "[7,  1200] loss: 0.106\n",
      "[7,  1400] loss: 0.086\n",
      "[7,  1600] loss: 0.115\n",
      "[7,  1800] loss: 0.111\n",
      "[7,  2000] loss: 0.099\n",
      "result of epoch 6accuracy is : 97 %\n",
      "[8,   200] loss: 0.099\n",
      "[8,   400] loss: 0.066\n",
      "[8,   600] loss: 0.107\n",
      "[8,   800] loss: 0.110\n",
      "[8,  1000] loss: 0.095\n",
      "[8,  1200] loss: 0.104\n",
      "[8,  1400] loss: 0.070\n",
      "[8,  1600] loss: 0.124\n",
      "[8,  1800] loss: 0.110\n",
      "[8,  2000] loss: 0.087\n",
      "result of epoch 7accuracy is : 96 %\n",
      "[9,   200] loss: 0.074\n",
      "[9,   400] loss: 0.089\n",
      "[9,   600] loss: 0.123\n",
      "[9,   800] loss: 0.091\n",
      "[9,  1000] loss: 0.086\n",
      "[9,  1200] loss: 0.063\n",
      "[9,  1400] loss: 0.070\n",
      "[9,  1600] loss: 0.091\n",
      "[9,  1800] loss: 0.146\n",
      "[9,  2000] loss: 0.092\n",
      "result of epoch 8accuracy is : 96 %\n",
      "[10,   200] loss: 0.089\n",
      "[10,   400] loss: 0.090\n",
      "[10,   600] loss: 0.068\n",
      "[10,   800] loss: 0.073\n",
      "[10,  1000] loss: 0.089\n",
      "[10,  1200] loss: 0.080\n",
      "[10,  1400] loss: 0.071\n",
      "[10,  1600] loss: 0.114\n",
      "[10,  1800] loss: 0.106\n",
      "[10,  2000] loss: 0.078\n",
      "result of epoch 9accuracy is : 96 %\n",
      "[11,   200] loss: 0.102\n",
      "[11,   400] loss: 0.110\n",
      "[11,   600] loss: 0.081\n",
      "[11,   800] loss: 0.080\n",
      "[11,  1000] loss: 0.080\n",
      "[11,  1200] loss: 0.067\n",
      "[11,  1400] loss: 0.099\n",
      "[11,  1600] loss: 0.093\n",
      "[11,  1800] loss: 0.059\n",
      "[11,  2000] loss: 0.055\n",
      "result of epoch 10accuracy is : 96 %\n",
      "[12,   200] loss: 0.069\n",
      "[12,   400] loss: 0.073\n",
      "[12,   600] loss: 0.092\n",
      "[12,   800] loss: 0.070\n",
      "[12,  1000] loss: 0.093\n",
      "[12,  1200] loss: 0.071\n",
      "[12,  1400] loss: 0.085\n",
      "[12,  1600] loss: 0.066\n",
      "[12,  1800] loss: 0.062\n",
      "[12,  2000] loss: 0.081\n",
      "result of epoch 11accuracy is : 96 %\n",
      "[13,   200] loss: 0.068\n",
      "[13,   400] loss: 0.086\n",
      "[13,   600] loss: 0.071\n",
      "[13,   800] loss: 0.062\n",
      "[13,  1000] loss: 0.060\n",
      "[13,  1200] loss: 0.076\n",
      "[13,  1400] loss: 0.062\n",
      "[13,  1600] loss: 0.084\n",
      "[13,  1800] loss: 0.086\n",
      "[13,  2000] loss: 0.068\n",
      "result of epoch 12accuracy is : 96 %\n",
      "[14,   200] loss: 0.077\n",
      "[14,   400] loss: 0.064\n",
      "[14,   600] loss: 0.081\n",
      "[14,   800] loss: 0.059\n",
      "[14,  1000] loss: 0.086\n",
      "[14,  1200] loss: 0.066\n",
      "[14,  1400] loss: 0.079\n",
      "[14,  1600] loss: 0.055\n",
      "[14,  1800] loss: 0.065\n",
      "[14,  2000] loss: 0.058\n",
      "result of epoch 13accuracy is : 96 %\n",
      "[15,   200] loss: 0.087\n",
      "[15,   400] loss: 0.063\n",
      "[15,   600] loss: 0.074\n",
      "[15,   800] loss: 0.056\n",
      "[15,  1000] loss: 0.059\n",
      "[15,  1200] loss: 0.066\n",
      "[15,  1400] loss: 0.053\n",
      "[15,  1600] loss: 0.063\n",
      "[15,  1800] loss: 0.071\n",
      "[15,  2000] loss: 0.055\n",
      "result of epoch 14accuracy is : 96 %\n",
      "[16,   200] loss: 0.058\n",
      "[16,   400] loss: 0.054\n",
      "[16,   600] loss: 0.058\n",
      "[16,   800] loss: 0.044\n",
      "[16,  1000] loss: 0.055\n",
      "[16,  1200] loss: 0.049\n",
      "[16,  1400] loss: 0.064\n",
      "[16,  1600] loss: 0.082\n",
      "[16,  1800] loss: 0.065\n",
      "[16,  2000] loss: 0.073\n",
      "result of epoch 15accuracy is : 96 %\n",
      "[17,   200] loss: 0.069\n",
      "[17,   400] loss: 0.056\n",
      "[17,   600] loss: 0.049\n",
      "[17,   800] loss: 0.073\n",
      "[17,  1000] loss: 0.039\n",
      "[17,  1200] loss: 0.049\n",
      "[17,  1400] loss: 0.059\n",
      "[17,  1600] loss: 0.059\n",
      "[17,  1800] loss: 0.052\n",
      "[17,  2000] loss: 0.069\n",
      "result of epoch 16accuracy is : 96 %\n",
      "[18,   200] loss: 0.047\n",
      "[18,   400] loss: 0.058\n",
      "[18,   600] loss: 0.063\n",
      "[18,   800] loss: 0.064\n",
      "[18,  1000] loss: 0.053\n",
      "[18,  1200] loss: 0.039\n",
      "[18,  1400] loss: 0.047\n",
      "[18,  1600] loss: 0.037\n",
      "[18,  1800] loss: 0.047\n",
      "[18,  2000] loss: 0.077\n",
      "result of epoch 17accuracy is : 96 %\n",
      "[19,   200] loss: 0.059\n",
      "[19,   400] loss: 0.056\n",
      "[19,   600] loss: 0.045\n",
      "[19,   800] loss: 0.046\n",
      "[19,  1000] loss: 0.038\n",
      "[19,  1200] loss: 0.049\n",
      "[19,  1400] loss: 0.051\n",
      "[19,  1600] loss: 0.048\n",
      "[19,  1800] loss: 0.064\n",
      "[19,  2000] loss: 0.067\n",
      "result of epoch 18accuracy is : 96 %\n",
      "[20,   200] loss: 0.054\n",
      "[20,   400] loss: 0.039\n",
      "[20,   600] loss: 0.037\n",
      "[20,   800] loss: 0.043\n",
      "[20,  1000] loss: 0.035\n",
      "[20,  1200] loss: 0.075\n",
      "[20,  1400] loss: 0.059\n",
      "[20,  1600] loss: 0.056\n",
      "[20,  1800] loss: 0.040\n",
      "[20,  2000] loss: 0.062\n",
      "result of epoch 19accuracy is : 96 %\n",
      "key内饰\n",
      "Finished Training\n",
      "Net(\n",
      "  (bilstm): LSTM(100, 100, bidirectional=True)\n",
      "  (fch): Linear(in_features=200, out_features=100, bias=True)\n",
      "  (fcv): Linear(in_features=100, out_features=100, bias=True)\n",
      "  (fcw): Linear(in_features=200, out_features=1, bias=True)\n",
      "  (fcwp): Linear(in_features=200, out_features=50, bias=True)\n",
      "  (fcwh): Linear(in_features=200, out_features=50, bias=True)\n",
      "  (fc1): Linear(in_features=3750, out_features=120, bias=True)\n",
      "  (fc2): Linear(in_features=120, out_features=50, bias=True)\n",
      "  (fc3): Linear(in_features=50, out_features=4, bias=True)\n",
      "  (embeddings): Embedding(2876, 100)\n",
      ")\n",
      "[1,   200] loss: 0.316\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1,   400] loss: 0.231\n",
      "[1,   600] loss: 0.223\n",
      "[1,   800] loss: 0.212\n",
      "[1,  1000] loss: 0.229\n",
      "[1,  1200] loss: 0.184\n",
      "[1,  1400] loss: 0.164\n",
      "[1,  1600] loss: 0.166\n",
      "[1,  1800] loss: 0.169\n",
      "[1,  2000] loss: 0.148\n",
      "-------------cur max is ::::----------92.0\n",
      "result of epoch 0accuracy is : 92 %\n",
      "[2,   200] loss: 0.169\n",
      "[2,   400] loss: 0.161\n",
      "[2,   600] loss: 0.163\n",
      "[2,   800] loss: 0.155\n",
      "[2,  1000] loss: 0.145\n",
      "[2,  1200] loss: 0.159\n",
      "[2,  1400] loss: 0.172\n",
      "[2,  1600] loss: 0.139\n",
      "[2,  1800] loss: 0.167\n",
      "[2,  2000] loss: 0.127\n",
      "result of epoch 1accuracy is : 92 %\n",
      "[3,   200] loss: 0.145\n",
      "[3,   400] loss: 0.141\n",
      "[3,   600] loss: 0.147\n",
      "[3,   800] loss: 0.135\n",
      "[3,  1000] loss: 0.163\n",
      "[3,  1200] loss: 0.156\n",
      "[3,  1400] loss: 0.156\n",
      "[3,  1600] loss: 0.117\n",
      "[3,  1800] loss: 0.173\n",
      "[3,  2000] loss: 0.127\n",
      "result of epoch 2accuracy is : 92 %\n",
      "[4,   200] loss: 0.168\n",
      "[4,   400] loss: 0.140\n",
      "[4,   600] loss: 0.111\n",
      "[4,   800] loss: 0.133\n",
      "[4,  1000] loss: 0.134\n",
      "[4,  1200] loss: 0.155\n",
      "[4,  1400] loss: 0.133\n",
      "[4,  1600] loss: 0.126\n",
      "[4,  1800] loss: 0.170\n",
      "[4,  2000] loss: 0.138\n",
      "result of epoch 3accuracy is : 92 %\n",
      "[5,   200] loss: 0.116\n",
      "[5,   400] loss: 0.128\n",
      "[5,   600] loss: 0.125\n",
      "[5,   800] loss: 0.121\n",
      "[5,  1000] loss: 0.139\n",
      "[5,  1200] loss: 0.125\n",
      "[5,  1400] loss: 0.147\n",
      "[5,  1600] loss: 0.149\n",
      "[5,  1800] loss: 0.146\n",
      "[5,  2000] loss: 0.105\n",
      "result of epoch 4accuracy is : 91 %\n",
      "[6,   200] loss: 0.150\n",
      "[6,   400] loss: 0.146\n",
      "[6,   600] loss: 0.090\n",
      "[6,   800] loss: 0.108\n",
      "[6,  1000] loss: 0.143\n",
      "[6,  1200] loss: 0.137\n",
      "[6,  1400] loss: 0.110\n",
      "[6,  1600] loss: 0.138\n",
      "[6,  1800] loss: 0.104\n",
      "[6,  2000] loss: 0.130\n",
      "result of epoch 5accuracy is : 91 %\n",
      "[7,   200] loss: 0.094\n",
      "[7,   400] loss: 0.124\n",
      "[7,   600] loss: 0.106\n",
      "[7,   800] loss: 0.128\n",
      "[7,  1000] loss: 0.118\n",
      "[7,  1200] loss: 0.116\n",
      "[7,  1400] loss: 0.112\n",
      "[7,  1600] loss: 0.110\n",
      "[7,  1800] loss: 0.131\n",
      "[7,  2000] loss: 0.142\n",
      "result of epoch 6accuracy is : 91 %\n",
      "[8,   200] loss: 0.131\n",
      "[8,   400] loss: 0.112\n",
      "[8,   600] loss: 0.084\n",
      "[8,   800] loss: 0.090\n",
      "[8,  1000] loss: 0.127\n",
      "[8,  1200] loss: 0.087\n",
      "[8,  1400] loss: 0.108\n",
      "[8,  1600] loss: 0.112\n",
      "[8,  1800] loss: 0.110\n",
      "[8,  2000] loss: 0.131\n",
      "result of epoch 7accuracy is : 91 %\n",
      "[9,   200] loss: 0.111\n",
      "[9,   400] loss: 0.120\n",
      "[9,   600] loss: 0.100\n",
      "[9,   800] loss: 0.107\n",
      "[9,  1000] loss: 0.112\n",
      "[9,  1200] loss: 0.094\n",
      "[9,  1400] loss: 0.112\n",
      "[9,  1600] loss: 0.113\n",
      "[9,  1800] loss: 0.076\n",
      "[9,  2000] loss: 0.096\n",
      "result of epoch 8accuracy is : 92 %\n",
      "[10,   200] loss: 0.095\n",
      "[10,   400] loss: 0.106\n",
      "[10,   600] loss: 0.078\n",
      "[10,   800] loss: 0.101\n",
      "[10,  1000] loss: 0.095\n",
      "[10,  1200] loss: 0.097\n",
      "[10,  1400] loss: 0.086\n",
      "[10,  1600] loss: 0.101\n",
      "[10,  1800] loss: 0.117\n",
      "[10,  2000] loss: 0.105\n",
      "result of epoch 9accuracy is : 91 %\n",
      "[11,   200] loss: 0.074\n",
      "[11,   400] loss: 0.111\n",
      "[11,   600] loss: 0.126\n",
      "[11,   800] loss: 0.093\n",
      "[11,  1000] loss: 0.115\n",
      "[11,  1200] loss: 0.095\n",
      "[11,  1400] loss: 0.092\n",
      "[11,  1600] loss: 0.080\n",
      "[11,  1800] loss: 0.098\n",
      "[11,  2000] loss: 0.066\n",
      "result of epoch 10accuracy is : 92 %\n",
      "[12,   200] loss: 0.096\n",
      "[12,   400] loss: 0.084\n",
      "[12,   600] loss: 0.079\n",
      "[12,   800] loss: 0.077\n",
      "[12,  1000] loss: 0.074\n",
      "[12,  1200] loss: 0.093\n",
      "[12,  1400] loss: 0.108\n",
      "[12,  1600] loss: 0.081\n",
      "[12,  1800] loss: 0.092\n",
      "[12,  2000] loss: 0.087\n",
      "result of epoch 11accuracy is : 92 %\n",
      "[13,   200] loss: 0.084\n",
      "[13,   400] loss: 0.082\n",
      "[13,   600] loss: 0.106\n",
      "[13,   800] loss: 0.062\n",
      "[13,  1000] loss: 0.078\n",
      "[13,  1200] loss: 0.076\n",
      "[13,  1400] loss: 0.077\n",
      "[13,  1600] loss: 0.088\n",
      "[13,  1800] loss: 0.071\n",
      "[13,  2000] loss: 0.083\n",
      "result of epoch 12accuracy is : 91 %\n",
      "[14,   200] loss: 0.094\n",
      "[14,   400] loss: 0.076\n",
      "[14,   600] loss: 0.077\n",
      "[14,   800] loss: 0.080\n",
      "[14,  1000] loss: 0.061\n",
      "[14,  1200] loss: 0.058\n",
      "[14,  1400] loss: 0.084\n",
      "[14,  1600] loss: 0.099\n",
      "[14,  1800] loss: 0.073\n",
      "[14,  2000] loss: 0.070\n",
      "result of epoch 13accuracy is : 92 %\n",
      "[15,   200] loss: 0.065\n",
      "[15,   400] loss: 0.045\n",
      "[15,   600] loss: 0.062\n",
      "[15,   800] loss: 0.070\n",
      "[15,  1000] loss: 0.088\n",
      "[15,  1200] loss: 0.065\n",
      "[15,  1400] loss: 0.103\n",
      "[15,  1600] loss: 0.081\n",
      "[15,  1800] loss: 0.083\n",
      "[15,  2000] loss: 0.069\n",
      "result of epoch 14accuracy is : 89 %\n",
      "[16,   200] loss: 0.070\n",
      "[16,   400] loss: 0.056\n",
      "[16,   600] loss: 0.065\n",
      "[16,   800] loss: 0.053\n",
      "[16,  1000] loss: 0.072\n",
      "[16,  1200] loss: 0.083\n",
      "[16,  1400] loss: 0.073\n",
      "[16,  1600] loss: 0.064\n",
      "[16,  1800] loss: 0.066\n",
      "[16,  2000] loss: 0.073\n",
      "result of epoch 15accuracy is : 91 %\n",
      "[17,   200] loss: 0.067\n",
      "[17,   400] loss: 0.068\n",
      "[17,   600] loss: 0.050\n",
      "[17,   800] loss: 0.052\n",
      "[17,  1000] loss: 0.066\n",
      "[17,  1200] loss: 0.054\n",
      "[17,  1400] loss: 0.082\n",
      "[17,  1600] loss: 0.049\n",
      "[17,  1800] loss: 0.080\n",
      "[17,  2000] loss: 0.087\n",
      "result of epoch 16accuracy is : 90 %\n",
      "[18,   200] loss: 0.059\n",
      "[18,   400] loss: 0.059\n",
      "[18,   600] loss: 0.051\n",
      "[18,   800] loss: 0.078\n",
      "[18,  1000] loss: 0.072\n",
      "[18,  1200] loss: 0.046\n",
      "[18,  1400] loss: 0.077\n",
      "[18,  1600] loss: 0.047\n",
      "[18,  1800] loss: 0.064\n",
      "[18,  2000] loss: 0.067\n",
      "result of epoch 17accuracy is : 91 %\n",
      "[19,   200] loss: 0.050\n",
      "[19,   400] loss: 0.057\n",
      "[19,   600] loss: 0.055\n",
      "[19,   800] loss: 0.058\n",
      "[19,  1000] loss: 0.084\n",
      "[19,  1200] loss: 0.050\n",
      "[19,  1400] loss: 0.053\n",
      "[19,  1600] loss: 0.054\n",
      "[19,  1800] loss: 0.073\n",
      "[19,  2000] loss: 0.046\n",
      "result of epoch 18accuracy is : 90 %\n",
      "[20,   200] loss: 0.031\n",
      "[20,   400] loss: 0.066\n",
      "[20,   600] loss: 0.065\n",
      "[20,   800] loss: 0.044\n",
      "[20,  1000] loss: 0.056\n",
      "[20,  1200] loss: 0.052\n",
      "[20,  1400] loss: 0.063\n",
      "[20,  1600] loss: 0.048\n",
      "[20,  1800] loss: 0.063\n",
      "[20,  2000] loss: 0.050\n",
      "result of epoch 19accuracy is : 90 %\n",
      "key安全性\n",
      "Finished Training\n",
      "Net(\n",
      "  (bilstm): LSTM(100, 100, bidirectional=True)\n",
      "  (fch): Linear(in_features=200, out_features=100, bias=True)\n",
      "  (fcv): Linear(in_features=100, out_features=100, bias=True)\n",
      "  (fcw): Linear(in_features=200, out_features=1, bias=True)\n",
      "  (fcwp): Linear(in_features=200, out_features=50, bias=True)\n",
      "  (fcwh): Linear(in_features=200, out_features=50, bias=True)\n",
      "  (fc1): Linear(in_features=3750, out_features=120, bias=True)\n",
      "  (fc2): Linear(in_features=120, out_features=50, bias=True)\n",
      "  (fc3): Linear(in_features=50, out_features=4, bias=True)\n",
      "  (embeddings): Embedding(2876, 100)\n",
      ")\n",
      "[1,   200] loss: 0.256\n",
      "[1,   400] loss: 0.220\n",
      "[1,   600] loss: 0.167\n",
      "[1,   800] loss: 0.160\n",
      "[1,  1000] loss: 0.180\n",
      "[1,  1200] loss: 0.143\n",
      "[1,  1400] loss: 0.113\n",
      "[1,  1600] loss: 0.151\n",
      "[1,  1800] loss: 0.094\n",
      "[1,  2000] loss: 0.125\n",
      "-------------cur max is ::::----------95.0\n",
      "result of epoch 0accuracy is : 95 %\n",
      "[2,   200] loss: 0.125\n",
      "[2,   400] loss: 0.105\n",
      "[2,   600] loss: 0.100\n",
      "[2,   800] loss: 0.143\n",
      "[2,  1000] loss: 0.148\n",
      "[2,  1200] loss: 0.094\n",
      "[2,  1400] loss: 0.115\n",
      "[2,  1600] loss: 0.104\n",
      "[2,  1800] loss: 0.113\n",
      "[2,  2000] loss: 0.130\n",
      "-------------cur max is ::::----------96.0\n",
      "result of epoch 1accuracy is : 96 %\n",
      "[3,   200] loss: 0.089\n",
      "[3,   400] loss: 0.111\n",
      "[3,   600] loss: 0.088\n",
      "[3,   800] loss: 0.131\n",
      "[3,  1000] loss: 0.104\n",
      "[3,  1200] loss: 0.119\n",
      "[3,  1400] loss: 0.123\n",
      "[3,  1600] loss: 0.112\n",
      "[3,  1800] loss: 0.133\n",
      "[3,  2000] loss: 0.097\n",
      "result of epoch 2accuracy is : 96 %\n",
      "[4,   200] loss: 0.103\n",
      "[4,   400] loss: 0.112\n",
      "[4,   600] loss: 0.114\n",
      "[4,   800] loss: 0.099\n",
      "[4,  1000] loss: 0.097\n",
      "[4,  1200] loss: 0.115\n",
      "[4,  1400] loss: 0.108\n",
      "[4,  1600] loss: 0.116\n",
      "[4,  1800] loss: 0.077\n",
      "[4,  2000] loss: 0.124\n",
      "result of epoch 3accuracy is : 95 %\n",
      "[5,   200] loss: 0.102\n",
      "[5,   400] loss: 0.110\n",
      "[5,   600] loss: 0.104\n",
      "[5,   800] loss: 0.107\n",
      "[5,  1000] loss: 0.071\n",
      "[5,  1200] loss: 0.106\n",
      "[5,  1400] loss: 0.092\n",
      "[5,  1600] loss: 0.092\n",
      "[5,  1800] loss: 0.090\n",
      "[5,  2000] loss: 0.124\n",
      "result of epoch 4accuracy is : 96 %\n",
      "[6,   200] loss: 0.086\n",
      "[6,   400] loss: 0.098\n",
      "[6,   600] loss: 0.100\n",
      "[6,   800] loss: 0.086\n",
      "[6,  1000] loss: 0.116\n",
      "[6,  1200] loss: 0.085\n",
      "[6,  1400] loss: 0.102\n",
      "[6,  1600] loss: 0.110\n",
      "[6,  1800] loss: 0.090\n",
      "[6,  2000] loss: 0.088\n",
      "result of epoch 5accuracy is : 96 %\n",
      "[7,   200] loss: 0.103\n",
      "[7,   400] loss: 0.115\n",
      "[7,   600] loss: 0.080\n",
      "[7,   800] loss: 0.075\n",
      "[7,  1000] loss: 0.090\n",
      "[7,  1200] loss: 0.073\n",
      "[7,  1400] loss: 0.083\n",
      "[7,  1600] loss: 0.094\n",
      "[7,  1800] loss: 0.082\n",
      "[7,  2000] loss: 0.129\n",
      "-------------cur max is ::::----------97.0\n",
      "result of epoch 6accuracy is : 97 %\n",
      "[8,   200] loss: 0.073\n",
      "[8,   400] loss: 0.075\n",
      "[8,   600] loss: 0.096\n",
      "[8,   800] loss: 0.072\n",
      "[8,  1000] loss: 0.090\n",
      "[8,  1200] loss: 0.082\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[8,  1400] loss: 0.099\n",
      "[8,  1600] loss: 0.103\n",
      "[8,  1800] loss: 0.101\n",
      "[8,  2000] loss: 0.082\n",
      "result of epoch 7accuracy is : 97 %\n",
      "[9,   200] loss: 0.102\n",
      "[9,   400] loss: 0.072\n",
      "[9,   600] loss: 0.089\n",
      "[9,   800] loss: 0.069\n",
      "[9,  1000] loss: 0.067\n",
      "[9,  1200] loss: 0.102\n",
      "[9,  1400] loss: 0.102\n",
      "[9,  1600] loss: 0.094\n",
      "[9,  1800] loss: 0.058\n",
      "[9,  2000] loss: 0.092\n",
      "result of epoch 8accuracy is : 96 %\n",
      "[10,   200] loss: 0.090\n",
      "[10,   400] loss: 0.059\n",
      "[10,   600] loss: 0.077\n",
      "[10,   800] loss: 0.072\n",
      "[10,  1000] loss: 0.082\n",
      "[10,  1200] loss: 0.084\n",
      "[10,  1400] loss: 0.101\n",
      "[10,  1600] loss: 0.065\n",
      "[10,  1800] loss: 0.074\n",
      "[10,  2000] loss: 0.091\n",
      "-------------cur max is ::::----------98.0\n",
      "result of epoch 9accuracy is : 98 %\n",
      "[11,   200] loss: 0.058\n",
      "[11,   400] loss: 0.068\n",
      "[11,   600] loss: 0.100\n",
      "[11,   800] loss: 0.065\n",
      "[11,  1000] loss: 0.063\n",
      "[11,  1200] loss: 0.061\n",
      "[11,  1400] loss: 0.079\n",
      "[11,  1600] loss: 0.078\n",
      "[11,  1800] loss: 0.093\n",
      "[11,  2000] loss: 0.112\n",
      "result of epoch 10accuracy is : 97 %\n",
      "[12,   200] loss: 0.053\n",
      "[12,   400] loss: 0.071\n",
      "[12,   600] loss: 0.072\n",
      "[12,   800] loss: 0.094\n",
      "[12,  1000] loss: 0.094\n",
      "[12,  1200] loss: 0.073\n",
      "[12,  1400] loss: 0.076\n",
      "[12,  1600] loss: 0.057\n",
      "[12,  1800] loss: 0.082\n",
      "[12,  2000] loss: 0.094\n",
      "result of epoch 11accuracy is : 98 %\n",
      "[13,   200] loss: 0.082\n",
      "[13,   400] loss: 0.053\n",
      "[13,   600] loss: 0.069\n",
      "[13,   800] loss: 0.085\n",
      "[13,  1000] loss: 0.075\n",
      "[13,  1200] loss: 0.079\n",
      "[13,  1400] loss: 0.068\n",
      "[13,  1600] loss: 0.065\n",
      "[13,  1800] loss: 0.065\n",
      "[13,  2000] loss: 0.069\n",
      "result of epoch 12accuracy is : 98 %\n",
      "[14,   200] loss: 0.076\n",
      "[14,   400] loss: 0.086\n",
      "[14,   600] loss: 0.044\n",
      "[14,   800] loss: 0.056\n",
      "[14,  1000] loss: 0.065\n",
      "[14,  1200] loss: 0.088\n",
      "[14,  1400] loss: 0.064\n",
      "[14,  1600] loss: 0.059\n",
      "[14,  1800] loss: 0.051\n",
      "[14,  2000] loss: 0.086\n",
      "result of epoch 13accuracy is : 98 %\n",
      "[15,   200] loss: 0.062\n",
      "[15,   400] loss: 0.054\n",
      "[15,   600] loss: 0.072\n",
      "[15,   800] loss: 0.084\n",
      "[15,  1000] loss: 0.055\n",
      "[15,  1200] loss: 0.055\n",
      "[15,  1400] loss: 0.061\n",
      "[15,  1600] loss: 0.061\n",
      "[15,  1800] loss: 0.069\n",
      "[15,  2000] loss: 0.079\n",
      "result of epoch 14accuracy is : 98 %\n",
      "[16,   200] loss: 0.077\n",
      "[16,   400] loss: 0.059\n",
      "[16,   600] loss: 0.050\n",
      "[16,   800] loss: 0.066\n",
      "[16,  1000] loss: 0.049\n",
      "[16,  1200] loss: 0.044\n",
      "[16,  1400] loss: 0.056\n",
      "[16,  1600] loss: 0.078\n",
      "[16,  1800] loss: 0.064\n",
      "[16,  2000] loss: 0.075\n",
      "result of epoch 15accuracy is : 98 %\n",
      "[17,   200] loss: 0.058\n",
      "[17,   400] loss: 0.046\n",
      "[17,   600] loss: 0.074\n",
      "[17,   800] loss: 0.060\n",
      "[17,  1000] loss: 0.053\n",
      "[17,  1200] loss: 0.052\n",
      "[17,  1400] loss: 0.077\n",
      "[17,  1600] loss: 0.057\n",
      "[17,  1800] loss: 0.057\n",
      "[17,  2000] loss: 0.060\n",
      "result of epoch 16accuracy is : 98 %\n",
      "[18,   200] loss: 0.059\n",
      "[18,   400] loss: 0.065\n",
      "[18,   600] loss: 0.062\n",
      "[18,   800] loss: 0.054\n",
      "[18,  1000] loss: 0.062\n",
      "[18,  1200] loss: 0.049\n",
      "[18,  1400] loss: 0.065\n",
      "[18,  1600] loss: 0.042\n",
      "[18,  1800] loss: 0.055\n",
      "[18,  2000] loss: 0.064\n",
      "result of epoch 17accuracy is : 98 %\n",
      "[19,   200] loss: 0.042\n",
      "[19,   400] loss: 0.042\n",
      "[19,   600] loss: 0.051\n",
      "[19,   800] loss: 0.058\n",
      "[19,  1000] loss: 0.069\n",
      "[19,  1200] loss: 0.047\n",
      "[19,  1400] loss: 0.069\n",
      "[19,  1600] loss: 0.069\n",
      "[19,  1800] loss: 0.051\n",
      "[19,  2000] loss: 0.066\n",
      "result of epoch 18accuracy is : 97 %\n",
      "[20,   200] loss: 0.045\n",
      "[20,   400] loss: 0.038\n",
      "[20,   600] loss: 0.054\n",
      "[20,   800] loss: 0.078\n",
      "[20,  1000] loss: 0.053\n",
      "[20,  1200] loss: 0.065\n",
      "[20,  1400] loss: 0.059\n",
      "[20,  1600] loss: 0.050\n",
      "[20,  1800] loss: 0.045\n",
      "[20,  2000] loss: 0.040\n",
      "result of epoch 19accuracy is : 98 %\n",
      "key空间\n",
      "Finished Training\n",
      "Net(\n",
      "  (bilstm): LSTM(100, 100, bidirectional=True)\n",
      "  (fch): Linear(in_features=200, out_features=100, bias=True)\n",
      "  (fcv): Linear(in_features=100, out_features=100, bias=True)\n",
      "  (fcw): Linear(in_features=200, out_features=1, bias=True)\n",
      "  (fcwp): Linear(in_features=200, out_features=50, bias=True)\n",
      "  (fcwh): Linear(in_features=200, out_features=50, bias=True)\n",
      "  (fc1): Linear(in_features=3750, out_features=120, bias=True)\n",
      "  (fc2): Linear(in_features=120, out_features=50, bias=True)\n",
      "  (fc3): Linear(in_features=50, out_features=4, bias=True)\n",
      "  (embeddings): Embedding(2876, 100)\n",
      ")\n",
      "[1,   200] loss: 0.337\n",
      "[1,   400] loss: 0.244\n",
      "[1,   600] loss: 0.227\n",
      "[1,   800] loss: 0.194\n",
      "[1,  1000] loss: 0.224\n",
      "[1,  1200] loss: 0.211\n",
      "[1,  1400] loss: 0.199\n",
      "[1,  1600] loss: 0.165\n",
      "[1,  1800] loss: 0.166\n",
      "[1,  2000] loss: 0.147\n",
      "-------------cur max is ::::----------95.0\n",
      "result of epoch 0accuracy is : 95 %\n",
      "[2,   200] loss: 0.160\n",
      "[2,   400] loss: 0.162\n",
      "[2,   600] loss: 0.216\n",
      "[2,   800] loss: 0.131\n",
      "[2,  1000] loss: 0.156\n",
      "[2,  1200] loss: 0.176\n",
      "[2,  1400] loss: 0.122\n",
      "[2,  1600] loss: 0.140\n",
      "[2,  1800] loss: 0.139\n",
      "[2,  2000] loss: 0.177\n",
      "result of epoch 1accuracy is : 95 %\n",
      "[3,   200] loss: 0.141\n",
      "[3,   400] loss: 0.111\n",
      "[3,   600] loss: 0.119\n",
      "[3,   800] loss: 0.141\n",
      "[3,  1000] loss: 0.158\n",
      "[3,  1200] loss: 0.155\n",
      "[3,  1400] loss: 0.121\n",
      "[3,  1600] loss: 0.124\n",
      "[3,  1800] loss: 0.178\n",
      "[3,  2000] loss: 0.132\n",
      "result of epoch 2accuracy is : 95 %\n",
      "[4,   200] loss: 0.103\n",
      "[4,   400] loss: 0.129\n",
      "[4,   600] loss: 0.129\n",
      "[4,   800] loss: 0.134\n",
      "[4,  1000] loss: 0.149\n",
      "[4,  1200] loss: 0.120\n",
      "[4,  1400] loss: 0.122\n",
      "[4,  1600] loss: 0.124\n",
      "[4,  1800] loss: 0.124\n",
      "[4,  2000] loss: 0.136\n",
      "result of epoch 3accuracy is : 95 %\n",
      "[5,   200] loss: 0.112\n",
      "[5,   400] loss: 0.118\n",
      "[5,   600] loss: 0.107\n",
      "[5,   800] loss: 0.104\n",
      "[5,  1000] loss: 0.148\n",
      "[5,  1200] loss: 0.119\n",
      "[5,  1400] loss: 0.084\n",
      "[5,  1600] loss: 0.122\n",
      "[5,  1800] loss: 0.137\n",
      "[5,  2000] loss: 0.107\n",
      "result of epoch 4accuracy is : 95 %\n",
      "[6,   200] loss: 0.095\n",
      "[6,   400] loss: 0.087\n",
      "[6,   600] loss: 0.106\n",
      "[6,   800] loss: 0.101\n",
      "[6,  1000] loss: 0.107\n",
      "[6,  1200] loss: 0.129\n",
      "[6,  1400] loss: 0.118\n",
      "[6,  1600] loss: 0.113\n",
      "[6,  1800] loss: 0.117\n",
      "[6,  2000] loss: 0.133\n",
      "result of epoch 5accuracy is : 95 %\n",
      "[7,   200] loss: 0.125\n",
      "[7,   400] loss: 0.109\n",
      "[7,   600] loss: 0.127\n",
      "[7,   800] loss: 0.076\n",
      "[7,  1000] loss: 0.127\n",
      "[7,  1200] loss: 0.089\n",
      "[7,  1400] loss: 0.091\n",
      "[7,  1600] loss: 0.086\n",
      "[7,  1800] loss: 0.092\n",
      "[7,  2000] loss: 0.115\n",
      "result of epoch 6accuracy is : 92 %\n",
      "[8,   200] loss: 0.087\n",
      "[8,   400] loss: 0.063\n",
      "[8,   600] loss: 0.106\n",
      "[8,   800] loss: 0.102\n",
      "[8,  1000] loss: 0.108\n",
      "[8,  1200] loss: 0.100\n",
      "[8,  1400] loss: 0.077\n",
      "[8,  1600] loss: 0.130\n",
      "[8,  1800] loss: 0.079\n",
      "[8,  2000] loss: 0.119\n",
      "result of epoch 7accuracy is : 93 %\n",
      "[9,   200] loss: 0.100\n",
      "[9,   400] loss: 0.074\n",
      "[9,   600] loss: 0.085\n",
      "[9,   800] loss: 0.082\n",
      "[9,  1000] loss: 0.114\n",
      "[9,  1200] loss: 0.092\n",
      "[9,  1400] loss: 0.095\n",
      "[9,  1600] loss: 0.119\n",
      "[9,  1800] loss: 0.087\n",
      "[9,  2000] loss: 0.089\n",
      "result of epoch 8accuracy is : 93 %\n",
      "[10,   200] loss: 0.109\n",
      "[10,   400] loss: 0.110\n",
      "[10,   600] loss: 0.081\n",
      "[10,   800] loss: 0.076\n",
      "[10,  1000] loss: 0.068\n",
      "[10,  1200] loss: 0.106\n",
      "[10,  1400] loss: 0.092\n",
      "[10,  1600] loss: 0.092\n",
      "[10,  1800] loss: 0.098\n",
      "[10,  2000] loss: 0.086\n",
      "result of epoch 9accuracy is : 92 %\n",
      "[11,   200] loss: 0.090\n",
      "[11,   400] loss: 0.075\n",
      "[11,   600] loss: 0.079\n",
      "[11,   800] loss: 0.075\n",
      "[11,  1000] loss: 0.092\n",
      "[11,  1200] loss: 0.083\n",
      "[11,  1400] loss: 0.079\n",
      "[11,  1600] loss: 0.082\n",
      "[11,  1800] loss: 0.108\n",
      "[11,  2000] loss: 0.070\n",
      "result of epoch 10accuracy is : 92 %\n",
      "[12,   200] loss: 0.095\n",
      "[12,   400] loss: 0.091\n",
      "[12,   600] loss: 0.067\n",
      "[12,   800] loss: 0.078\n",
      "[12,  1000] loss: 0.097\n",
      "[12,  1200] loss: 0.060\n",
      "[12,  1400] loss: 0.088\n",
      "[12,  1600] loss: 0.078\n",
      "[12,  1800] loss: 0.078\n",
      "[12,  2000] loss: 0.070\n",
      "result of epoch 11accuracy is : 92 %\n",
      "[13,   200] loss: 0.078\n",
      "[13,   400] loss: 0.062\n",
      "[13,   600] loss: 0.059\n",
      "[13,   800] loss: 0.078\n",
      "[13,  1000] loss: 0.065\n",
      "[13,  1200] loss: 0.064\n",
      "[13,  1400] loss: 0.071\n",
      "[13,  1600] loss: 0.100\n",
      "[13,  1800] loss: 0.071\n",
      "[13,  2000] loss: 0.083\n",
      "result of epoch 12accuracy is : 92 %\n",
      "[14,   200] loss: 0.082\n",
      "[14,   400] loss: 0.074\n",
      "[14,   600] loss: 0.056\n",
      "[14,   800] loss: 0.052\n",
      "[14,  1000] loss: 0.074\n",
      "[14,  1200] loss: 0.088\n",
      "[14,  1400] loss: 0.064\n",
      "[14,  1600] loss: 0.086\n",
      "[14,  1800] loss: 0.069\n",
      "[14,  2000] loss: 0.072\n",
      "result of epoch 13accuracy is : 92 %\n",
      "[15,   200] loss: 0.089\n",
      "[15,   400] loss: 0.070\n",
      "[15,   600] loss: 0.067\n",
      "[15,   800] loss: 0.058\n",
      "[15,  1000] loss: 0.075\n",
      "[15,  1200] loss: 0.046\n",
      "[15,  1400] loss: 0.070\n",
      "[15,  1600] loss: 0.066\n",
      "[15,  1800] loss: 0.080\n",
      "[15,  2000] loss: 0.053\n",
      "result of epoch 14accuracy is : 92 %\n",
      "[16,   200] loss: 0.050\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[16,   400] loss: 0.078\n",
      "[16,   600] loss: 0.086\n",
      "[16,   800] loss: 0.084\n",
      "[16,  1000] loss: 0.052\n",
      "[16,  1200] loss: 0.045\n",
      "[16,  1400] loss: 0.063\n",
      "[16,  1600] loss: 0.056\n",
      "[16,  1800] loss: 0.073\n",
      "[16,  2000] loss: 0.068\n",
      "result of epoch 15accuracy is : 92 %\n",
      "[17,   200] loss: 0.089\n",
      "[17,   400] loss: 0.075\n",
      "[17,   600] loss: 0.071\n",
      "[17,   800] loss: 0.068\n",
      "[17,  1000] loss: 0.070\n",
      "[17,  1200] loss: 0.050\n",
      "[17,  1400] loss: 0.046\n",
      "[17,  1600] loss: 0.060\n",
      "[17,  1800] loss: 0.050\n",
      "[17,  2000] loss: 0.062\n",
      "result of epoch 16accuracy is : 92 %\n",
      "[18,   200] loss: 0.053\n",
      "[18,   400] loss: 0.059\n",
      "[18,   600] loss: 0.067\n",
      "[18,   800] loss: 0.054\n",
      "[18,  1000] loss: 0.068\n",
      "[18,  1200] loss: 0.067\n",
      "[18,  1400] loss: 0.068\n",
      "[18,  1600] loss: 0.056\n",
      "[18,  1800] loss: 0.044\n",
      "[18,  2000] loss: 0.061\n",
      "result of epoch 17accuracy is : 92 %\n",
      "[19,   200] loss: 0.052\n",
      "[19,   400] loss: 0.040\n",
      "[19,   600] loss: 0.073\n",
      "[19,   800] loss: 0.058\n",
      "[19,  1000] loss: 0.044\n",
      "[19,  1200] loss: 0.055\n",
      "[19,  1400] loss: 0.071\n",
      "[19,  1600] loss: 0.055\n",
      "[19,  1800] loss: 0.053\n",
      "[19,  2000] loss: 0.061\n",
      "result of epoch 18accuracy is : 92 %\n",
      "[20,   200] loss: 0.030\n",
      "[20,   400] loss: 0.053\n",
      "[20,   600] loss: 0.054\n",
      "[20,   800] loss: 0.041\n",
      "[20,  1000] loss: 0.060\n",
      "[20,  1200] loss: 0.056\n",
      "[20,  1400] loss: 0.060\n",
      "[20,  1600] loss: 0.049\n",
      "[20,  1800] loss: 0.064\n",
      "[20,  2000] loss: 0.060\n",
      "result of epoch 19accuracy is : 92 %\n",
      "key外观\n",
      "Finished Training\n"
     ]
    }
   ],
   "source": [
    "ii = 0\n",
    "import time\n",
    "for key in sub_set:\n",
    "    if ii == 10:\n",
    "        break\n",
    "    ii += 1\n",
    "    net = Net(pretrained, len(pretrained))\n",
    "    cur_max_acc = 0.0\n",
    "    print(net)\n",
    "    from torch import optim\n",
    "    criterion = nn.CrossEntropyLoss() # 交叉熵损失函数\n",
    "    optimizer = optim.Adagrad(net.parameters(), lr=0.01)#, momentum=0.9)\n",
    "    train_x, test_x, train_y, test_y = train_test_split(han_x, sub_set[key], test_size=0.01, random_state=42)\n",
    "    trainset = [(train_x[i], train_y[i]) for i in range(len(train_x))]\n",
    "    testset = [(test_x[i], test_y[i]) for i in range(len(test_x))]\n",
    "    trainloader = torch.utils.data.DataLoader(\n",
    "                        trainset, \n",
    "                        batch_size=4,\n",
    "                        shuffle=True, \n",
    "                        num_workers=2)\n",
    "    testloader = torch.utils.data.DataLoader(\n",
    "                        testset, \n",
    "                        batch_size=4,\n",
    "                        shuffle=False, \n",
    "                        num_workers=2)\n",
    "    torch.set_num_threads(8)\n",
    "    for epoch in range(20):  \n",
    "\n",
    "        running_loss = 0.0\n",
    "        for i, data in enumerate(trainloader, 0):\n",
    "\n",
    "            # 输入数据\n",
    "            inputs, labels = data\n",
    "            # 梯度清零\n",
    "            optimizer.zero_grad()\n",
    "            # forward + backward \n",
    "            va = [[word2ind[key]]]\n",
    "            va = torch.from_numpy(np.array(va))\n",
    "            outputs = net(inputs, va)\n",
    "            loss = criterion(outputs, labels)\n",
    "            loss.backward()   \n",
    "\n",
    "            # 更新参数 \n",
    "            optimizer.step()\n",
    "\n",
    "            # 打印log信息\n",
    "            # loss 是一个scalar,需要使用loss.item()来获取数值，不能使用loss[0]\n",
    "            running_loss += loss.item()\n",
    "            if i % 200 == 199: # 每200个batch打印一下训练状态\n",
    "                print('[%d, %5d] loss: %.3f' \\\n",
    "                      % (epoch+1, i+1, running_loss / 200))\n",
    "                running_loss = 0.0\n",
    "                \n",
    "        with torch.no_grad():\n",
    "            correct, total = 0, 0\n",
    "            for data in testloader:\n",
    "                images, labels = data\n",
    "                va = [[word2ind[key]]]\n",
    "                va = torch.from_numpy(np.array(va))\n",
    "                outputs = net(images,va)\n",
    "                _, predicted = torch.max(outputs, 1)\n",
    "                #import ipdb;ipdb.set_trace()\n",
    "                #res = res + [map_[int(predicted[i])] for i in range(len(predicted))]\n",
    "                total += labels.size(0)\n",
    "                correct += (predicted == labels).sum()\n",
    "            if cur_max_acc < float(100 * correct / total):\n",
    "                print('-------------cur max is ::::----------'+str(float(100 * correct / total)))\n",
    "                cur_max_acc = float(100 * correct / total)\n",
    "                torch.save(net, 'charresult/net' + key + '.pkl')  # 保存整个网络\n",
    "            print('result of epoch ' + str(epoch) + 'accuracy is : %d %%' % (100 * correct / total))\n",
    "\n",
    "    print('key' + key)\n",
    "    #net2 = torch.load('net.pkl')\n",
    "    #prediction = net2(x)\n",
    "    print('Finished Training')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "价格\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/works/dl-tools/anaconda2/envs/yxvenv/lib/python3.6/site-packages/ipykernel/__main__.py:73: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "配置\n",
      "操控\n",
      "舒适性\n",
      "油耗\n",
      "动力\n",
      "内饰\n",
      "安全性\n",
      "空间\n",
      "外观\n"
     ]
    }
   ],
   "source": [
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "result_set = {}\n",
    "testset = han_x_test\n",
    "testloader = torch.utils.data.DataLoader(\n",
    "                    testset, \n",
    "                    batch_size=4,\n",
    "                    shuffle=False, \n",
    "                    num_workers=2)\n",
    "for key in sub_set:\n",
    "    print(key)\n",
    "    res = []\n",
    "    with torch.no_grad():\n",
    "        correct, total = 0, 0\n",
    "        for data in testloader:\n",
    "            images = data\n",
    "            va = [[word2ind[key]]]\n",
    "            va = torch.from_numpy(np.array(va))\n",
    "            net = torch.load('charresult/net' + key + '.pkl')\n",
    "            outputs = net(images,va)\n",
    "            _, predicted = torch.max(outputs, 1)\n",
    "            res = res + [map_[int(predicted[i])] for i in range(len(predicted))]\n",
    "    result_set[key] = res\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "价格1273\n",
      "1014\n",
      "145\n",
      "114\n",
      "配置853\n",
      "579\n",
      "154\n",
      "120\n",
      "操控1036\n",
      "606\n",
      "124\n",
      "306\n",
      "舒适性931\n",
      "564\n",
      "256\n",
      "111\n",
      "油耗1082\n",
      "793\n",
      "138\n",
      "151\n",
      "动力2732\n",
      "1970\n",
      "378\n",
      "384\n",
      "内饰536\n",
      "271\n",
      "150\n",
      "115\n",
      "安全性573\n",
      "380\n",
      "93\n",
      "100\n",
      "空间442\n",
      "221\n",
      "67\n",
      "154\n",
      "外观489\n",
      "263\n",
      "111\n",
      "115\n"
     ]
    }
   ],
   "source": [
    "data = pd.read_csv('../../data/df_sen_sub/train.csv')\n",
    "uni_sub = data['subject'].unique()\n",
    "for key in uni_sub:\n",
    "    print(key + str(len(data[data['subject'] == key])))\n",
    "    ttt = data[data['subject'] == key]\n",
    "    print(len(ttt[ttt['sentiment_value'] == 0]))\n",
    "    print(len(ttt[ttt['sentiment_value'] == -1]))\n",
    "    print(len(ttt[ttt['sentiment_value'] == 1]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "real_pred = {}\n",
    "content_ids = []\n",
    "subjects = []\n",
    "sentiment_values = []\n",
    "sentiment_words = []\n",
    "contents = []\n",
    "#content_id,subject,sentiment_value,sentiment_word\n",
    "for i in range(len(test_data)):\n",
    "    content_id = test_data.loc[i, 'content_id']\n",
    "    flag = 0\n",
    "    for key in result_set:\n",
    "        if result_set[key][i] != '2':\n",
    "            flag = 1\n",
    "            content_ids.append(str(content_id))\n",
    "            subjects.append(key)\n",
    "            sentiment_values.append(int(result_set[key][i]))\n",
    "            sentiment_words.append(\"\")\n",
    "            contents.append(str(test_data.loc[i, 'content']))\n",
    "    if flag == 0:\n",
    "        content_ids.append(str(content_id))\n",
    "        subjects.append('动力')\n",
    "        sentiment_values.append(0)\n",
    "        sentiment_words.append(\"\")   \n",
    "        contents.append(str(test_data.loc[i, 'content']))\n",
    "real_pred = {\"content_id\":content_ids, \"subject\":subjects, \"sentiment_value\":sentiment_values, \"sentiment_word\":sentiment_words}\n",
    "real_df = pd.DataFrame(real_pred)\n",
    "real_df.to_csv('charresult/final_result++.csv', encoding = \"utf-8\", index = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(2573, 2364)"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(real_df), len(test_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "real_pred['content'] = contents\n",
    "\n",
    "dtt = pd.DataFrame(real_pred)\n",
    "dtt.to_csv('charresult/see_final_result++.csv', encoding = \"utf-8\", index = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "77"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(dtt[dtt['sentiment_value'] == -1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>content_id</th>\n",
       "      <th>subject</th>\n",
       "      <th>sentiment_value</th>\n",
       "      <th>sentiment_word</th>\n",
       "      <th>content</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>46</th>\n",
       "      <td>M3Hqx1Un8ygzFTtl</td>\n",
       "      <td>动力</td>\n",
       "      <td>1</td>\n",
       "      <td></td>\n",
       "      <td>我有一个朋友是玩越野的，一直不待见城市SUV的四驱性能，直到有一次一辆森林人跟着他们一起出去...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>67</th>\n",
       "      <td>sKPpYiV2bXWEjTLc</td>\n",
       "      <td>空间</td>\n",
       "      <td>1</td>\n",
       "      <td></td>\n",
       "      <td>q3呗。森林人倒是比q3空间大多了。</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>87</th>\n",
       "      <td>9Jt0O5d3s6wz1lkf</td>\n",
       "      <td>舒适性</td>\n",
       "      <td>1</td>\n",
       "      <td></td>\n",
       "      <td>腰不好还是别开车了，森林人坐着不舒服，这个级别就没有适合你的车了</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>102</th>\n",
       "      <td>SEFvD0TOQgnlJsWK</td>\n",
       "      <td>操控</td>\n",
       "      <td>1</td>\n",
       "      <td></td>\n",
       "      <td>我有一台老x1，2.0进口的，操控动力都挺不错的，新x1就算了，减配挺严重的，4s店都这么说。</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>108</th>\n",
       "      <td>WZmFIHJLqT3O1BVk</td>\n",
       "      <td>空间</td>\n",
       "      <td>1</td>\n",
       "      <td></td>\n",
       "      <td>现在大家有了孩子都买SUV车型，确实，后备箱，空间很大，利于平时家庭使用。</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>160</th>\n",
       "      <td>zXPLFe5Sqvc06RuG</td>\n",
       "      <td>空间</td>\n",
       "      <td>1</td>\n",
       "      <td></td>\n",
       "      <td>我个人觉得不是空间问题。只是更喜欢森林人外观。xv不太喜欢。但是价钱上面很是喜欢……我对空间...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>188</th>\n",
       "      <td>H6CfVzu4mLq0JkR7</td>\n",
       "      <td>操控</td>\n",
       "      <td>1</td>\n",
       "      <td></td>\n",
       "      <td>觉着不错！森林人是我的第四辆车！除了内饰看着一般外其他都不错！我也是试驾了所有同类别车后决定...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>199</th>\n",
       "      <td>8oeBjF7TwlPyLvcY</td>\n",
       "      <td>舒适性</td>\n",
       "      <td>1</td>\n",
       "      <td></td>\n",
       "      <td>总之除了森林人，其他车都比森林人舒适</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>207</th>\n",
       "      <td>qopu4EsiAz9KU7MC</td>\n",
       "      <td>空间</td>\n",
       "      <td>1</td>\n",
       "      <td></td>\n",
       "      <td>对后排空间要求不高一定是新款XV，新平台不一样</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>225</th>\n",
       "      <td>7duqegOxLs2Vo8XW</td>\n",
       "      <td>舒适性</td>\n",
       "      <td>1</td>\n",
       "      <td></td>\n",
       "      <td>想后排舒适就顶配奇骏吧，我就2.0后程超车费劲，那些说2.0也能跑180的滚粗，我也跑过18...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>229</th>\n",
       "      <td>axPES1MA7I8BlcvO</td>\n",
       "      <td>操控</td>\n",
       "      <td>1</td>\n",
       "      <td></td>\n",
       "      <td>的确如此。那时候的森林人，简单粗暴，操控不错，就是舒适性相对现在的而言，的确有些无法形容……...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>334</th>\n",
       "      <td>6GjoJk7wyDZVFQ3C</td>\n",
       "      <td>空间</td>\n",
       "      <td>1</td>\n",
       "      <td></td>\n",
       "      <td>我觉得内饰提升 空间变大是王道</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>349</th>\n",
       "      <td>cVlv8HZPjB6m4y75</td>\n",
       "      <td>空间</td>\n",
       "      <td>1</td>\n",
       "      <td></td>\n",
       "      <td>听老婆的吧。老婆满意，生活才能和谐。两个观点供您参考：1.一分钱一分货2.空间多大是个大呢？...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>411</th>\n",
       "      <td>DamKXCFiZHT37BGO</td>\n",
       "      <td>动力</td>\n",
       "      <td>1</td>\n",
       "      <td></td>\n",
       "      <td>一个是越野车，一个是城市SUV。比越野性能就不在同一个起跑线上，没法比的。H9是2.0T，要...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>413</th>\n",
       "      <td>E3NbgOkJ9tlinSDp</td>\n",
       "      <td>舒适性</td>\n",
       "      <td>1</td>\n",
       "      <td></td>\n",
       "      <td>建议购买傲虎，舒适性和安全性都高过森林人、隔音真的很好还有鹰眼系统。动力的话，建议选2.0T...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>414</th>\n",
       "      <td>E3NbgOkJ9tlinSDp</td>\n",
       "      <td>动力</td>\n",
       "      <td>1</td>\n",
       "      <td></td>\n",
       "      <td>建议购买傲虎，舒适性和安全性都高过森林人、隔音真的很好还有鹰眼系统。动力的话，建议选2.0T...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>435</th>\n",
       "      <td>CTatqAVoBvLW4GbM</td>\n",
       "      <td>操控</td>\n",
       "      <td>1</td>\n",
       "      <td></td>\n",
       "      <td>内饰：傲虎比森林人强些；操控：没太大区别，不过因为森林人车身短些，在城里穿梭森林人比傲虎灵活...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>436</th>\n",
       "      <td>CTatqAVoBvLW4GbM</td>\n",
       "      <td>舒适性</td>\n",
       "      <td>1</td>\n",
       "      <td></td>\n",
       "      <td>内饰：傲虎比森林人强些；操控：没太大区别，不过因为森林人车身短些，在城里穿梭森林人比傲虎灵活...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>438</th>\n",
       "      <td>Lxkirv1mpWqPR4SD</td>\n",
       "      <td>舒适性</td>\n",
       "      <td>1</td>\n",
       "      <td></td>\n",
       "      <td>傲虎好一些，适合旅行出去玩，舒适度，油耗，后期使用成本低。正常保养的话，费用也不多不到六百块...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>444</th>\n",
       "      <td>AzyW4NBUETH7vbgP</td>\n",
       "      <td>操控</td>\n",
       "      <td>1</td>\n",
       "      <td></td>\n",
       "      <td>虽然自己开的是sg9森，但也不能说瞎话，bmw其他不说，操控真是爆了森，3系没开过，开过“笨...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>446</th>\n",
       "      <td>MLKIN0SUHq5v8zYW</td>\n",
       "      <td>操控</td>\n",
       "      <td>1</td>\n",
       "      <td></td>\n",
       "      <td>12款森林人，现在越开越喜欢，特别是他的操控感。平时只需正常保养即可。</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>480</th>\n",
       "      <td>fRC3VjrYoL2OFZNz</td>\n",
       "      <td>操控</td>\n",
       "      <td>1</td>\n",
       "      <td></td>\n",
       "      <td>光有2.0排量确实欠考虑。你走量不反对，但是也要给大家选择吧。一辆空有操控没有动力的车只能算半残。</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>481</th>\n",
       "      <td>fRC3VjrYoL2OFZNz</td>\n",
       "      <td>动力</td>\n",
       "      <td>1</td>\n",
       "      <td></td>\n",
       "      <td>光有2.0排量确实欠考虑。你走量不反对，但是也要给大家选择吧。一辆空有操控没有动力的车只能算半残。</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>496</th>\n",
       "      <td>pLKVyHlB9n6Yr4XC</td>\n",
       "      <td>配置</td>\n",
       "      <td>1</td>\n",
       "      <td></td>\n",
       "      <td>你的要求，是配置高？还是排量大？又或是操控感好？</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>573</th>\n",
       "      <td>SNZAupTeyE8f3DOa</td>\n",
       "      <td>舒适性</td>\n",
       "      <td>1</td>\n",
       "      <td></td>\n",
       "      <td>看你的需求吧。看重机械性能还是森林人。要追求舒适静音跟内饰档次还是昂科威</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>591</th>\n",
       "      <td>7vM2TIJH9Qbe5qcN</td>\n",
       "      <td>空间</td>\n",
       "      <td>1</td>\n",
       "      <td></td>\n",
       "      <td>q3我也去试驾过，试了前驱的，空间比森小，视野不及森，动力1.5t的还算不错。不过价格去到2...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>710</th>\n",
       "      <td>Gi3vb2Ha0zCoTk75</td>\n",
       "      <td>操控</td>\n",
       "      <td>1</td>\n",
       "      <td></td>\n",
       "      <td>而且经常比森林人强不是非常正常吗，人家硬派越野。你让他跟森林人比比操控好不好啊</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>715</th>\n",
       "      <td>bEf1ZICFYTW97Lr6</td>\n",
       "      <td>空间</td>\n",
       "      <td>1</td>\n",
       "      <td></td>\n",
       "      <td>二十万哪是说存就存的。需要大空间车是拉货家用都能用的。现在君威太小了拉不了货。不然也不用着急...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>734</th>\n",
       "      <td>TfQUE3IXugtVsHFN</td>\n",
       "      <td>空间</td>\n",
       "      <td>1</td>\n",
       "      <td></td>\n",
       "      <td>问题指南是横置发动机，理论上侵占的空间应该更少。。。。</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>750</th>\n",
       "      <td>p2DgM5uoHAT9XPki</td>\n",
       "      <td>操控</td>\n",
       "      <td>1</td>\n",
       "      <td></td>\n",
       "      <td>应该要换轿车，重心低操控好，我喜欢低一点开车</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1602</th>\n",
       "      <td>k3dnRXbhuqiMje8D</td>\n",
       "      <td>操控</td>\n",
       "      <td>1</td>\n",
       "      <td></td>\n",
       "      <td>虽然我开了10多年车，但是一直不知道什么叫操控，只开过：五菱之光、昌河铃木利亚纳1.4手动、...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1656</th>\n",
       "      <td>pURWwJXEY9boHvLq</td>\n",
       "      <td>舒适性</td>\n",
       "      <td>1</td>\n",
       "      <td></td>\n",
       "      <td>普拉多硬派越野，动力大，载人多。但舒适性免谈！连x6也没森林人减震好！</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1657</th>\n",
       "      <td>pURWwJXEY9boHvLq</td>\n",
       "      <td>动力</td>\n",
       "      <td>1</td>\n",
       "      <td></td>\n",
       "      <td>普拉多硬派越野，动力大，载人多。但舒适性免谈！连x6也没森林人减震好！</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1690</th>\n",
       "      <td>3IULXkViPBDKYjvw</td>\n",
       "      <td>动力</td>\n",
       "      <td>1</td>\n",
       "      <td></td>\n",
       "      <td>是啊，动力搭配对四驱性能也很关键</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1710</th>\n",
       "      <td>5hscw7oaqFm3iCBx</td>\n",
       "      <td>操控</td>\n",
       "      <td>1</td>\n",
       "      <td></td>\n",
       "      <td>说的挺中肯的，果然是有过森林人的朋友，好多来这里黑森林人的，说宝马操控怎么怎么好，哈哈哈，你...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1739</th>\n",
       "      <td>0ZcJSahWkL3TmIzN</td>\n",
       "      <td>动力</td>\n",
       "      <td>1</td>\n",
       "      <td></td>\n",
       "      <td>排量差异看扭矩，扭矩直接反应加速性强弱，2.5满载我开着都感觉动力不太足，何况2.0。</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1804</th>\n",
       "      <td>78vjfAny6s9aIKmO</td>\n",
       "      <td>动力</td>\n",
       "      <td>1</td>\n",
       "      <td></td>\n",
       "      <td>途观还比森林人越野性能好点，这是我今年听到最大的笑话</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1830</th>\n",
       "      <td>01kgxZUTtfODp2hr</td>\n",
       "      <td>操控</td>\n",
       "      <td>1</td>\n",
       "      <td></td>\n",
       "      <td>斯巴鲁的操控确实不错，十一可以开着我斯巴鲁游玩了，走起来</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1850</th>\n",
       "      <td>sP2Ax8OS9bgIafqE</td>\n",
       "      <td>动力</td>\n",
       "      <td>1</td>\n",
       "      <td></td>\n",
       "      <td>斯巴鲁四驱是针对公路的，紧急并线驾驶极限比rav4高，内饰做工稍差……我是2.0的，4万公里...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1944</th>\n",
       "      <td>lwz4A0aUcGDJVOxX</td>\n",
       "      <td>舒适性</td>\n",
       "      <td>1</td>\n",
       "      <td></td>\n",
       "      <td>冷车怠速1900所以声音大，急加速肯定超1900了。森林人本来就是18-22万的平均隔音水准...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1964</th>\n",
       "      <td>oi3egvK85kdCLym4</td>\n",
       "      <td>空间</td>\n",
       "      <td>1</td>\n",
       "      <td></td>\n",
       "      <td>x1太小了，男人开确实不太适合，后排空间也比森小很多，有孩子以后会觉得后排空间还是很有用的，...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2018</th>\n",
       "      <td>ueY7R2gFVMB9bWvL</td>\n",
       "      <td>操控</td>\n",
       "      <td>1</td>\n",
       "      <td></td>\n",
       "      <td>傲虎舒适性更好，森林人通过性和操控更好。所以看你更看重哪一点？还是去试驾，坐进去感受一下再选择吧。</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2019</th>\n",
       "      <td>mreCtuKXFwYsi0z6</td>\n",
       "      <td>空间</td>\n",
       "      <td>1</td>\n",
       "      <td></td>\n",
       "      <td>多4公分能感觉宽多少？关键看造型，方正的森林人内部空间宽度比同级别的不差！锐界比汉兰达尺寸都...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2020</th>\n",
       "      <td>n2TZNWRdfSCilqLh</td>\n",
       "      <td>空间</td>\n",
       "      <td>1</td>\n",
       "      <td></td>\n",
       "      <td>汉兰达空间不差吧？汉兰达就是以空间大而著称的！</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2035</th>\n",
       "      <td>ciFVdL85Xfv0wEaN</td>\n",
       "      <td>动力</td>\n",
       "      <td>1</td>\n",
       "      <td></td>\n",
       "      <td>可靠性，较大的离地间隙，较轻的车重和比较好的操控，较强的越野能力。</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2045</th>\n",
       "      <td>isSJMTg0FcyKpOQH</td>\n",
       "      <td>动力</td>\n",
       "      <td>1</td>\n",
       "      <td></td>\n",
       "      <td>GT是伟大的旅行的缩写，动力操控长途旅行各方面吊打森林人，非要找缺点的话，森林人短些刨泥坑好...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2135</th>\n",
       "      <td>eCudFcjE3NyVaYtz</td>\n",
       "      <td>空间</td>\n",
       "      <td>1</td>\n",
       "      <td></td>\n",
       "      <td>车内空间还是比较完整，人扣上安全带应该没多大事。希望一直保持这安全水准，我也会一直追随！</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2165</th>\n",
       "      <td>j7FmnNEyAGBHTu51</td>\n",
       "      <td>操控</td>\n",
       "      <td>1</td>\n",
       "      <td></td>\n",
       "      <td>噪音大？不觉得！我开了三年，没觉得后悔，操控好，加速稳，还有，不是街车！</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2191</th>\n",
       "      <td>rJbkSWvNsAdq5uY0</td>\n",
       "      <td>舒适性</td>\n",
       "      <td>1</td>\n",
       "      <td></td>\n",
       "      <td>200t的价格比森林人高多了，没法比较吧…雷车豪华舒适，但论性能。森林人绝对不比它差。</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2199</th>\n",
       "      <td>bemz6FHr47lLEXqt</td>\n",
       "      <td>安全性</td>\n",
       "      <td>1</td>\n",
       "      <td></td>\n",
       "      <td>放中间系好安全带是很安全的，中间需要再买一条两边接头的安全带，绕过座椅扣到后座后面的卡扣，你...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2206</th>\n",
       "      <td>hz5flpCykL9qiSB8</td>\n",
       "      <td>操控</td>\n",
       "      <td>1</td>\n",
       "      <td></td>\n",
       "      <td>森林人轴距短，只有2.6米多，这才是所谓操控好主要的原因。</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2275</th>\n",
       "      <td>foxsAMS3TVwvdiPh</td>\n",
       "      <td>空间</td>\n",
       "      <td>1</td>\n",
       "      <td></td>\n",
       "      <td>宽适空间和较高配置的是年轻人选车的首选呀</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2367</th>\n",
       "      <td>3qravlupfdIAMznx</td>\n",
       "      <td>空间</td>\n",
       "      <td>1</td>\n",
       "      <td></td>\n",
       "      <td>出门自驾游还是森林人有优势，一是开长途空间大不容易疲劳，二是半拉子越野车（承载式车身经常能不...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2374</th>\n",
       "      <td>Q89PBCgxDdeJ5Vfn</td>\n",
       "      <td>操控</td>\n",
       "      <td>1</td>\n",
       "      <td></td>\n",
       "      <td>不好说是不是感觉的问题，森的内饰简单，操作单元少，但功能不缺失</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2379</th>\n",
       "      <td>aB6ythMmUQL4TneC</td>\n",
       "      <td>操控</td>\n",
       "      <td>1</td>\n",
       "      <td></td>\n",
       "      <td>没啥纠结的肯定森林人，性能出众。耐用性什么的都要比Jeep强太多......特别是Eyesi...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2380</th>\n",
       "      <td>aB6ythMmUQL4TneC</td>\n",
       "      <td>动力</td>\n",
       "      <td>1</td>\n",
       "      <td></td>\n",
       "      <td>没啥纠结的肯定森林人，性能出众。耐用性什么的都要比Jeep强太多......特别是Eyesi...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2391</th>\n",
       "      <td>h7Fx4nQTyPR2z9M6</td>\n",
       "      <td>动力</td>\n",
       "      <td>1</td>\n",
       "      <td></td>\n",
       "      <td>车身设计有一定的韧性，加强件增加的是车身的刚性。</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2485</th>\n",
       "      <td>6nulXChYs8biaKg7</td>\n",
       "      <td>操控</td>\n",
       "      <td>1</td>\n",
       "      <td></td>\n",
       "      <td>在公路操控还是马自达略胜半筹但是差别不大，然而到了烂路上就不一样了。森林人胜在全面。</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2504</th>\n",
       "      <td>nYqDJsS4CEVwAu8x</td>\n",
       "      <td>动力</td>\n",
       "      <td>1</td>\n",
       "      <td></td>\n",
       "      <td>老实说斯巴鲁不能越野，城市SUV都不能越野。不是大梁或者内嵌大梁，你车身会变形的。</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2568</th>\n",
       "      <td>IoKEnR3JdXu0gG4h</td>\n",
       "      <td>动力</td>\n",
       "      <td>1</td>\n",
       "      <td></td>\n",
       "      <td>我觉得斯巴鲁的CVT比奥迪的CVT还要好，新XV上的CVT更猛。已经习惯了CVT持续加速感后...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>91 rows × 5 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "            content_id subject  sentiment_value sentiment_word  \\\n",
       "46    M3Hqx1Un8ygzFTtl      动力                1                  \n",
       "67    sKPpYiV2bXWEjTLc      空间                1                  \n",
       "87    9Jt0O5d3s6wz1lkf     舒适性                1                  \n",
       "102   SEFvD0TOQgnlJsWK      操控                1                  \n",
       "108   WZmFIHJLqT3O1BVk      空间                1                  \n",
       "160   zXPLFe5Sqvc06RuG      空间                1                  \n",
       "188   H6CfVzu4mLq0JkR7      操控                1                  \n",
       "199   8oeBjF7TwlPyLvcY     舒适性                1                  \n",
       "207   qopu4EsiAz9KU7MC      空间                1                  \n",
       "225   7duqegOxLs2Vo8XW     舒适性                1                  \n",
       "229   axPES1MA7I8BlcvO      操控                1                  \n",
       "334   6GjoJk7wyDZVFQ3C      空间                1                  \n",
       "349   cVlv8HZPjB6m4y75      空间                1                  \n",
       "411   DamKXCFiZHT37BGO      动力                1                  \n",
       "413   E3NbgOkJ9tlinSDp     舒适性                1                  \n",
       "414   E3NbgOkJ9tlinSDp      动力                1                  \n",
       "435   CTatqAVoBvLW4GbM      操控                1                  \n",
       "436   CTatqAVoBvLW4GbM     舒适性                1                  \n",
       "438   Lxkirv1mpWqPR4SD     舒适性                1                  \n",
       "444   AzyW4NBUETH7vbgP      操控                1                  \n",
       "446   MLKIN0SUHq5v8zYW      操控                1                  \n",
       "480   fRC3VjrYoL2OFZNz      操控                1                  \n",
       "481   fRC3VjrYoL2OFZNz      动力                1                  \n",
       "496   pLKVyHlB9n6Yr4XC      配置                1                  \n",
       "573   SNZAupTeyE8f3DOa     舒适性                1                  \n",
       "591   7vM2TIJH9Qbe5qcN      空间                1                  \n",
       "710   Gi3vb2Ha0zCoTk75      操控                1                  \n",
       "715   bEf1ZICFYTW97Lr6      空间                1                  \n",
       "734   TfQUE3IXugtVsHFN      空间                1                  \n",
       "750   p2DgM5uoHAT9XPki      操控                1                  \n",
       "...                ...     ...              ...            ...   \n",
       "1602  k3dnRXbhuqiMje8D      操控                1                  \n",
       "1656  pURWwJXEY9boHvLq     舒适性                1                  \n",
       "1657  pURWwJXEY9boHvLq      动力                1                  \n",
       "1690  3IULXkViPBDKYjvw      动力                1                  \n",
       "1710  5hscw7oaqFm3iCBx      操控                1                  \n",
       "1739  0ZcJSahWkL3TmIzN      动力                1                  \n",
       "1804  78vjfAny6s9aIKmO      动力                1                  \n",
       "1830  01kgxZUTtfODp2hr      操控                1                  \n",
       "1850  sP2Ax8OS9bgIafqE      动力                1                  \n",
       "1944  lwz4A0aUcGDJVOxX     舒适性                1                  \n",
       "1964  oi3egvK85kdCLym4      空间                1                  \n",
       "2018  ueY7R2gFVMB9bWvL      操控                1                  \n",
       "2019  mreCtuKXFwYsi0z6      空间                1                  \n",
       "2020  n2TZNWRdfSCilqLh      空间                1                  \n",
       "2035  ciFVdL85Xfv0wEaN      动力                1                  \n",
       "2045  isSJMTg0FcyKpOQH      动力                1                  \n",
       "2135  eCudFcjE3NyVaYtz      空间                1                  \n",
       "2165  j7FmnNEyAGBHTu51      操控                1                  \n",
       "2191  rJbkSWvNsAdq5uY0     舒适性                1                  \n",
       "2199  bemz6FHr47lLEXqt     安全性                1                  \n",
       "2206  hz5flpCykL9qiSB8      操控                1                  \n",
       "2275  foxsAMS3TVwvdiPh      空间                1                  \n",
       "2367  3qravlupfdIAMznx      空间                1                  \n",
       "2374  Q89PBCgxDdeJ5Vfn      操控                1                  \n",
       "2379  aB6ythMmUQL4TneC      操控                1                  \n",
       "2380  aB6ythMmUQL4TneC      动力                1                  \n",
       "2391  h7Fx4nQTyPR2z9M6      动力                1                  \n",
       "2485  6nulXChYs8biaKg7      操控                1                  \n",
       "2504  nYqDJsS4CEVwAu8x      动力                1                  \n",
       "2568  IoKEnR3JdXu0gG4h      动力                1                  \n",
       "\n",
       "                                                content  \n",
       "46    我有一个朋友是玩越野的，一直不待见城市SUV的四驱性能，直到有一次一辆森林人跟着他们一起出去...  \n",
       "67                                   q3呗。森林人倒是比q3空间大多了。  \n",
       "87                     腰不好还是别开车了，森林人坐着不舒服，这个级别就没有适合你的车了  \n",
       "102     我有一台老x1，2.0进口的，操控动力都挺不错的，新x1就算了，减配挺严重的，4s店都这么说。  \n",
       "108               现在大家有了孩子都买SUV车型，确实，后备箱，空间很大，利于平时家庭使用。  \n",
       "160   我个人觉得不是空间问题。只是更喜欢森林人外观。xv不太喜欢。但是价钱上面很是喜欢……我对空间...  \n",
       "188   觉着不错！森林人是我的第四辆车！除了内饰看着一般外其他都不错！我也是试驾了所有同类别车后决定...  \n",
       "199                              总之除了森林人，其他车都比森林人舒适      \n",
       "207                             对后排空间要求不高一定是新款XV，新平台不一样  \n",
       "225   想后排舒适就顶配奇骏吧，我就2.0后程超车费劲，那些说2.0也能跑180的滚粗，我也跑过18...  \n",
       "229   的确如此。那时候的森林人，简单粗暴，操控不错，就是舒适性相对现在的而言，的确有些无法形容……...  \n",
       "334                                     我觉得内饰提升 空间变大是王道  \n",
       "349   听老婆的吧。老婆满意，生活才能和谐。两个观点供您参考：1.一分钱一分货2.空间多大是个大呢？...  \n",
       "411   一个是越野车，一个是城市SUV。比越野性能就不在同一个起跑线上，没法比的。H9是2.0T，要...  \n",
       "413   建议购买傲虎，舒适性和安全性都高过森林人、隔音真的很好还有鹰眼系统。动力的话，建议选2.0T...  \n",
       "414   建议购买傲虎，舒适性和安全性都高过森林人、隔音真的很好还有鹰眼系统。动力的话，建议选2.0T...  \n",
       "435   内饰：傲虎比森林人强些；操控：没太大区别，不过因为森林人车身短些，在城里穿梭森林人比傲虎灵活...  \n",
       "436   内饰：傲虎比森林人强些；操控：没太大区别，不过因为森林人车身短些，在城里穿梭森林人比傲虎灵活...  \n",
       "438   傲虎好一些，适合旅行出去玩，舒适度，油耗，后期使用成本低。正常保养的话，费用也不多不到六百块...  \n",
       "444   虽然自己开的是sg9森，但也不能说瞎话，bmw其他不说，操控真是爆了森，3系没开过，开过“笨...  \n",
       "446                 12款森林人，现在越开越喜欢，特别是他的操控感。平时只需正常保养即可。  \n",
       "480   光有2.0排量确实欠考虑。你走量不反对，但是也要给大家选择吧。一辆空有操控没有动力的车只能算半残。  \n",
       "481   光有2.0排量确实欠考虑。你走量不反对，但是也要给大家选择吧。一辆空有操控没有动力的车只能算半残。  \n",
       "496                            你的要求，是配置高？还是排量大？又或是操控感好？  \n",
       "573                看你的需求吧。看重机械性能还是森林人。要追求舒适静音跟内饰档次还是昂科威  \n",
       "591   q3我也去试驾过，试了前驱的，空间比森小，视野不及森，动力1.5t的还算不错。不过价格去到2...  \n",
       "710             而且经常比森林人强不是非常正常吗，人家硬派越野。你让他跟森林人比比操控好不好啊  \n",
       "715   二十万哪是说存就存的。需要大空间车是拉货家用都能用的。现在君威太小了拉不了货。不然也不用着急...  \n",
       "734                         问题指南是横置发动机，理论上侵占的空间应该更少。。。。  \n",
       "750                              应该要换轿车，重心低操控好，我喜欢低一点开车  \n",
       "...                                                 ...  \n",
       "1602  虽然我开了10多年车，但是一直不知道什么叫操控，只开过：五菱之光、昌河铃木利亚纳1.4手动、...  \n",
       "1656                普拉多硬派越野，动力大，载人多。但舒适性免谈！连x6也没森林人减震好！  \n",
       "1657                普拉多硬派越野，动力大，载人多。但舒适性免谈！连x6也没森林人减震好！  \n",
       "1690                               是啊，动力搭配对四驱性能也很关键      \n",
       "1710  说的挺中肯的，果然是有过森林人的朋友，好多来这里黑森林人的，说宝马操控怎么怎么好，哈哈哈，你...  \n",
       "1739        排量差异看扭矩，扭矩直接反应加速性强弱，2.5满载我开着都感觉动力不太足，何况2.0。  \n",
       "1804                         途观还比森林人越野性能好点，这是我今年听到最大的笑话  \n",
       "1830                       斯巴鲁的操控确实不错，十一可以开着我斯巴鲁游玩了，走起来  \n",
       "1850  斯巴鲁四驱是针对公路的，紧急并线驾驶极限比rav4高，内饰做工稍差……我是2.0的，4万公里...  \n",
       "1944  冷车怠速1900所以声音大，急加速肯定超1900了。森林人本来就是18-22万的平均隔音水准...  \n",
       "1964  x1太小了，男人开确实不太适合，后排空间也比森小很多，有孩子以后会觉得后排空间还是很有用的，...  \n",
       "2018  傲虎舒适性更好，森林人通过性和操控更好。所以看你更看重哪一点？还是去试驾，坐进去感受一下再选择吧。  \n",
       "2019  多4公分能感觉宽多少？关键看造型，方正的森林人内部空间宽度比同级别的不差！锐界比汉兰达尺寸都...  \n",
       "2020                         汉兰达空间不差吧？汉兰达就是以空间大而著称的！     \n",
       "2035                  可靠性，较大的离地间隙，较轻的车重和比较好的操控，较强的越野能力。  \n",
       "2045  GT是伟大的旅行的缩写，动力操控长途旅行各方面吊打森林人，非要找缺点的话，森林人短些刨泥坑好...  \n",
       "2135       车内空间还是比较完整，人扣上安全带应该没多大事。希望一直保持这安全水准，我也会一直追随！  \n",
       "2165            噪音大？不觉得！我开了三年，没觉得后悔，操控好，加速稳，还有，不是街车！     \n",
       "2191        200t的价格比森林人高多了，没法比较吧…雷车豪华舒适，但论性能。森林人绝对不比它差。  \n",
       "2199  放中间系好安全带是很安全的，中间需要再买一条两边接头的安全带，绕过座椅扣到后座后面的卡扣，你...  \n",
       "2206                      森林人轴距短，只有2.6米多，这才是所谓操控好主要的原因。  \n",
       "2275                               宽适空间和较高配置的是年轻人选车的首选呀  \n",
       "2367  出门自驾游还是森林人有优势，一是开长途空间大不容易疲劳，二是半拉子越野车（承载式车身经常能不...  \n",
       "2374                    不好说是不是感觉的问题，森的内饰简单，操作单元少，但功能不缺失  \n",
       "2379  没啥纠结的肯定森林人，性能出众。耐用性什么的都要比Jeep强太多......特别是Eyesi...  \n",
       "2380  没啥纠结的肯定森林人，性能出众。耐用性什么的都要比Jeep强太多......特别是Eyesi...  \n",
       "2391                           车身设计有一定的韧性，加强件增加的是车身的刚性。  \n",
       "2485         在公路操控还是马自达略胜半筹但是差别不大，然而到了烂路上就不一样了。森林人胜在全面。  \n",
       "2504          老实说斯巴鲁不能越野，城市SUV都不能越野。不是大梁或者内嵌大梁，你车身会变形的。  \n",
       "2568  我觉得斯巴鲁的CVT比奥迪的CVT还要好，新XV上的CVT更猛。已经习惯了CVT持续加速感后...  \n",
       "\n",
       "[91 rows x 5 columns]"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dtt[dtt['sentiment_value'] == 1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:yxvenv]",
   "language": "python",
   "name": "conda-env-yxvenv-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
