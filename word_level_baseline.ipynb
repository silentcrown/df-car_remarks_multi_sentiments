{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import torchvision as tv\n",
    "import jieba\n",
    "from gensim import models\n",
    "from gensim.models import Word2Vec\n",
    "import torchvision.transforms as transforms\n",
    "from torchvision.transforms import ToPILImage\n",
    "import torch\n",
    "show = ToPILImage() # 可以把Tensor转成Image，方便可视化\n",
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>content_id</th>\n",
       "      <th>content</th>\n",
       "      <th>subject</th>\n",
       "      <th>sentiment_value</th>\n",
       "      <th>sentiment_word</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>vUXizsqexyZVRdFH</td>\n",
       "      <td>因为森林人即将换代，这套系统没必要装在一款即将换代的车型上，因为肯定会影响价格。</td>\n",
       "      <td>价格</td>\n",
       "      <td>0</td>\n",
       "      <td>影响</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>4QroPd9hNfnCHVt7</td>\n",
       "      <td>四驱价格貌似挺高的，高的可以看齐XC60了，看实车前脸有点违和感。不过大众的车应该不会差。</td>\n",
       "      <td>价格</td>\n",
       "      <td>-1</td>\n",
       "      <td>高</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>QmqJ2AvM5GplaRyz</td>\n",
       "      <td>斯柯达要说质量，似乎比大众要好一点，价格也低一些，用料完全一样。我听说过野帝，但没听说过你说...</td>\n",
       "      <td>价格</td>\n",
       "      <td>1</td>\n",
       "      <td>低</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>KMT1gFJiU4NWrVDn</td>\n",
       "      <td>这玩意都是给有钱任性又不懂车的土豪用的，这价格换一次我妹夫EP020可以换三锅了</td>\n",
       "      <td>价格</td>\n",
       "      <td>-1</td>\n",
       "      <td>有钱任性</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>nVIlGd5yMmc37t1o</td>\n",
       "      <td>17价格忒高，估计也就是14-15左右。</td>\n",
       "      <td>价格</td>\n",
       "      <td>-1</td>\n",
       "      <td>高</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>TVciHBPL5XmUxMEd</td>\n",
       "      <td>我开始就是荣放2.5  森林人2.5二选一    荣放主要是底盘质感不行   太硬  其次是...</td>\n",
       "      <td>价格</td>\n",
       "      <td>1</td>\n",
       "      <td>便宜</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>4lb9TsO5rjqUy1Bu</td>\n",
       "      <td>唉，这货的价格死硬死硬的，低配版优惠1万据说已经罕有了。</td>\n",
       "      <td>价格</td>\n",
       "      <td>-1</td>\n",
       "      <td>死硬</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>z98xV7MphZIF4EvO</td>\n",
       "      <td>价格的话只能说一般般吧，太仓前段时间定的比你便宜！</td>\n",
       "      <td>价格</td>\n",
       "      <td>0</td>\n",
       "      <td>一般</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>hoWrMnGTUvdsK3Dm</td>\n",
       "      <td>听过，价格太贵，但一直念念不忘</td>\n",
       "      <td>价格</td>\n",
       "      <td>-1</td>\n",
       "      <td>贵</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>r1WHgbI0ZKqMdELy</td>\n",
       "      <td>恭喜恭喜，这个优惠不错哦！</td>\n",
       "      <td>价格</td>\n",
       "      <td>1</td>\n",
       "      <td>优惠不错</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>JSQUo6kblXYvtc2h</td>\n",
       "      <td>优惠幅度不小了，北京优惠八千</td>\n",
       "      <td>价格</td>\n",
       "      <td>1</td>\n",
       "      <td>优惠幅度不小</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>7kCF590PjAYqzEL6</td>\n",
       "      <td>优惠可以了！购进吧！买了不会后悔的！时间可鉴！</td>\n",
       "      <td>价格</td>\n",
       "      <td>1</td>\n",
       "      <td>不会后悔</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>EXBiRczhIu3paJWb</td>\n",
       "      <td>现在 什么价 优惠多少</td>\n",
       "      <td>价格</td>\n",
       "      <td>0</td>\n",
       "      <td>优惠</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>nQ0bIZtzj6P1Esgd</td>\n",
       "      <td>优惠一万一 送贴膜装甲脚垫 铁西庞大</td>\n",
       "      <td>价格</td>\n",
       "      <td>0</td>\n",
       "      <td>优惠</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>JvXIqLT8cGDuPEWe</td>\n",
       "      <td>我也大连的，最近也考虑入手森林人，优惠太小了</td>\n",
       "      <td>价格</td>\n",
       "      <td>-1</td>\n",
       "      <td>优惠太小</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>NXyGEbt0AZ5rHJ3e</td>\n",
       "      <td>山东威海全系这才优惠3000，MD</td>\n",
       "      <td>价格</td>\n",
       "      <td>-1</td>\n",
       "      <td>才优惠</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>kN0LghcimajxWwH8</td>\n",
       "      <td>下手了，豪导特供，优惠1.6万</td>\n",
       "      <td>价格</td>\n",
       "      <td>0</td>\n",
       "      <td>优惠</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>vVoKucJy5pO0jSk2</td>\n",
       "      <td>优惠了8000，什么都不送。</td>\n",
       "      <td>价格</td>\n",
       "      <td>0</td>\n",
       "      <td>优惠</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>iBFJMqHtTRD5Qo6S</td>\n",
       "      <td>兄弟2.5豪导特供优惠1.6万可以下手吗？</td>\n",
       "      <td>价格</td>\n",
       "      <td>0</td>\n",
       "      <td>优惠</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>G8Yr51elsVaXFUZC</td>\n",
       "      <td>恭喜，优惠多少，我准备明天去提，2.5特装优惠两万</td>\n",
       "      <td>价格</td>\n",
       "      <td>0</td>\n",
       "      <td>优惠</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>10WF8Q53pVfOryvA</td>\n",
       "      <td>什么车款，多少优惠啊？康桥我只能谈到优惠1.5其他还送什么没问，试驾了一次看了两次2.0时尚...</td>\n",
       "      <td>价格</td>\n",
       "      <td>0</td>\n",
       "      <td>优惠</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>VrRd1HcoMNAkvhJy</td>\n",
       "      <td>优惠1 ，就送行程记录</td>\n",
       "      <td>价格</td>\n",
       "      <td>0</td>\n",
       "      <td>优惠</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>1BYpO9FsgkmWLNQu</td>\n",
       "      <td>平常心吧，我本来想买傲虎，优惠不大，钱不够，改提森林人，6月提尊贵优惠1.4w，到了9月做活...</td>\n",
       "      <td>价格</td>\n",
       "      <td>0</td>\n",
       "      <td>优惠</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>9EFImNb0ywhHBlcR</td>\n",
       "      <td>哈哈，25.48。优惠够给力</td>\n",
       "      <td>价格</td>\n",
       "      <td>0</td>\n",
       "      <td>优惠</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>2aNFSuYeZo7B1b9R</td>\n",
       "      <td>兄弟，我也云南的，你的优惠也挺大的，现在哪里来的全系3万啊。。。现傲虎全系无优惠，森林人才八...</td>\n",
       "      <td>价格</td>\n",
       "      <td>-1</td>\n",
       "      <td>才</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>4EK1Nu7X2DTzomRS</td>\n",
       "      <td>来湖北，我上月订的2.0蓝色时尚，优惠1万3送6次保养，本月底提车</td>\n",
       "      <td>价格</td>\n",
       "      <td>0</td>\n",
       "      <td>优惠</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26</th>\n",
       "      <td>TWPEyNaI5mFgYupn</td>\n",
       "      <td>什么都没有，就是现金优惠和给了点小东西</td>\n",
       "      <td>价格</td>\n",
       "      <td>0</td>\n",
       "      <td>优惠</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27</th>\n",
       "      <td>96A5VQfBgPWUYkul</td>\n",
       "      <td>什么都没有，就是现金优惠和给了点小东西，你最好先问问看有没有车</td>\n",
       "      <td>价格</td>\n",
       "      <td>0</td>\n",
       "      <td>优惠</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28</th>\n",
       "      <td>JXlEzBcKGpI8stdr</td>\n",
       "      <td>原来最低也就优惠15000至16000</td>\n",
       "      <td>价格</td>\n",
       "      <td>0</td>\n",
       "      <td>优惠</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29</th>\n",
       "      <td>P5A3evWb9jUyHMB2</td>\n",
       "      <td>我们这里，优惠2000，我呵呵了</td>\n",
       "      <td>价格</td>\n",
       "      <td>-1</td>\n",
       "      <td>呵呵</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9917</th>\n",
       "      <td>NtDO9KM2TQJYp8rC</td>\n",
       "      <td>风噪大 音响差驾驶什么的，秒杀其他</td>\n",
       "      <td>舒适性</td>\n",
       "      <td>-1</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9918</th>\n",
       "      <td>lsMktgZyBDUfbowu</td>\n",
       "      <td>安全大于一切，出远门前一定要检查车子，主要有全车油水，轮胎，刹车系统等。</td>\n",
       "      <td>安全性</td>\n",
       "      <td>1</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9919</th>\n",
       "      <td>hwzJjbCV26pLscxk</td>\n",
       "      <td>发动机直接就不一样了 FA20是斯巴鲁的招牌发动机 给WRX用要是烧的厉害那帮暴力驾驶的估计...</td>\n",
       "      <td>动力</td>\n",
       "      <td>-1</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9920</th>\n",
       "      <td>6FMslAfukBpR82Po</td>\n",
       "      <td>看路况，省道多平均油耗8-9，市区多11-12</td>\n",
       "      <td>油耗</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9921</th>\n",
       "      <td>7X9tyquOCj0aw2Ql</td>\n",
       "      <td>换挡不是根据速度，而是根据你的意图。你想省油并匀速驾驶，就在转速允许的情况档位越高越好。想要...</td>\n",
       "      <td>动力</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9922</th>\n",
       "      <td>7X9tyquOCj0aw2Ql</td>\n",
       "      <td>换挡不是根据速度，而是根据你的意图。你想省油并匀速驾驶，就在转速允许的情况档位越高越好。想要...</td>\n",
       "      <td>安全性</td>\n",
       "      <td>1</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9923</th>\n",
       "      <td>QBGuT7YNWVDsXgb8</td>\n",
       "      <td>同款配置黑森还要下个月中旬才能提车</td>\n",
       "      <td>配置</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9924</th>\n",
       "      <td>goheSWvcEPp79Lm6</td>\n",
       "      <td>正常，我城里跑油耗11</td>\n",
       "      <td>油耗</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9925</th>\n",
       "      <td>pdjz83AoiWvu1lbh</td>\n",
       "      <td>森林人做工一般，配置还不如8、9万的国产车，这是事实。在老家侄儿子的五菱宏光把我的森林人给甩...</td>\n",
       "      <td>配置</td>\n",
       "      <td>-1</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9926</th>\n",
       "      <td>pdjz83AoiWvu1lbh</td>\n",
       "      <td>森林人做工一般，配置还不如8、9万的国产车，这是事实。在老家侄儿子的五菱宏光把我的森林人给甩...</td>\n",
       "      <td>内饰</td>\n",
       "      <td>-1</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9927</th>\n",
       "      <td>K9s7OTLiCMm1dvzH</td>\n",
       "      <td>导航已经换成凯立德了，其它的功能也很差，我只是用来听收音机，导航还是手机的好</td>\n",
       "      <td>配置</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9928</th>\n",
       "      <td>wpHCZYOSrmske3yW</td>\n",
       "      <td>有没有换过导航啥的，一般新车很少电路故障，行车电脑问题几率大点！</td>\n",
       "      <td>配置</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9929</th>\n",
       "      <td>I5NyHgsnkWvj84di</td>\n",
       "      <td>感觉稍微有点高了，油耗高低和很多方面有关，比如你个人驾驶习惯，你行驶道路拥堵状况等等，平稳驾...</td>\n",
       "      <td>油耗</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9930</th>\n",
       "      <td>AoZJqK17aOz4UfxX</td>\n",
       "      <td>选12款之前的。12款后都是fb发动机， 机油消耗大。</td>\n",
       "      <td>动力</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9931</th>\n",
       "      <td>cQlpvPRdOwUXaVkh</td>\n",
       "      <td>跟欧蓝德的调校很相似啊，掌握规律后，堵车时跟车，可减少踩刹车的次数</td>\n",
       "      <td>安全性</td>\n",
       "      <td>1</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9932</th>\n",
       "      <td>QVf8TWXrIPDwEgNU</td>\n",
       "      <td>哈哈哈，欧兰德也能上来跟森比，那破车你开几年试试，那操控也能比</td>\n",
       "      <td>操控</td>\n",
       "      <td>-1</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9933</th>\n",
       "      <td>dr1QZyaGWbI2BKxz</td>\n",
       "      <td>14款2.0，大连，七万多公里了，平均油耗10。</td>\n",
       "      <td>油耗</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9934</th>\n",
       "      <td>hMZEBAwkNz8Du714</td>\n",
       "      <td>森林人2.0开了两年，一直在中石化加油站加92#，没啥问题，杠杠的，夏天开空调油耗8.5左右。</td>\n",
       "      <td>油耗</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9935</th>\n",
       "      <td>hMZEBAwkNz8Du714</td>\n",
       "      <td>森林人2.0开了两年，一直在中石化加油站加92#，没啥问题，杠杠的，夏天开空调油耗8.5左右。</td>\n",
       "      <td>舒适性</td>\n",
       "      <td>1</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9936</th>\n",
       "      <td>d4aM8HCr5VisWlfU</td>\n",
       "      <td>国内轮胎的品牌还是比较多的，看你要准备用什么价位的了，一般来说声音越小的价格也就高些。</td>\n",
       "      <td>价格</td>\n",
       "      <td>-1</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9937</th>\n",
       "      <td>9oHZT5rXOjauPA7V</td>\n",
       "      <td>我的也这样，换刹车片后消失</td>\n",
       "      <td>安全性</td>\n",
       "      <td>1</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9938</th>\n",
       "      <td>wlSvQOt3Kz2ekbcg</td>\n",
       "      <td>反正我是不会去了，除非关健部位如变速箱油</td>\n",
       "      <td>动力</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9939</th>\n",
       "      <td>ELB0ZT5CvK9Fok4H</td>\n",
       "      <td>我感觉你的油耗稍大些，我这里山东，最冷零下18度，最高6度或者0度左右，也是16款2.0的，...</td>\n",
       "      <td>油耗</td>\n",
       "      <td>-1</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9940</th>\n",
       "      <td>vdDQXJEg3wSj84er</td>\n",
       "      <td>我的方向盘也是两边缝不一样大</td>\n",
       "      <td>操控</td>\n",
       "      <td>-1</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9941</th>\n",
       "      <td>hUSkd6ptCbfxMPo8</td>\n",
       "      <td>俺必须的说，15公里以上的上下班单程行程，很少红灯，80左右的速度……对小森是极好的……所以...</td>\n",
       "      <td>油耗</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9942</th>\n",
       "      <td>VywQTI4iLuzd1DZ3</td>\n",
       "      <td>老铁没毛病...双击666！！！是不是这样？我这理解逻辑也挑不出毛病吧！你不矫情你试试？多大...</td>\n",
       "      <td>外观</td>\n",
       "      <td>1</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9943</th>\n",
       "      <td>Ufv6VpyNaGnShzlJ</td>\n",
       "      <td>2.0时尚，四川这段时间温度最低-1，基本上下班用，现在均速18，表显油耗9.2</td>\n",
       "      <td>油耗</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9944</th>\n",
       "      <td>S8tmC0gxyBjzvLuN</td>\n",
       "      <td>相貌不起眼，内饰太平淡，开起来才知道好</td>\n",
       "      <td>内饰</td>\n",
       "      <td>-1</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9945</th>\n",
       "      <td>vpaS3ueRQi2rhAgH</td>\n",
       "      <td>一看就知道山寨的！用的肯定是中控的普通视频输入接口而已，这种无屏的记录仪淘宝也就一两百块的东...</td>\n",
       "      <td>配置</td>\n",
       "      <td>-1</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9946</th>\n",
       "      <td>5R0ZoOdv8H2MNGgt</td>\n",
       "      <td>楼主还在吗，同在上海，想咨询一下家用首辆车，到底是买森林人还是力狮好？如果森林人，2.0的动...</td>\n",
       "      <td>动力</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>9947 rows × 5 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "            content_id                                            content  \\\n",
       "0     vUXizsqexyZVRdFH           因为森林人即将换代，这套系统没必要装在一款即将换代的车型上，因为肯定会影响价格。   \n",
       "1     4QroPd9hNfnCHVt7      四驱价格貌似挺高的，高的可以看齐XC60了，看实车前脸有点违和感。不过大众的车应该不会差。   \n",
       "2     QmqJ2AvM5GplaRyz  斯柯达要说质量，似乎比大众要好一点，价格也低一些，用料完全一样。我听说过野帝，但没听说过你说...   \n",
       "3     KMT1gFJiU4NWrVDn           这玩意都是给有钱任性又不懂车的土豪用的，这价格换一次我妹夫EP020可以换三锅了   \n",
       "4     nVIlGd5yMmc37t1o                            17价格忒高，估计也就是14-15左右。      \n",
       "5     TVciHBPL5XmUxMEd  我开始就是荣放2.5  森林人2.5二选一    荣放主要是底盘质感不行   太硬  其次是...   \n",
       "6     4lb9TsO5rjqUy1Bu                   唉，这货的价格死硬死硬的，低配版优惠1万据说已经罕有了。       \n",
       "7     z98xV7MphZIF4EvO                      价格的话只能说一般般吧，太仓前段时间定的比你便宜！       \n",
       "8     hoWrMnGTUvdsK3Dm                                听过，价格太贵，但一直念念不忘       \n",
       "9     r1WHgbI0ZKqMdELy                                      恭喜恭喜，这个优惠不错哦！   \n",
       "10    JSQUo6kblXYvtc2h                                     优惠幅度不小了，北京优惠八千   \n",
       "11    7kCF590PjAYqzEL6                         优惠可以了！购进吧！买了不会后悔的！时间可鉴！      \n",
       "12    EXBiRczhIu3paJWb                                        现在 什么价 优惠多少   \n",
       "13    nQ0bIZtzj6P1Esgd                                 优惠一万一 送贴膜装甲脚垫 铁西庞大   \n",
       "14    JvXIqLT8cGDuPEWe                             我也大连的，最近也考虑入手森林人，优惠太小了   \n",
       "15    NXyGEbt0AZ5rHJ3e                                  山东威海全系这才优惠3000，MD   \n",
       "16    kN0LghcimajxWwH8                                    下手了，豪导特供，优惠1.6万   \n",
       "17    vVoKucJy5pO0jSk2                                 优惠了8000，什么都不送。       \n",
       "18    iBFJMqHtTRD5Qo6S                          兄弟2.5豪导特供优惠1.6万可以下手吗？       \n",
       "19    G8Yr51elsVaXFUZC                          恭喜，优惠多少，我准备明天去提，2.5特装优惠两万   \n",
       "20    10WF8Q53pVfOryvA  什么车款，多少优惠啊？康桥我只能谈到优惠1.5其他还送什么没问，试驾了一次看了两次2.0时尚...   \n",
       "21    VrRd1HcoMNAkvhJy                                   优惠1 ，就送行程记录        \n",
       "22    1BYpO9FsgkmWLNQu  平常心吧，我本来想买傲虎，优惠不大，钱不够，改提森林人，6月提尊贵优惠1.4w，到了9月做活...   \n",
       "23    9EFImNb0ywhHBlcR                                 哈哈，25.48。优惠够给力       \n",
       "24    2aNFSuYeZo7B1b9R  兄弟，我也云南的，你的优惠也挺大的，现在哪里来的全系3万啊。。。现傲虎全系无优惠，森林人才八...   \n",
       "25    4EK1Nu7X2DTzomRS                  来湖北，我上月订的2.0蓝色时尚，优惠1万3送6次保养，本月底提车   \n",
       "26    TWPEyNaI5mFgYupn                            什么都没有，就是现金优惠和给了点小东西       \n",
       "27    96A5VQfBgPWUYkul                什么都没有，就是现金优惠和给了点小东西，你最好先问问看有没有车       \n",
       "28    JXlEzBcKGpI8stdr                             原来最低也就优惠15000至16000      \n",
       "29    P5A3evWb9jUyHMB2                                   我们这里，优惠2000，我呵呵了   \n",
       "...                ...                                                ...   \n",
       "9917  NtDO9KM2TQJYp8rC                                  风噪大 音响差驾驶什么的，秒杀其他   \n",
       "9918  lsMktgZyBDUfbowu               安全大于一切，出远门前一定要检查车子，主要有全车油水，轮胎，刹车系统等。   \n",
       "9919  hwzJjbCV26pLscxk  发动机直接就不一样了 FA20是斯巴鲁的招牌发动机 给WRX用要是烧的厉害那帮暴力驾驶的估计...   \n",
       "9920  6FMslAfukBpR82Po                            看路况，省道多平均油耗8-9，市区多11-12   \n",
       "9921  7X9tyquOCj0aw2Ql  换挡不是根据速度，而是根据你的意图。你想省油并匀速驾驶，就在转速允许的情况档位越高越好。想要...   \n",
       "9922  7X9tyquOCj0aw2Ql  换挡不是根据速度，而是根据你的意图。你想省油并匀速驾驶，就在转速允许的情况档位越高越好。想要...   \n",
       "9923  QBGuT7YNWVDsXgb8                                  同款配置黑森还要下个月中旬才能提车   \n",
       "9924  goheSWvcEPp79Lm6                                        正常，我城里跑油耗11   \n",
       "9925  pdjz83AoiWvu1lbh  森林人做工一般，配置还不如8、9万的国产车，这是事实。在老家侄儿子的五菱宏光把我的森林人给甩...   \n",
       "9926  pdjz83AoiWvu1lbh  森林人做工一般，配置还不如8、9万的国产车，这是事实。在老家侄儿子的五菱宏光把我的森林人给甩...   \n",
       "9927  K9s7OTLiCMm1dvzH             导航已经换成凯立德了，其它的功能也很差，我只是用来听收音机，导航还是手机的好   \n",
       "9928  wpHCZYOSrmske3yW                   有没有换过导航啥的，一般新车很少电路故障，行车电脑问题几率大点！   \n",
       "9929  I5NyHgsnkWvj84di  感觉稍微有点高了，油耗高低和很多方面有关，比如你个人驾驶习惯，你行驶道路拥堵状况等等，平稳驾...   \n",
       "9930  AoZJqK17aOz4UfxX                        选12款之前的。12款后都是fb发动机， 机油消耗大。   \n",
       "9931  cQlpvPRdOwUXaVkh                  跟欧蓝德的调校很相似啊，掌握规律后，堵车时跟车，可减少踩刹车的次数   \n",
       "9932  QVf8TWXrIPDwEgNU                    哈哈哈，欧兰德也能上来跟森比，那破车你开几年试试，那操控也能比   \n",
       "9933  dr1QZyaGWbI2BKxz                           14款2.0，大连，七万多公里了，平均油耗10。   \n",
       "9934  hMZEBAwkNz8Du714    森林人2.0开了两年，一直在中石化加油站加92#，没啥问题，杠杠的，夏天开空调油耗8.5左右。   \n",
       "9935  hMZEBAwkNz8Du714    森林人2.0开了两年，一直在中石化加油站加92#，没啥问题，杠杠的，夏天开空调油耗8.5左右。   \n",
       "9936  d4aM8HCr5VisWlfU        国内轮胎的品牌还是比较多的，看你要准备用什么价位的了，一般来说声音越小的价格也就高些。   \n",
       "9937  9oHZT5rXOjauPA7V                                      我的也这样，换刹车片后消失   \n",
       "9938  wlSvQOt3Kz2ekbcg                               反正我是不会去了，除非关健部位如变速箱油   \n",
       "9939  ELB0ZT5CvK9Fok4H  我感觉你的油耗稍大些，我这里山东，最冷零下18度，最高6度或者0度左右，也是16款2.0的，...   \n",
       "9940  vdDQXJEg3wSj84er                                     我的方向盘也是两边缝不一样大   \n",
       "9941  hUSkd6ptCbfxMPo8  俺必须的说，15公里以上的上下班单程行程，很少红灯，80左右的速度……对小森是极好的……所以...   \n",
       "9942  VywQTI4iLuzd1DZ3  老铁没毛病...双击666！！！是不是这样？我这理解逻辑也挑不出毛病吧！你不矫情你试试？多大...   \n",
       "9943  Ufv6VpyNaGnShzlJ           2.0时尚，四川这段时间温度最低-1，基本上下班用，现在均速18，表显油耗9.2   \n",
       "9944  S8tmC0gxyBjzvLuN                                相貌不起眼，内饰太平淡，开起来才知道好   \n",
       "9945  vpaS3ueRQi2rhAgH  一看就知道山寨的！用的肯定是中控的普通视频输入接口而已，这种无屏的记录仪淘宝也就一两百块的东...   \n",
       "9946  5R0ZoOdv8H2MNGgt  楼主还在吗，同在上海，想咨询一下家用首辆车，到底是买森林人还是力狮好？如果森林人，2.0的动...   \n",
       "\n",
       "     subject  sentiment_value sentiment_word  \n",
       "0         价格                0             影响  \n",
       "1         价格               -1              高  \n",
       "2         价格                1              低  \n",
       "3         价格               -1           有钱任性  \n",
       "4         价格               -1              高  \n",
       "5         价格                1             便宜  \n",
       "6         价格               -1             死硬  \n",
       "7         价格                0             一般  \n",
       "8         价格               -1              贵  \n",
       "9         价格                1           优惠不错  \n",
       "10        价格                1         优惠幅度不小  \n",
       "11        价格                1           不会后悔  \n",
       "12        价格                0             优惠  \n",
       "13        价格                0             优惠  \n",
       "14        价格               -1           优惠太小  \n",
       "15        价格               -1            才优惠  \n",
       "16        价格                0             优惠  \n",
       "17        价格                0             优惠  \n",
       "18        价格                0             优惠  \n",
       "19        价格                0             优惠  \n",
       "20        价格                0             优惠  \n",
       "21        价格                0             优惠  \n",
       "22        价格                0             优惠  \n",
       "23        价格                0             优惠  \n",
       "24        价格               -1              才  \n",
       "25        价格                0             优惠  \n",
       "26        价格                0             优惠  \n",
       "27        价格                0             优惠  \n",
       "28        价格                0             优惠  \n",
       "29        价格               -1             呵呵  \n",
       "...      ...              ...            ...  \n",
       "9917     舒适性               -1            NaN  \n",
       "9918     安全性                1            NaN  \n",
       "9919      动力               -1            NaN  \n",
       "9920      油耗                0            NaN  \n",
       "9921      动力                0            NaN  \n",
       "9922     安全性                1            NaN  \n",
       "9923      配置                0            NaN  \n",
       "9924      油耗                0            NaN  \n",
       "9925      配置               -1            NaN  \n",
       "9926      内饰               -1            NaN  \n",
       "9927      配置                0            NaN  \n",
       "9928      配置                0            NaN  \n",
       "9929      油耗                0            NaN  \n",
       "9930      动力                0            NaN  \n",
       "9931     安全性                1            NaN  \n",
       "9932      操控               -1            NaN  \n",
       "9933      油耗                0            NaN  \n",
       "9934      油耗                0            NaN  \n",
       "9935     舒适性                1            NaN  \n",
       "9936      价格               -1            NaN  \n",
       "9937     安全性                1            NaN  \n",
       "9938      动力                0            NaN  \n",
       "9939      油耗               -1            NaN  \n",
       "9940      操控               -1            NaN  \n",
       "9941      油耗                0            NaN  \n",
       "9942      外观                1            NaN  \n",
       "9943      油耗                0            NaN  \n",
       "9944      内饰               -1            NaN  \n",
       "9945      配置               -1            NaN  \n",
       "9946      动力                0            NaN  \n",
       "\n",
       "[9947 rows x 5 columns]"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data = pd.read_csv('../../data/df_sen_sub/train.csv')\n",
    "data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"\\ndata = pd.read_csv('../../data/df_sen_sub/train.csv')\\nlen(data['content_id'].unique()), len(list(data['content_id']))\\ncontent_ids = data['content_id'].unique()\\nsubjs = data['subject'].unique()\\ndf = {}\\ntext, subs, sentis = [], [], []\\nfor i in range(len(content_ids)):\\n    if i % 100 == 0:print(i)\\n    dd = data[data['content_id'] == content_ids[i]]\\n    text.append(dd.loc[dd.index.tolist()[0], 'content'])\\n    temp_subs, temp_senti = [], []\\n    for sub in subjs:\\n        temp_subs.append(sub)\\n        if len(dd[dd['subject'] == sub]) != 0:\\n            temp_senti.append(str(int(dd[dd['subject'] == sub]['sentiment_value'])))\\n        else:\\n            temp_senti.append('2')\\n    subs.append(','.join(temp_subs))\\n    sentis.append(','.join(temp_senti))\\ndf['content'] = text\\ndf['subjects'] = subs\\ndf['sentiments'] = sentis\\ndf = pd.DataFrame(df)\\ndf.to_csv('../../data/df_sen_sub/merge_train.csv', index = False)\\n#data = pd.read_csv('../../data/df_sen_sub/test_public.csv')\\n\""
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "'''\n",
    "data = pd.read_csv('../../data/df_sen_sub/train.csv')\n",
    "len(data['content_id'].unique()), len(list(data['content_id']))\n",
    "content_ids = data['content_id'].unique()\n",
    "subjs = data['subject'].unique()\n",
    "df = {}\n",
    "text, subs, sentis = [], [], []\n",
    "for i in range(len(content_ids)):\n",
    "    if i % 100 == 0:print(i)\n",
    "    dd = data[data['content_id'] == content_ids[i]]\n",
    "    text.append(dd.loc[dd.index.tolist()[0], 'content'])\n",
    "    temp_subs, temp_senti = [], []\n",
    "    for sub in subjs:\n",
    "        temp_subs.append(sub)\n",
    "        if len(dd[dd['subject'] == sub]) != 0:\n",
    "            temp_senti.append(str(int(dd[dd['subject'] == sub]['sentiment_value'])))\n",
    "        else:\n",
    "            temp_senti.append('2')\n",
    "    subs.append(','.join(temp_subs))\n",
    "    sentis.append(','.join(temp_senti))\n",
    "df['content'] = text\n",
    "df['subjects'] = subs\n",
    "df['sentiments'] = sentis\n",
    "df = pd.DataFrame(df)\n",
    "df.to_csv('../../data/df_sen_sub/merge_train.csv', index = False)\n",
    "#data = pd.read_csv('../../data/df_sen_sub/test_public.csv')\n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = pd.read_csv('../../data/df_sen_sub/merge_train.csv')\n",
    "data = data.fillna('')\n",
    "subs = list(data['subjects'])\n",
    "sentiments = list(data['sentiments'])\n",
    "content = list(data['content'])\n",
    "test_data = pd.read_csv('../../data/df_sen_sub/test_public.csv')\n",
    "test_data = test_data.fillna('')\n",
    "test_content = list(test_data['content'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Building prefix dict from the default dictionary ...\n",
      "Loading model from cache /tmp/jieba.cache\n",
      "Loading model cost 0.985 seconds.\n",
      "Prefix dict has been built succesfully.\n"
     ]
    }
   ],
   "source": [
    "with open('../../data/df_sen_sub/add_text.txt','w') as f:\n",
    "    f.write('\\n'.join(list(content) + list(test_content)  + list(subs)))\n",
    "# 迭代器，使用jieba将句子进行分词\n",
    "class Sentences(object):# 这个类可以根据实际情况重写，我已经将所有的文章进行分句，并整合到了一个文件里面\n",
    "    def __init__(self, dirname):\n",
    "        self.dirname = dirname # 句子所在文件，没句句子占一行\n",
    "        #jieba.load_userdict(\"wordBase.txt\") # 加载词库\n",
    "\n",
    "    def __iter__(self):\n",
    "        #for fname in os.listdir(self.dirname):\n",
    "        for line in open(self.dirname):\n",
    "                line = line.replace('\\n', '')\n",
    "                yield list(jieba.cut(line))\n",
    "\n",
    "sentences = []\n",
    "def train_word2vec(folder_path, size=100):\n",
    "    global sentences\n",
    "    sentences = Sentences(folder_path) #生成分词后的句子，是一个二维数组\n",
    "\n",
    "    # size是词向量长度\n",
    "    # worker是线程数量，建议与物理线程数量一致\n",
    "    # min_count是指出现次数小于一定程度，就忽略，0表示不忽略\n",
    "    #model = Word2Vec(sentences, size=size, workers=8, min_count=0)\n",
    "\n",
    "    # 训练结束就将模型保存起来\n",
    "    #model.save(\"../../data/df_sen_sub/add_word2vec_model\")\n",
    "\n",
    "# 生成50维度的词向量模型\n",
    "train_word2vec(\"../../data/df_sen_sub/add_text.txt\",100)\n",
    "\n",
    "# 测试训练好的词向量模型，使用model[keyWord]即可获取keyword这个词的词向量\n",
    "model = Word2Vec.load(\"../../data/df_sen_sub/add_word2vec_model\")\n",
    "sentences = list(sentences)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/works/dl-tools/anaconda2/envs/yxvenv/lib/python3.6/site-packages/ipykernel/__main__.py:14: DeprecationWarning: Call to deprecated `__getitem__` (Method will be removed in 4.0.0, use self.wv.__getitem__() instead).\n",
      "/home/works/dl-tools/anaconda2/envs/yxvenv/lib/python3.6/site-packages/ipykernel/__main__.py:18: DeprecationWarning: Call to deprecated `__getitem__` (Method will be removed in 4.0.0, use self.wv.__getitem__() instead).\n",
      "/home/works/dl-tools/anaconda2/envs/yxvenv/lib/python3.6/site-packages/ipykernel/__main__.py:34: DeprecationWarning: Call to deprecated `__getitem__` (Method will be removed in 4.0.0, use self.wv.__getitem__() instead).\n",
      "/home/works/dl-tools/anaconda2/envs/yxvenv/lib/python3.6/site-packages/ipykernel/__main__.py:30: DeprecationWarning: Call to deprecated `__getitem__` (Method will be removed in 4.0.0, use self.wv.__getitem__() instead).\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(8290, 50, 100) (2364, 50, 100)\n"
     ]
    }
   ],
   "source": [
    "x_vecs = []\n",
    "x_test_vecs = []  \n",
    "ind = 0\n",
    "word2ind = {}\n",
    "pretrained = []\n",
    "senti_sen = []\n",
    "senti_test_sen = []\n",
    "for i in range(len(sentences) - len(content)):\n",
    "    if i < len(content):\n",
    "        temp = []\n",
    "        t_s = []\n",
    "        for j in range(len(sentences[i])):\n",
    "            if sentences[i][j] not in word2ind:\n",
    "                pretrained.append(model[sentences[i][j]])\n",
    "                word2ind[sentences[i][j]] = ind\n",
    "                ind += 1\n",
    "            t_s.append(sentences[i][j])\n",
    "            temp.append(model[sentences[i][j]])\n",
    "        while len(temp) < 50:\n",
    "            temp.append([0.0] * 100)\n",
    "        if len(temp) > 50:\n",
    "            temp = temp[:50]\n",
    "        x_vecs.append(temp)\n",
    "        senti_sen.append(t_s[:50])\n",
    "    else:\n",
    "        temp = []\n",
    "        t_s = []\n",
    "        for j in range(len(sentences[i])):\n",
    "            if sentences[i][j] not in word2ind:\n",
    "                pretrained.append(model[sentences[i][j]])\n",
    "                word2ind[sentences[i][j]] = ind\n",
    "                ind += 1\n",
    "            t_s.append(sentences[i][j])\n",
    "            temp.append(model[sentences[i][j]])\n",
    "        while len(temp) < 50:\n",
    "            temp.append([0.0] * 100)\n",
    "        if len(temp) > 50:\n",
    "            temp = temp[:50]\n",
    "        x_test_vecs.append(temp)\n",
    "        senti_test_sen.append(t_s[:50])     \n",
    "x_vecs = np.array(x_vecs)\n",
    "x_test_vecs = np.array(x_test_vecs)\n",
    "print(x_vecs.shape, x_test_vecs.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "#va, content_vecs, y\n",
    "pretrained.append([0.0] * 100)\n",
    "word2ind['null'] = 17387\n",
    "map_ = ['-1', '0', '1', '2']\n",
    "sub_set = {}\n",
    "for i in range(len(subs)):\n",
    "    subjs = subs[i].split(',')\n",
    "    sentis = sentiments[i].split(',')\n",
    "    for j in range(len(subjs)):\n",
    "        if subjs[j] not in sub_set:\n",
    "            sub_set[subjs[j]] = []\n",
    "        sub_set[subjs[j]].append(map_.index(sentis[j]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "pretrained = np.array(pretrained)\n",
    "han_x = []\n",
    "for i in range(len(senti_sen)):\n",
    "    temp = []\n",
    "    for j in range(len(senti_sen[i])):\n",
    "        temp.append(word2ind[senti_sen[i][j]])\n",
    "    while len(temp) < 50:\n",
    "        temp.append(17387)\n",
    "\n",
    "    temp = temp[:50]\n",
    "\n",
    "    han_x.append(temp)\n",
    "han_x = np.array(han_x)\n",
    "\n",
    "han_x_test = []\n",
    "for i in range(len(senti_test_sen)):\n",
    "    temp = []\n",
    "    for j in range(len(senti_test_sen[i])):\n",
    "        temp.append(word2ind[senti_test_sen[i][j]])\n",
    "    while len(temp) < 50:\n",
    "        temp.append(17387)\n",
    "\n",
    "    temp = temp[:50]\n",
    "\n",
    "    han_x_test.append(temp)\n",
    "han_x = np.array(han_x)\n",
    "han_x_test = np.array(han_x_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "'''\n",
    "class Net(nn.Module):\n",
    "    def __init__(self, pretrained, vocab_size):\n",
    "        super(Net, self).__init__()\n",
    "        self.bilstm = nn.LSTM(input_size = 100, hidden_size = 100, bidirectional = True) \n",
    "        #self.fc1   = nn.Linear(3750, 50) \n",
    "        #self.fc2   = nn.Linear(200, 50)\n",
    "        #self.fc3   = nn.Linear(200, 50)\n",
    "        #self.fc4   = nn.Linear(100, 3)\n",
    "        self.fctest   = nn.Linear(200, 3)\n",
    "        self.embeddings = nn.Embedding(vocab_size, 100)\n",
    "        pretrained_weight = np.array(pretrained)\n",
    "        self.embeddings.weight.data.copy_(torch.from_numpy(pretrained_weight))\n",
    "        \n",
    "    def forward(self, x, aspects): \n",
    "        x = self.embeddings(x)#batch,50,100\n",
    "        #va = self.embeddings(aspects[0])\n",
    "        #t_va = va.unsqueeze(0).expand(x.shape[0], x.shape[1], 100)\n",
    "        output, (hn, cn) =  self.bilstm(x.float())#batch,50,200\n",
    "        H, hN = output, output[:,-1,:]\n",
    "        #con = torch.cat((t_va, H), 2)\n",
    "        #t1 = F.max_pool2d(F.relu(con), (1, 4))\n",
    "        #con = t1.view(x.size()[0], -1)\n",
    "        #con = F.relu(self.fc1(con))\n",
    "        #alpha = con.unsqueeze(1)\n",
    "        #rr = torch.matmul(alpha,H).squeeze(1)\n",
    "        #yy = torch.cat((F.relu(self.fc2(rr)), F.relu(self.fc3(hN))), 1)\n",
    "        #x = self.fc4(yy)\n",
    "        x  = self.fctest(hN)\n",
    "        return x\n",
    "    \n",
    "\n",
    "net = Net(pretrained, len(pretrained))\n",
    "print(net)\n",
    "from torch import optim\n",
    "criterion = nn.CrossEntropyLoss() # 交叉熵损失函数\n",
    "optimizer = optim.SGD(net.parameters(), lr=0.005, momentum=0.9)\n",
    "'''\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "\n",
    "class Net(nn.Module):\n",
    "    def __init__(self, pretrained, vocab_size):\n",
    "        super(Net, self).__init__()\n",
    "        #self.rnn1 = nn.RNN(100, 100) \n",
    "        self.bilstm = nn.LSTM(input_size = 100, hidden_size = 100, bidirectional = True)\n",
    "        #self.fc1   = nn.Linear(1250, 120) \n",
    "        self.fch = nn.Linear(200, 100)\n",
    "        self.fcv = nn.Linear(100, 100)\n",
    "        self.fcw = nn.Linear(200, 1)\n",
    "        self.fcwp = nn.Linear(200,50)\n",
    "        self.fcwh = nn.Linear(200,50)\n",
    "        self.fc1   = nn.Linear(3750, 120) \n",
    "        self.fc2   = nn.Linear(120, 50)\n",
    "        self.fc3   = nn.Linear(50, 4)\n",
    "        self.embeddings = nn.Embedding(vocab_size, 100)\n",
    "        pretrained_weight = np.array(pretrained)\n",
    "        self.embeddings.weight.data.copy_(torch.from_numpy(pretrained_weight))\n",
    "        \n",
    "    def forward(self, x, aspects): \n",
    "        x = self.embeddings(x) #[4,50,100]\n",
    "        batch_size = x.shape[0]\n",
    "        N = x.shape[1]\n",
    "        output, (hn, cn) =  self.bilstm(x.float())  #[4,50,200]\n",
    "        hN = output[:,-1,:]\n",
    "        va = self.embeddings(aspects[0]) #[1, 100]\n",
    "        t_va = torch.matmul(torch.ones((x.shape[0],50, 1)), va)#[4, 50, 100]\n",
    "        t_va = t_va.reshape((-1, 100)) #[4*50, 100]\n",
    "        x = output.reshape((-1, 200)) #[4*50, 200]\n",
    "        x = torch.tanh(torch.cat((self.fch(x), self.fcv(t_va)), 1))\n",
    "        M = x.reshape((batch_size, N, -1)) #[4, 50, 200]\n",
    "        alpha = F.softmax(self.fcw(M)).reshape((batch_size, 1, -1))#[4,50]\n",
    "        rr = torch.matmul(alpha, output).reshape((batch_size, -1)) #[4, 200]\n",
    "        final = torch.tanh(self.fcwh(hN) + self.fcwp(rr))\n",
    "        x = self.fc3(final)   \n",
    "        return x\n",
    "    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Net(\n",
      "  (bilstm): LSTM(100, 100, bidirectional=True)\n",
      "  (fch): Linear(in_features=200, out_features=100, bias=True)\n",
      "  (fcv): Linear(in_features=100, out_features=100, bias=True)\n",
      "  (fcw): Linear(in_features=200, out_features=1, bias=True)\n",
      "  (fcwp): Linear(in_features=200, out_features=50, bias=True)\n",
      "  (fcwh): Linear(in_features=200, out_features=50, bias=True)\n",
      "  (fc1): Linear(in_features=3750, out_features=120, bias=True)\n",
      "  (fc2): Linear(in_features=120, out_features=50, bias=True)\n",
      "  (fc3): Linear(in_features=50, out_features=4, bias=True)\n",
      "  (embeddings): Embedding(19791, 100)\n",
      ")\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/works/dl-tools/anaconda2/envs/yxvenv/lib/python3.6/site-packages/ipykernel/__main__.py:73: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1,   200] loss: 0.524\n",
      "[1,   400] loss: 0.509\n",
      "[1,   600] loss: 0.482\n",
      "[1,   800] loss: 0.332\n",
      "[1,  1000] loss: 0.317\n",
      "[1,  1200] loss: 0.222\n",
      "[1,  1400] loss: 0.225\n",
      "[1,  1600] loss: 0.256\n",
      "[1,  1800] loss: 0.244\n",
      "[1,  2000] loss: 0.268\n",
      "-------------cur max is ::::----------93.0\n",
      "result of epoch 0accuracy is : 93 %\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/works/dl-tools/anaconda2/envs/yxvenv/lib/python3.6/site-packages/torch/serialization.py:241: UserWarning: Couldn't retrieve source code for container of type Net. It won't be checked for correctness upon loading.\n",
      "  \"type \" + obj.__name__ + \". It won't be checked \"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[2,   200] loss: 0.195\n",
      "[2,   400] loss: 0.218\n",
      "[2,   600] loss: 0.207\n",
      "[2,   800] loss: 0.183\n",
      "[2,  1000] loss: 0.205\n",
      "[2,  1200] loss: 0.200\n",
      "[2,  1400] loss: 0.234\n",
      "[2,  1600] loss: 0.206\n",
      "[2,  1800] loss: 0.182\n",
      "[2,  2000] loss: 0.275\n",
      "-------------cur max is ::::----------95.0\n",
      "result of epoch 1accuracy is : 95 %\n",
      "[3,   200] loss: 0.179\n",
      "[3,   400] loss: 0.170\n",
      "[3,   600] loss: 0.216\n",
      "[3,   800] loss: 0.221\n",
      "[3,  1000] loss: 0.176\n",
      "[3,  1200] loss: 0.190\n",
      "[3,  1400] loss: 0.160\n",
      "[3,  1600] loss: 0.199\n",
      "[3,  1800] loss: 0.178\n",
      "[3,  2000] loss: 0.156\n",
      "result of epoch 2accuracy is : 92 %\n",
      "[4,   200] loss: 0.138\n",
      "[4,   400] loss: 0.188\n",
      "[4,   600] loss: 0.153\n",
      "[4,   800] loss: 0.197\n",
      "[4,  1000] loss: 0.137\n",
      "[4,  1200] loss: 0.183\n",
      "[4,  1400] loss: 0.161\n",
      "[4,  1600] loss: 0.170\n",
      "[4,  1800] loss: 0.130\n",
      "[4,  2000] loss: 0.163\n",
      "result of epoch 3accuracy is : 93 %\n",
      "[5,   200] loss: 0.139\n",
      "[5,   400] loss: 0.140\n",
      "[5,   600] loss: 0.137\n",
      "[5,   800] loss: 0.112\n",
      "[5,  1000] loss: 0.182\n",
      "[5,  1200] loss: 0.132\n",
      "[5,  1400] loss: 0.135\n",
      "[5,  1600] loss: 0.125\n",
      "[5,  1800] loss: 0.148\n",
      "[5,  2000] loss: 0.150\n",
      "result of epoch 4accuracy is : 92 %\n",
      "[6,   200] loss: 0.116\n",
      "[6,   400] loss: 0.108\n",
      "[6,   600] loss: 0.124\n",
      "[6,   800] loss: 0.136\n",
      "[6,  1000] loss: 0.121\n",
      "[6,  1200] loss: 0.108\n",
      "[6,  1400] loss: 0.131\n",
      "[6,  1600] loss: 0.117\n",
      "[6,  1800] loss: 0.104\n",
      "[6,  2000] loss: 0.135\n",
      "result of epoch 5accuracy is : 92 %\n",
      "[7,   200] loss: 0.110\n",
      "[7,   400] loss: 0.091\n",
      "[7,   600] loss: 0.107\n",
      "[7,   800] loss: 0.103\n",
      "[7,  1000] loss: 0.111\n",
      "[7,  1200] loss: 0.090\n",
      "[7,  1400] loss: 0.107\n",
      "[7,  1600] loss: 0.088\n",
      "[7,  1800] loss: 0.110\n",
      "[7,  2000] loss: 0.110\n",
      "result of epoch 6accuracy is : 92 %\n",
      "[8,   200] loss: 0.090\n",
      "[8,   400] loss: 0.114\n",
      "[8,   600] loss: 0.071\n",
      "[8,   800] loss: 0.078\n",
      "[8,  1000] loss: 0.087\n",
      "[8,  1200] loss: 0.111\n",
      "[8,  1400] loss: 0.065\n",
      "[8,  1600] loss: 0.099\n",
      "[8,  1800] loss: 0.080\n",
      "[8,  2000] loss: 0.075\n",
      "result of epoch 7accuracy is : 92 %\n",
      "[9,   200] loss: 0.082\n",
      "[9,   400] loss: 0.091\n",
      "[9,   600] loss: 0.070\n",
      "[9,   800] loss: 0.070\n",
      "[9,  1000] loss: 0.099\n",
      "[9,  1200] loss: 0.094\n",
      "[9,  1400] loss: 0.055\n",
      "[9,  1600] loss: 0.054\n",
      "[9,  1800] loss: 0.072\n",
      "[9,  2000] loss: 0.089\n",
      "result of epoch 8accuracy is : 91 %\n",
      "[10,   200] loss: 0.077\n",
      "[10,   400] loss: 0.059\n",
      "[10,   600] loss: 0.062\n",
      "[10,   800] loss: 0.055\n",
      "[10,  1000] loss: 0.047\n",
      "[10,  1200] loss: 0.069\n",
      "[10,  1400] loss: 0.065\n",
      "[10,  1600] loss: 0.070\n",
      "[10,  1800] loss: 0.058\n",
      "[10,  2000] loss: 0.067\n",
      "result of epoch 9accuracy is : 90 %\n",
      "[11,   200] loss: 0.063\n",
      "[11,   400] loss: 0.066\n",
      "[11,   600] loss: 0.058\n",
      "[11,   800] loss: 0.039\n",
      "[11,  1000] loss: 0.060\n",
      "[11,  1200] loss: 0.053\n",
      "[11,  1400] loss: 0.038\n",
      "[11,  1600] loss: 0.044\n",
      "[11,  1800] loss: 0.043\n",
      "[11,  2000] loss: 0.069\n",
      "result of epoch 10accuracy is : 93 %\n",
      "[12,   200] loss: 0.049\n",
      "[12,   400] loss: 0.060\n",
      "[12,   600] loss: 0.057\n",
      "[12,   800] loss: 0.045\n",
      "[12,  1000] loss: 0.037\n",
      "[12,  1200] loss: 0.055\n",
      "[12,  1400] loss: 0.040\n",
      "[12,  1600] loss: 0.053\n",
      "[12,  1800] loss: 0.044\n",
      "[12,  2000] loss: 0.046\n",
      "result of epoch 11accuracy is : 91 %\n",
      "[13,   200] loss: 0.044\n",
      "[13,   400] loss: 0.045\n",
      "[13,   600] loss: 0.030\n",
      "[13,   800] loss: 0.025\n",
      "[13,  1000] loss: 0.044\n",
      "[13,  1200] loss: 0.043\n",
      "[13,  1400] loss: 0.039\n",
      "[13,  1600] loss: 0.037\n",
      "[13,  1800] loss: 0.050\n",
      "[13,  2000] loss: 0.055\n",
      "result of epoch 12accuracy is : 93 %\n",
      "[14,   200] loss: 0.047\n",
      "[14,   400] loss: 0.036\n",
      "[14,   600] loss: 0.028\n",
      "[14,   800] loss: 0.035\n",
      "[14,  1000] loss: 0.041\n",
      "[14,  1200] loss: 0.035\n",
      "[14,  1400] loss: 0.041\n",
      "[14,  1600] loss: 0.034\n",
      "[14,  1800] loss: 0.033\n",
      "[14,  2000] loss: 0.044\n",
      "result of epoch 13accuracy is : 95 %\n",
      "[15,   200] loss: 0.028\n",
      "[15,   400] loss: 0.037\n",
      "[15,   600] loss: 0.023\n",
      "[15,   800] loss: 0.035\n",
      "[15,  1000] loss: 0.028\n",
      "[15,  1200] loss: 0.048\n",
      "[15,  1400] loss: 0.031\n",
      "[15,  1600] loss: 0.036\n",
      "[15,  1800] loss: 0.034\n",
      "[15,  2000] loss: 0.032\n",
      "result of epoch 14accuracy is : 93 %\n",
      "[16,   200] loss: 0.025\n",
      "[16,   400] loss: 0.022\n",
      "[16,   600] loss: 0.029\n",
      "[16,   800] loss: 0.029\n",
      "[16,  1000] loss: 0.029\n",
      "[16,  1200] loss: 0.035\n",
      "[16,  1400] loss: 0.027\n",
      "[16,  1600] loss: 0.045\n",
      "[16,  1800] loss: 0.023\n",
      "[16,  2000] loss: 0.027\n",
      "result of epoch 15accuracy is : 92 %\n",
      "[17,   200] loss: 0.028\n",
      "[17,   400] loss: 0.025\n",
      "[17,   600] loss: 0.017\n",
      "[17,   800] loss: 0.029\n",
      "[17,  1000] loss: 0.022\n",
      "[17,  1200] loss: 0.013\n",
      "[17,  1400] loss: 0.023\n",
      "[17,  1600] loss: 0.024\n",
      "[17,  1800] loss: 0.035\n",
      "[17,  2000] loss: 0.028\n",
      "result of epoch 16accuracy is : 91 %\n",
      "[18,   200] loss: 0.015\n",
      "[18,   400] loss: 0.021\n",
      "[18,   600] loss: 0.013\n",
      "[18,   800] loss: 0.025\n",
      "[18,  1000] loss: 0.025\n",
      "[18,  1200] loss: 0.022\n",
      "[18,  1400] loss: 0.021\n",
      "[18,  1600] loss: 0.033\n",
      "[18,  1800] loss: 0.029\n",
      "[18,  2000] loss: 0.036\n",
      "result of epoch 17accuracy is : 93 %\n",
      "[19,   200] loss: 0.022\n",
      "[19,   400] loss: 0.021\n",
      "[19,   600] loss: 0.022\n",
      "[19,   800] loss: 0.029\n",
      "[19,  1000] loss: 0.010\n",
      "[19,  1200] loss: 0.023\n",
      "[19,  1400] loss: 0.028\n",
      "[19,  1600] loss: 0.023\n",
      "[19,  1800] loss: 0.025\n",
      "[19,  2000] loss: 0.025\n",
      "result of epoch 18accuracy is : 93 %\n",
      "[20,   200] loss: 0.020\n",
      "[20,   400] loss: 0.019\n",
      "[20,   600] loss: 0.020\n",
      "[20,   800] loss: 0.015\n",
      "[20,  1000] loss: 0.024\n",
      "[20,  1200] loss: 0.024\n",
      "[20,  1400] loss: 0.017\n",
      "[20,  1600] loss: 0.028\n",
      "[20,  1800] loss: 0.014\n",
      "[20,  2000] loss: 0.017\n",
      "result of epoch 19accuracy is : 93 %\n",
      "key价格\n",
      "Finished Training\n",
      "Net(\n",
      "  (bilstm): LSTM(100, 100, bidirectional=True)\n",
      "  (fch): Linear(in_features=200, out_features=100, bias=True)\n",
      "  (fcv): Linear(in_features=100, out_features=100, bias=True)\n",
      "  (fcw): Linear(in_features=200, out_features=1, bias=True)\n",
      "  (fcwp): Linear(in_features=200, out_features=50, bias=True)\n",
      "  (fcwh): Linear(in_features=200, out_features=50, bias=True)\n",
      "  (fc1): Linear(in_features=3750, out_features=120, bias=True)\n",
      "  (fc2): Linear(in_features=120, out_features=50, bias=True)\n",
      "  (fc3): Linear(in_features=50, out_features=4, bias=True)\n",
      "  (embeddings): Embedding(19791, 100)\n",
      ")\n",
      "[1,   200] loss: 0.447\n",
      "[1,   400] loss: 0.405\n",
      "[1,   600] loss: 0.483\n",
      "[1,   800] loss: 0.399\n",
      "[1,  1000] loss: 0.457\n",
      "[1,  1200] loss: 0.418\n",
      "[1,  1400] loss: 0.340\n",
      "[1,  1600] loss: 0.371\n",
      "[1,  1800] loss: 0.373\n",
      "[1,  2000] loss: 0.306\n",
      "-------------cur max is ::::----------90.0\n",
      "result of epoch 0accuracy is : 90 %\n",
      "[2,   200] loss: 0.241\n",
      "[2,   400] loss: 0.258\n",
      "[2,   600] loss: 0.173\n",
      "[2,   800] loss: 0.253\n",
      "[2,  1000] loss: 0.248\n",
      "[2,  1200] loss: 0.221\n",
      "[2,  1400] loss: 0.220\n",
      "[2,  1600] loss: 0.190\n",
      "[2,  1800] loss: 0.203\n",
      "[2,  2000] loss: 0.205\n",
      "-------------cur max is ::::----------92.0\n",
      "result of epoch 1accuracy is : 92 %\n",
      "[3,   200] loss: 0.142\n",
      "[3,   400] loss: 0.179\n",
      "[3,   600] loss: 0.186\n",
      "[3,   800] loss: 0.155\n",
      "[3,  1000] loss: 0.168\n",
      "[3,  1200] loss: 0.177\n",
      "[3,  1400] loss: 0.164\n",
      "[3,  1600] loss: 0.177\n",
      "[3,  1800] loss: 0.178\n",
      "[3,  2000] loss: 0.176\n",
      "result of epoch 2accuracy is : 92 %\n",
      "[4,   200] loss: 0.164\n",
      "[4,   400] loss: 0.165\n",
      "[4,   600] loss: 0.139\n",
      "[4,   800] loss: 0.176\n",
      "[4,  1000] loss: 0.126\n",
      "[4,  1200] loss: 0.135\n",
      "[4,  1400] loss: 0.135\n",
      "[4,  1600] loss: 0.138\n",
      "[4,  1800] loss: 0.141\n",
      "[4,  2000] loss: 0.174\n",
      "-------------cur max is ::::----------93.0\n",
      "result of epoch 3accuracy is : 93 %\n",
      "[5,   200] loss: 0.123\n",
      "[5,   400] loss: 0.122\n",
      "[5,   600] loss: 0.143\n",
      "[5,   800] loss: 0.162\n",
      "[5,  1000] loss: 0.125\n",
      "[5,  1200] loss: 0.123\n",
      "[5,  1400] loss: 0.136\n",
      "[5,  1600] loss: 0.128\n",
      "[5,  1800] loss: 0.127\n",
      "[5,  2000] loss: 0.121\n",
      "result of epoch 4accuracy is : 92 %\n",
      "[6,   200] loss: 0.100\n",
      "[6,   400] loss: 0.123\n",
      "[6,   600] loss: 0.110\n",
      "[6,   800] loss: 0.111\n",
      "[6,  1000] loss: 0.107\n",
      "[6,  1200] loss: 0.112\n",
      "[6,  1400] loss: 0.123\n",
      "[6,  1600] loss: 0.155\n",
      "[6,  1800] loss: 0.113\n",
      "[6,  2000] loss: 0.127\n",
      "result of epoch 5accuracy is : 93 %\n",
      "[7,   200] loss: 0.113\n",
      "[7,   400] loss: 0.125\n",
      "[7,   600] loss: 0.125\n",
      "[7,   800] loss: 0.108\n",
      "[7,  1000] loss: 0.110\n",
      "[7,  1200] loss: 0.088\n",
      "[7,  1400] loss: 0.100\n",
      "[7,  1600] loss: 0.106\n",
      "[7,  1800] loss: 0.107\n",
      "[7,  2000] loss: 0.100\n",
      "result of epoch 6accuracy is : 92 %\n",
      "[8,   200] loss: 0.109\n",
      "[8,   400] loss: 0.117\n",
      "[8,   600] loss: 0.093\n",
      "[8,   800] loss: 0.076\n",
      "[8,  1000] loss: 0.113\n",
      "[8,  1200] loss: 0.098\n",
      "[8,  1400] loss: 0.105\n",
      "[8,  1600] loss: 0.095\n",
      "[8,  1800] loss: 0.076\n",
      "[8,  2000] loss: 0.108\n",
      "result of epoch 7accuracy is : 92 %\n",
      "[9,   200] loss: 0.111\n",
      "[9,   400] loss: 0.083\n",
      "[9,   600] loss: 0.094\n",
      "[9,   800] loss: 0.105\n",
      "[9,  1000] loss: 0.087\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[9,  1200] loss: 0.061\n",
      "[9,  1400] loss: 0.103\n",
      "[9,  1600] loss: 0.112\n",
      "[9,  1800] loss: 0.108\n",
      "[9,  2000] loss: 0.082\n",
      "result of epoch 8accuracy is : 92 %\n",
      "[10,   200] loss: 0.084\n",
      "[10,   400] loss: 0.104\n",
      "[10,   600] loss: 0.086\n",
      "[10,   800] loss: 0.075\n",
      "[10,  1000] loss: 0.057\n",
      "[10,  1200] loss: 0.082\n",
      "[10,  1400] loss: 0.123\n",
      "[10,  1600] loss: 0.074\n",
      "[10,  1800] loss: 0.070\n",
      "[10,  2000] loss: 0.096\n",
      "result of epoch 9accuracy is : 91 %\n",
      "[11,   200] loss: 0.086\n",
      "[11,   400] loss: 0.066\n",
      "[11,   600] loss: 0.050\n",
      "[11,   800] loss: 0.081\n",
      "[11,  1000] loss: 0.095\n",
      "[11,  1200] loss: 0.088\n",
      "[11,  1400] loss: 0.075\n",
      "[11,  1600] loss: 0.085\n",
      "[11,  1800] loss: 0.072\n",
      "[11,  2000] loss: 0.070\n",
      "result of epoch 10accuracy is : 91 %\n",
      "[12,   200] loss: 0.088\n",
      "[12,   400] loss: 0.070\n",
      "[12,   600] loss: 0.067\n",
      "[12,   800] loss: 0.067\n",
      "[12,  1000] loss: 0.088\n",
      "[12,  1200] loss: 0.067\n",
      "[12,  1400] loss: 0.066\n",
      "[12,  1600] loss: 0.060\n",
      "[12,  1800] loss: 0.073\n",
      "[12,  2000] loss: 0.061\n",
      "result of epoch 11accuracy is : 92 %\n",
      "[13,   200] loss: 0.055\n",
      "[13,   400] loss: 0.083\n",
      "[13,   600] loss: 0.053\n",
      "[13,   800] loss: 0.058\n",
      "[13,  1000] loss: 0.077\n",
      "[13,  1200] loss: 0.051\n",
      "[13,  1400] loss: 0.069\n",
      "[13,  1600] loss: 0.050\n",
      "[13,  1800] loss: 0.071\n",
      "[13,  2000] loss: 0.064\n",
      "result of epoch 12accuracy is : 91 %\n",
      "[14,   200] loss: 0.054\n",
      "[14,   400] loss: 0.062\n",
      "[14,   600] loss: 0.063\n",
      "[14,   800] loss: 0.068\n",
      "[14,  1000] loss: 0.048\n",
      "[14,  1200] loss: 0.071\n",
      "[14,  1400] loss: 0.051\n",
      "[14,  1600] loss: 0.054\n",
      "[14,  1800] loss: 0.046\n",
      "[14,  2000] loss: 0.065\n",
      "result of epoch 13accuracy is : 92 %\n",
      "[15,   200] loss: 0.061\n",
      "[15,   400] loss: 0.055\n",
      "[15,   600] loss: 0.045\n",
      "[15,   800] loss: 0.057\n",
      "[15,  1000] loss: 0.061\n",
      "[15,  1200] loss: 0.047\n",
      "[15,  1400] loss: 0.034\n",
      "[15,  1600] loss: 0.056\n",
      "[15,  1800] loss: 0.039\n",
      "[15,  2000] loss: 0.047\n",
      "result of epoch 14accuracy is : 91 %\n",
      "[16,   200] loss: 0.047\n",
      "[16,   400] loss: 0.046\n",
      "[16,   600] loss: 0.047\n",
      "[16,   800] loss: 0.041\n",
      "[16,  1000] loss: 0.035\n",
      "[16,  1200] loss: 0.058\n",
      "[16,  1400] loss: 0.048\n",
      "[16,  1600] loss: 0.056\n",
      "[16,  1800] loss: 0.039\n",
      "[16,  2000] loss: 0.037\n",
      "result of epoch 15accuracy is : 92 %\n",
      "[17,   200] loss: 0.039\n",
      "[17,   400] loss: 0.038\n",
      "[17,   600] loss: 0.028\n",
      "[17,   800] loss: 0.037\n",
      "[17,  1000] loss: 0.027\n",
      "[17,  1200] loss: 0.051\n",
      "[17,  1400] loss: 0.044\n",
      "[17,  1600] loss: 0.026\n",
      "[17,  1800] loss: 0.047\n",
      "[17,  2000] loss: 0.043\n",
      "result of epoch 16accuracy is : 92 %\n",
      "[18,   200] loss: 0.032\n",
      "[18,   400] loss: 0.024\n",
      "[18,   600] loss: 0.031\n",
      "[18,   800] loss: 0.036\n",
      "[18,  1000] loss: 0.037\n",
      "[18,  1200] loss: 0.035\n",
      "[18,  1400] loss: 0.038\n",
      "[18,  1600] loss: 0.035\n",
      "[18,  1800] loss: 0.027\n",
      "[18,  2000] loss: 0.023\n",
      "result of epoch 17accuracy is : 92 %\n",
      "[19,   200] loss: 0.033\n",
      "[19,   400] loss: 0.031\n",
      "[19,   600] loss: 0.031\n",
      "[19,   800] loss: 0.030\n",
      "[19,  1000] loss: 0.017\n",
      "[19,  1200] loss: 0.026\n",
      "[19,  1400] loss: 0.025\n",
      "[19,  1600] loss: 0.029\n",
      "[19,  1800] loss: 0.029\n",
      "[19,  2000] loss: 0.025\n",
      "result of epoch 18accuracy is : 92 %\n",
      "[20,   200] loss: 0.023\n",
      "[20,   400] loss: 0.023\n",
      "[20,   600] loss: 0.019\n",
      "[20,   800] loss: 0.023\n",
      "[20,  1000] loss: 0.020\n",
      "[20,  1200] loss: 0.032\n",
      "[20,  1400] loss: 0.033\n",
      "[20,  1600] loss: 0.023\n",
      "[20,  1800] loss: 0.027\n",
      "[20,  2000] loss: 0.031\n",
      "result of epoch 19accuracy is : 92 %\n",
      "key配置\n",
      "Finished Training\n",
      "Net(\n",
      "  (bilstm): LSTM(100, 100, bidirectional=True)\n",
      "  (fch): Linear(in_features=200, out_features=100, bias=True)\n",
      "  (fcv): Linear(in_features=100, out_features=100, bias=True)\n",
      "  (fcw): Linear(in_features=200, out_features=1, bias=True)\n",
      "  (fcwp): Linear(in_features=200, out_features=50, bias=True)\n",
      "  (fcwh): Linear(in_features=200, out_features=50, bias=True)\n",
      "  (fc1): Linear(in_features=3750, out_features=120, bias=True)\n",
      "  (fc2): Linear(in_features=120, out_features=50, bias=True)\n",
      "  (fc3): Linear(in_features=50, out_features=4, bias=True)\n",
      "  (embeddings): Embedding(19791, 100)\n",
      ")\n",
      "[1,   200] loss: 0.503\n",
      "[1,   400] loss: 0.443\n",
      "[1,   600] loss: 0.502\n",
      "[1,   800] loss: 0.528\n",
      "[1,  1000] loss: 0.474\n",
      "[1,  1200] loss: 0.531\n",
      "[1,  1400] loss: 0.506\n",
      "[1,  1600] loss: 0.487\n",
      "[1,  1800] loss: 0.527\n",
      "[1,  2000] loss: 0.470\n",
      "-------------cur max is ::::----------84.0\n",
      "result of epoch 0accuracy is : 84 %\n",
      "[2,   200] loss: 0.481\n",
      "[2,   400] loss: 0.497\n",
      "[2,   600] loss: 0.524\n",
      "[2,   800] loss: 0.459\n",
      "[2,  1000] loss: 0.418\n",
      "[2,  1200] loss: 0.406\n",
      "[2,  1400] loss: 0.330\n",
      "[2,  1600] loss: 0.313\n",
      "[2,  1800] loss: 0.320\n",
      "[2,  2000] loss: 0.266\n",
      "-------------cur max is ::::----------86.0\n",
      "result of epoch 1accuracy is : 86 %\n",
      "[3,   200] loss: 0.193\n",
      "[3,   400] loss: 0.283\n",
      "[3,   600] loss: 0.260\n",
      "[3,   800] loss: 0.271\n",
      "[3,  1000] loss: 0.244\n",
      "[3,  1200] loss: 0.206\n",
      "[3,  1400] loss: 0.246\n",
      "[3,  1600] loss: 0.190\n",
      "[3,  1800] loss: 0.275\n",
      "[3,  2000] loss: 0.258\n",
      "-------------cur max is ::::----------87.0\n",
      "result of epoch 2accuracy is : 87 %\n",
      "[4,   200] loss: 0.256\n",
      "[4,   400] loss: 0.231\n",
      "[4,   600] loss: 0.189\n",
      "[4,   800] loss: 0.228\n",
      "[4,  1000] loss: 0.167\n",
      "[4,  1200] loss: 0.220\n",
      "[4,  1400] loss: 0.199\n",
      "[4,  1600] loss: 0.217\n",
      "[4,  1800] loss: 0.225\n",
      "[4,  2000] loss: 0.192\n",
      "result of epoch 3accuracy is : 87 %\n",
      "[5,   200] loss: 0.210\n",
      "[5,   400] loss: 0.172\n",
      "[5,   600] loss: 0.160\n",
      "[5,   800] loss: 0.192\n",
      "[5,  1000] loss: 0.147\n",
      "[5,  1200] loss: 0.179\n",
      "[5,  1400] loss: 0.184\n",
      "[5,  1600] loss: 0.175\n",
      "[5,  1800] loss: 0.177\n",
      "[5,  2000] loss: 0.190\n",
      "result of epoch 4accuracy is : 87 %\n",
      "[6,   200] loss: 0.163\n",
      "[6,   400] loss: 0.126\n",
      "[6,   600] loss: 0.134\n",
      "[6,   800] loss: 0.194\n",
      "[6,  1000] loss: 0.144\n",
      "[6,  1200] loss: 0.134\n",
      "[6,  1400] loss: 0.144\n",
      "[6,  1600] loss: 0.135\n",
      "[6,  1800] loss: 0.176\n",
      "[6,  2000] loss: 0.140\n",
      "result of epoch 5accuracy is : 86 %\n",
      "[7,   200] loss: 0.120\n",
      "[7,   400] loss: 0.109\n",
      "[7,   600] loss: 0.131\n",
      "[7,   800] loss: 0.120\n",
      "[7,  1000] loss: 0.129\n",
      "[7,  1200] loss: 0.099\n",
      "[7,  1400] loss: 0.137\n",
      "[7,  1600] loss: 0.112\n",
      "[7,  1800] loss: 0.131\n",
      "[7,  2000] loss: 0.137\n",
      "result of epoch 6accuracy is : 87 %\n",
      "[8,   200] loss: 0.112\n",
      "[8,   400] loss: 0.093\n",
      "[8,   600] loss: 0.094\n",
      "[8,   800] loss: 0.093\n",
      "[8,  1000] loss: 0.082\n",
      "[8,  1200] loss: 0.104\n",
      "[8,  1400] loss: 0.090\n",
      "[8,  1600] loss: 0.125\n",
      "[8,  1800] loss: 0.097\n",
      "[8,  2000] loss: 0.082\n",
      "-------------cur max is ::::----------90.0\n",
      "result of epoch 7accuracy is : 90 %\n",
      "[9,   200] loss: 0.093\n",
      "[9,   400] loss: 0.082\n",
      "[9,   600] loss: 0.069\n",
      "[9,   800] loss: 0.087\n",
      "[9,  1000] loss: 0.105\n",
      "[9,  1200] loss: 0.077\n",
      "[9,  1400] loss: 0.072\n",
      "[9,  1600] loss: 0.079\n",
      "[9,  1800] loss: 0.091\n",
      "[9,  2000] loss: 0.084\n",
      "-------------cur max is ::::----------91.0\n",
      "result of epoch 8accuracy is : 91 %\n",
      "[10,   200] loss: 0.090\n",
      "[10,   400] loss: 0.065\n",
      "[10,   600] loss: 0.082\n",
      "[10,   800] loss: 0.058\n",
      "[10,  1000] loss: 0.093\n",
      "[10,  1200] loss: 0.062\n",
      "[10,  1400] loss: 0.083\n",
      "[10,  1600] loss: 0.063\n",
      "[10,  1800] loss: 0.065\n",
      "[10,  2000] loss: 0.058\n",
      "result of epoch 9accuracy is : 86 %\n",
      "[11,   200] loss: 0.083\n",
      "[11,   400] loss: 0.041\n",
      "[11,   600] loss: 0.050\n",
      "[11,   800] loss: 0.066\n",
      "[11,  1000] loss: 0.063\n",
      "[11,  1200] loss: 0.065\n",
      "[11,  1400] loss: 0.064\n",
      "[11,  1600] loss: 0.065\n",
      "[11,  1800] loss: 0.061\n",
      "[11,  2000] loss: 0.049\n",
      "result of epoch 10accuracy is : 87 %\n",
      "[12,   200] loss: 0.047\n",
      "[12,   400] loss: 0.052\n",
      "[12,   600] loss: 0.067\n",
      "[12,   800] loss: 0.049\n",
      "[12,  1000] loss: 0.059\n",
      "[12,  1200] loss: 0.067\n",
      "[12,  1400] loss: 0.048\n",
      "[12,  1600] loss: 0.046\n",
      "[12,  1800] loss: 0.042\n",
      "[12,  2000] loss: 0.049\n",
      "result of epoch 11accuracy is : 87 %\n",
      "[13,   200] loss: 0.059\n",
      "[13,   400] loss: 0.047\n",
      "[13,   600] loss: 0.058\n",
      "[13,   800] loss: 0.043\n",
      "[13,  1000] loss: 0.044\n",
      "[13,  1200] loss: 0.035\n",
      "[13,  1400] loss: 0.048\n",
      "[13,  1600] loss: 0.041\n",
      "[13,  1800] loss: 0.040\n",
      "[13,  2000] loss: 0.041\n",
      "result of epoch 12accuracy is : 89 %\n",
      "[14,   200] loss: 0.031\n",
      "[14,   400] loss: 0.051\n",
      "[14,   600] loss: 0.032\n",
      "[14,   800] loss: 0.058\n",
      "[14,  1000] loss: 0.045\n",
      "[14,  1200] loss: 0.043\n",
      "[14,  1400] loss: 0.020\n",
      "[14,  1600] loss: 0.037\n",
      "[14,  1800] loss: 0.045\n",
      "[14,  2000] loss: 0.022\n",
      "result of epoch 13accuracy is : 87 %\n",
      "[15,   200] loss: 0.031\n",
      "[15,   400] loss: 0.042\n",
      "[15,   600] loss: 0.033\n",
      "[15,   800] loss: 0.025\n",
      "[15,  1000] loss: 0.055\n",
      "[15,  1200] loss: 0.032\n",
      "[15,  1400] loss: 0.045\n",
      "[15,  1600] loss: 0.024\n",
      "[15,  1800] loss: 0.026\n",
      "[15,  2000] loss: 0.050\n",
      "result of epoch 14accuracy is : 89 %\n",
      "[16,   200] loss: 0.038\n",
      "[16,   400] loss: 0.029\n",
      "[16,   600] loss: 0.046\n",
      "[16,   800] loss: 0.025\n",
      "[16,  1000] loss: 0.030\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[16,  1200] loss: 0.026\n",
      "[16,  1400] loss: 0.026\n",
      "[16,  1600] loss: 0.044\n",
      "[16,  1800] loss: 0.021\n",
      "[16,  2000] loss: 0.025\n",
      "result of epoch 15accuracy is : 87 %\n",
      "[17,   200] loss: 0.026\n",
      "[17,   400] loss: 0.027\n",
      "[17,   600] loss: 0.029\n",
      "[17,   800] loss: 0.035\n",
      "[17,  1000] loss: 0.027\n",
      "[17,  1200] loss: 0.037\n",
      "[17,  1400] loss: 0.016\n",
      "[17,  1600] loss: 0.027\n",
      "[17,  1800] loss: 0.033\n",
      "[17,  2000] loss: 0.028\n",
      "result of epoch 16accuracy is : 89 %\n",
      "[18,   200] loss: 0.034\n",
      "[18,   400] loss: 0.023\n",
      "[18,   600] loss: 0.031\n",
      "[18,   800] loss: 0.022\n",
      "[18,  1000] loss: 0.034\n",
      "[18,  1200] loss: 0.019\n",
      "[18,  1400] loss: 0.023\n",
      "[18,  1600] loss: 0.034\n",
      "[18,  1800] loss: 0.024\n",
      "[18,  2000] loss: 0.022\n",
      "result of epoch 17accuracy is : 89 %\n",
      "[19,   200] loss: 0.026\n",
      "[19,   400] loss: 0.015\n",
      "[19,   600] loss: 0.021\n",
      "[19,   800] loss: 0.028\n",
      "[19,  1000] loss: 0.022\n",
      "[19,  1200] loss: 0.020\n",
      "[19,  1400] loss: 0.023\n",
      "[19,  1600] loss: 0.032\n",
      "[19,  1800] loss: 0.024\n",
      "[19,  2000] loss: 0.019\n",
      "result of epoch 18accuracy is : 87 %\n",
      "[20,   200] loss: 0.025\n",
      "[20,   400] loss: 0.011\n",
      "[20,   600] loss: 0.015\n",
      "[20,   800] loss: 0.021\n",
      "[20,  1000] loss: 0.019\n",
      "[20,  1200] loss: 0.027\n",
      "[20,  1400] loss: 0.021\n",
      "[20,  1600] loss: 0.017\n",
      "[20,  1800] loss: 0.016\n",
      "[20,  2000] loss: 0.017\n",
      "result of epoch 19accuracy is : 86 %\n",
      "key操控\n",
      "Finished Training\n",
      "Net(\n",
      "  (bilstm): LSTM(100, 100, bidirectional=True)\n",
      "  (fch): Linear(in_features=200, out_features=100, bias=True)\n",
      "  (fcv): Linear(in_features=100, out_features=100, bias=True)\n",
      "  (fcw): Linear(in_features=200, out_features=1, bias=True)\n",
      "  (fcwp): Linear(in_features=200, out_features=50, bias=True)\n",
      "  (fcwh): Linear(in_features=200, out_features=50, bias=True)\n",
      "  (fc1): Linear(in_features=3750, out_features=120, bias=True)\n",
      "  (fc2): Linear(in_features=120, out_features=50, bias=True)\n",
      "  (fc3): Linear(in_features=50, out_features=4, bias=True)\n",
      "  (embeddings): Embedding(19791, 100)\n",
      ")\n",
      "[1,   200] loss: 0.480\n",
      "[1,   400] loss: 0.411\n",
      "[1,   600] loss: 0.495\n",
      "[1,   800] loss: 0.492\n",
      "[1,  1000] loss: 0.414\n",
      "[1,  1200] loss: 0.365\n",
      "[1,  1400] loss: 0.452\n",
      "[1,  1600] loss: 0.516\n",
      "[1,  1800] loss: 0.457\n",
      "[1,  2000] loss: 0.449\n",
      "-------------cur max is ::::----------87.0\n",
      "result of epoch 0accuracy is : 87 %\n",
      "[2,   200] loss: 0.446\n",
      "[2,   400] loss: 0.383\n",
      "[2,   600] loss: 0.438\n",
      "[2,   800] loss: 0.357\n",
      "[2,  1000] loss: 0.303\n",
      "[2,  1200] loss: 0.323\n",
      "[2,  1400] loss: 0.320\n",
      "[2,  1600] loss: 0.348\n",
      "[2,  1800] loss: 0.306\n",
      "[2,  2000] loss: 0.297\n",
      "-------------cur max is ::::----------90.0\n",
      "result of epoch 1accuracy is : 90 %\n",
      "[3,   200] loss: 0.305\n",
      "[3,   400] loss: 0.263\n",
      "[3,   600] loss: 0.255\n",
      "[3,   800] loss: 0.264\n",
      "[3,  1000] loss: 0.272\n",
      "[3,  1200] loss: 0.229\n",
      "[3,  1400] loss: 0.262\n",
      "[3,  1600] loss: 0.227\n",
      "[3,  1800] loss: 0.206\n",
      "[3,  2000] loss: 0.217\n",
      "result of epoch 2accuracy is : 87 %\n",
      "[4,   200] loss: 0.219\n",
      "[4,   400] loss: 0.194\n",
      "[4,   600] loss: 0.196\n",
      "[4,   800] loss: 0.205\n",
      "[4,  1000] loss: 0.190\n",
      "[4,  1200] loss: 0.198\n",
      "[4,  1400] loss: 0.184\n",
      "[4,  1600] loss: 0.181\n",
      "[4,  1800] loss: 0.171\n",
      "[4,  2000] loss: 0.218\n",
      "-------------cur max is ::::----------91.0\n",
      "result of epoch 3accuracy is : 91 %\n",
      "[5,   200] loss: 0.190\n",
      "[5,   400] loss: 0.157\n",
      "[5,   600] loss: 0.149\n",
      "[5,   800] loss: 0.167\n",
      "[5,  1000] loss: 0.167\n",
      "[5,  1200] loss: 0.125\n",
      "[5,  1400] loss: 0.157\n",
      "[5,  1600] loss: 0.162\n",
      "[5,  1800] loss: 0.147\n",
      "[5,  2000] loss: 0.132\n",
      "result of epoch 4accuracy is : 91 %\n",
      "[6,   200] loss: 0.150\n",
      "[6,   400] loss: 0.121\n",
      "[6,   600] loss: 0.130\n",
      "[6,   800] loss: 0.120\n",
      "[6,  1000] loss: 0.109\n",
      "[6,  1200] loss: 0.141\n",
      "[6,  1400] loss: 0.113\n",
      "[6,  1600] loss: 0.128\n",
      "[6,  1800] loss: 0.104\n",
      "[6,  2000] loss: 0.135\n",
      "result of epoch 5accuracy is : 90 %\n",
      "[7,   200] loss: 0.113\n",
      "[7,   400] loss: 0.117\n",
      "[7,   600] loss: 0.101\n",
      "[7,   800] loss: 0.085\n",
      "[7,  1000] loss: 0.100\n",
      "[7,  1200] loss: 0.108\n",
      "[7,  1400] loss: 0.122\n",
      "[7,  1600] loss: 0.115\n",
      "[7,  1800] loss: 0.088\n",
      "[7,  2000] loss: 0.122\n",
      "result of epoch 6accuracy is : 87 %\n",
      "[8,   200] loss: 0.079\n",
      "[8,   400] loss: 0.075\n",
      "[8,   600] loss: 0.110\n",
      "[8,   800] loss: 0.095\n",
      "[8,  1000] loss: 0.096\n",
      "[8,  1200] loss: 0.098\n",
      "[8,  1400] loss: 0.092\n",
      "[8,  1600] loss: 0.089\n",
      "[8,  1800] loss: 0.106\n",
      "[8,  2000] loss: 0.085\n",
      "result of epoch 7accuracy is : 87 %\n",
      "[9,   200] loss: 0.081\n",
      "[9,   400] loss: 0.071\n",
      "[9,   600] loss: 0.077\n",
      "[9,   800] loss: 0.071\n",
      "[9,  1000] loss: 0.077\n",
      "[9,  1200] loss: 0.078\n",
      "[9,  1400] loss: 0.080\n",
      "[9,  1600] loss: 0.082\n",
      "[9,  1800] loss: 0.087\n",
      "[9,  2000] loss: 0.090\n",
      "result of epoch 8accuracy is : 87 %\n",
      "[10,   200] loss: 0.068\n",
      "[10,   400] loss: 0.079\n",
      "[10,   600] loss: 0.080\n",
      "[10,   800] loss: 0.058\n",
      "[10,  1000] loss: 0.064\n",
      "[10,  1200] loss: 0.063\n",
      "[10,  1400] loss: 0.057\n",
      "[10,  1600] loss: 0.069\n",
      "[10,  1800] loss: 0.070\n",
      "[10,  2000] loss: 0.063\n",
      "result of epoch 9accuracy is : 89 %\n",
      "[11,   200] loss: 0.064\n",
      "[11,   400] loss: 0.050\n",
      "[11,   600] loss: 0.060\n",
      "[11,   800] loss: 0.058\n",
      "[11,  1000] loss: 0.070\n",
      "[11,  1200] loss: 0.051\n",
      "[11,  1400] loss: 0.060\n",
      "[11,  1600] loss: 0.046\n",
      "[11,  1800] loss: 0.055\n",
      "[11,  2000] loss: 0.066\n",
      "result of epoch 10accuracy is : 89 %\n",
      "[12,   200] loss: 0.047\n",
      "[12,   400] loss: 0.042\n",
      "[12,   600] loss: 0.076\n",
      "[12,   800] loss: 0.066\n",
      "[12,  1000] loss: 0.058\n",
      "[12,  1200] loss: 0.041\n",
      "[12,  1400] loss: 0.044\n",
      "[12,  1600] loss: 0.045\n",
      "[12,  1800] loss: 0.046\n",
      "[12,  2000] loss: 0.050\n",
      "result of epoch 11accuracy is : 89 %\n",
      "[13,   200] loss: 0.048\n",
      "[13,   400] loss: 0.045\n",
      "[13,   600] loss: 0.038\n",
      "[13,   800] loss: 0.050\n",
      "[13,  1000] loss: 0.037\n",
      "[13,  1200] loss: 0.045\n",
      "[13,  1400] loss: 0.053\n",
      "[13,  1600] loss: 0.036\n",
      "[13,  1800] loss: 0.055\n",
      "[13,  2000] loss: 0.047\n",
      "result of epoch 12accuracy is : 90 %\n",
      "[14,   200] loss: 0.043\n",
      "[14,   400] loss: 0.049\n",
      "[14,   600] loss: 0.047\n",
      "[14,   800] loss: 0.046\n",
      "[14,  1000] loss: 0.054\n",
      "[14,  1200] loss: 0.025\n",
      "[14,  1400] loss: 0.033\n",
      "[14,  1600] loss: 0.044\n",
      "[14,  1800] loss: 0.043\n",
      "[14,  2000] loss: 0.020\n",
      "result of epoch 13accuracy is : 90 %\n",
      "[15,   200] loss: 0.035\n",
      "[15,   400] loss: 0.029\n",
      "[15,   600] loss: 0.043\n",
      "[15,   800] loss: 0.036\n",
      "[15,  1000] loss: 0.046\n",
      "[15,  1200] loss: 0.034\n",
      "[15,  1400] loss: 0.020\n",
      "[15,  1600] loss: 0.036\n",
      "[15,  1800] loss: 0.036\n",
      "[15,  2000] loss: 0.046\n",
      "result of epoch 14accuracy is : 90 %\n",
      "[16,   200] loss: 0.024\n",
      "[16,   400] loss: 0.021\n",
      "[16,   600] loss: 0.035\n",
      "[16,   800] loss: 0.025\n",
      "[16,  1000] loss: 0.024\n",
      "[16,  1200] loss: 0.022\n",
      "[16,  1400] loss: 0.033\n",
      "[16,  1600] loss: 0.031\n",
      "[16,  1800] loss: 0.044\n",
      "[16,  2000] loss: 0.038\n",
      "result of epoch 15accuracy is : 89 %\n",
      "[17,   200] loss: 0.024\n",
      "[17,   400] loss: 0.040\n",
      "[17,   600] loss: 0.029\n",
      "[17,   800] loss: 0.021\n",
      "[17,  1000] loss: 0.031\n",
      "[17,  1200] loss: 0.036\n",
      "[17,  1400] loss: 0.026\n",
      "[17,  1600] loss: 0.026\n",
      "[17,  1800] loss: 0.019\n",
      "[17,  2000] loss: 0.023\n",
      "result of epoch 16accuracy is : 90 %\n",
      "[18,   200] loss: 0.024\n",
      "[18,   400] loss: 0.026\n",
      "[18,   600] loss: 0.019\n",
      "[18,   800] loss: 0.031\n",
      "[18,  1000] loss: 0.025\n",
      "[18,  1200] loss: 0.024\n",
      "[18,  1400] loss: 0.013\n",
      "[18,  1600] loss: 0.033\n",
      "[18,  1800] loss: 0.033\n",
      "[18,  2000] loss: 0.025\n",
      "result of epoch 17accuracy is : 90 %\n",
      "[19,   200] loss: 0.019\n",
      "[19,   400] loss: 0.019\n",
      "[19,   600] loss: 0.019\n",
      "[19,   800] loss: 0.021\n",
      "[19,  1000] loss: 0.021\n",
      "[19,  1200] loss: 0.028\n",
      "[19,  1400] loss: 0.023\n",
      "[19,  1600] loss: 0.017\n",
      "[19,  1800] loss: 0.022\n",
      "[19,  2000] loss: 0.031\n",
      "result of epoch 18accuracy is : 90 %\n",
      "[20,   200] loss: 0.018\n",
      "[20,   400] loss: 0.023\n",
      "[20,   600] loss: 0.019\n",
      "[20,   800] loss: 0.019\n",
      "[20,  1000] loss: 0.021\n",
      "[20,  1200] loss: 0.028\n",
      "[20,  1400] loss: 0.014\n",
      "[20,  1600] loss: 0.012\n",
      "[20,  1800] loss: 0.012\n",
      "[20,  2000] loss: 0.032\n",
      "result of epoch 19accuracy is : 90 %\n",
      "key舒适性\n",
      "Finished Training\n",
      "Net(\n",
      "  (bilstm): LSTM(100, 100, bidirectional=True)\n",
      "  (fch): Linear(in_features=200, out_features=100, bias=True)\n",
      "  (fcv): Linear(in_features=100, out_features=100, bias=True)\n",
      "  (fcw): Linear(in_features=200, out_features=1, bias=True)\n",
      "  (fcwp): Linear(in_features=200, out_features=50, bias=True)\n",
      "  (fcwh): Linear(in_features=200, out_features=50, bias=True)\n",
      "  (fc1): Linear(in_features=3750, out_features=120, bias=True)\n",
      "  (fc2): Linear(in_features=120, out_features=50, bias=True)\n",
      "  (fc3): Linear(in_features=50, out_features=4, bias=True)\n",
      "  (embeddings): Embedding(19791, 100)\n",
      ")\n",
      "[1,   200] loss: 0.507\n",
      "[1,   400] loss: 0.489\n",
      "[1,   600] loss: 0.453\n",
      "[1,   800] loss: 0.441\n",
      "[1,  1000] loss: 0.273\n",
      "[1,  1200] loss: 0.258\n",
      "[1,  1400] loss: 0.244\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1,  1600] loss: 0.155\n",
      "[1,  1800] loss: 0.232\n",
      "[1,  2000] loss: 0.178\n",
      "-------------cur max is ::::----------100.0\n",
      "result of epoch 0accuracy is : 100 %\n",
      "[2,   200] loss: 0.168\n",
      "[2,   400] loss: 0.173\n",
      "[2,   600] loss: 0.165\n",
      "[2,   800] loss: 0.167\n",
      "[2,  1000] loss: 0.167\n",
      "[2,  1200] loss: 0.175\n",
      "[2,  1400] loss: 0.202\n",
      "[2,  1600] loss: 0.209\n",
      "[2,  1800] loss: 0.185\n",
      "[2,  2000] loss: 0.174\n",
      "result of epoch 1accuracy is : 100 %\n",
      "[3,   200] loss: 0.156\n",
      "[3,   400] loss: 0.187\n",
      "[3,   600] loss: 0.147\n",
      "[3,   800] loss: 0.135\n",
      "[3,  1000] loss: 0.158\n",
      "[3,  1200] loss: 0.157\n",
      "[3,  1400] loss: 0.152\n",
      "[3,  1600] loss: 0.182\n",
      "[3,  1800] loss: 0.139\n",
      "[3,  2000] loss: 0.160\n",
      "result of epoch 2accuracy is : 100 %\n",
      "[4,   200] loss: 0.128\n",
      "[4,   400] loss: 0.126\n",
      "[4,   600] loss: 0.115\n",
      "[4,   800] loss: 0.130\n",
      "[4,  1000] loss: 0.182\n",
      "[4,  1200] loss: 0.124\n",
      "[4,  1400] loss: 0.147\n",
      "[4,  1600] loss: 0.153\n",
      "[4,  1800] loss: 0.134\n",
      "[4,  2000] loss: 0.143\n",
      "result of epoch 3accuracy is : 100 %\n",
      "[5,   200] loss: 0.135\n",
      "[5,   400] loss: 0.131\n",
      "[5,   600] loss: 0.139\n",
      "[5,   800] loss: 0.115\n",
      "[5,  1000] loss: 0.102\n",
      "[5,  1200] loss: 0.108\n",
      "[5,  1400] loss: 0.114\n",
      "[5,  1600] loss: 0.096\n",
      "[5,  1800] loss: 0.126\n",
      "[5,  2000] loss: 0.135\n",
      "result of epoch 4accuracy is : 98 %\n",
      "[6,   200] loss: 0.089\n",
      "[6,   400] loss: 0.121\n",
      "[6,   600] loss: 0.119\n",
      "[6,   800] loss: 0.109\n",
      "[6,  1000] loss: 0.122\n",
      "[6,  1200] loss: 0.095\n",
      "[6,  1400] loss: 0.116\n",
      "[6,  1600] loss: 0.117\n",
      "[6,  1800] loss: 0.101\n",
      "[6,  2000] loss: 0.114\n",
      "result of epoch 5accuracy is : 98 %\n",
      "[7,   200] loss: 0.091\n",
      "[7,   400] loss: 0.101\n",
      "[7,   600] loss: 0.067\n",
      "[7,   800] loss: 0.082\n",
      "[7,  1000] loss: 0.111\n",
      "[7,  1200] loss: 0.086\n",
      "[7,  1400] loss: 0.091\n",
      "[7,  1600] loss: 0.113\n",
      "[7,  1800] loss: 0.093\n",
      "[7,  2000] loss: 0.109\n",
      "result of epoch 6accuracy is : 98 %\n",
      "[8,   200] loss: 0.100\n",
      "[8,   400] loss: 0.079\n",
      "[8,   600] loss: 0.088\n",
      "[8,   800] loss: 0.077\n",
      "[8,  1000] loss: 0.088\n",
      "[8,  1200] loss: 0.073\n",
      "[8,  1400] loss: 0.072\n",
      "[8,  1600] loss: 0.085\n",
      "[8,  1800] loss: 0.074\n",
      "[8,  2000] loss: 0.067\n",
      "result of epoch 7accuracy is : 98 %\n",
      "[9,   200] loss: 0.067\n",
      "[9,   400] loss: 0.076\n",
      "[9,   600] loss: 0.084\n",
      "[9,   800] loss: 0.077\n",
      "[9,  1000] loss: 0.083\n",
      "[9,  1200] loss: 0.055\n",
      "[9,  1400] loss: 0.052\n",
      "[9,  1600] loss: 0.074\n",
      "[9,  1800] loss: 0.061\n",
      "[9,  2000] loss: 0.071\n",
      "result of epoch 8accuracy is : 98 %\n",
      "[10,   200] loss: 0.083\n",
      "[10,   400] loss: 0.044\n",
      "[10,   600] loss: 0.069\n",
      "[10,   800] loss: 0.054\n",
      "[10,  1000] loss: 0.063\n",
      "[10,  1200] loss: 0.047\n",
      "[10,  1400] loss: 0.053\n",
      "[10,  1600] loss: 0.064\n",
      "[10,  1800] loss: 0.057\n",
      "[10,  2000] loss: 0.042\n",
      "result of epoch 9accuracy is : 97 %\n",
      "[11,   200] loss: 0.046\n",
      "[11,   400] loss: 0.063\n",
      "[11,   600] loss: 0.066\n",
      "[11,   800] loss: 0.048\n",
      "[11,  1000] loss: 0.046\n",
      "[11,  1200] loss: 0.039\n",
      "[11,  1400] loss: 0.028\n",
      "[11,  1600] loss: 0.058\n",
      "[11,  1800] loss: 0.054\n",
      "[11,  2000] loss: 0.048\n",
      "result of epoch 10accuracy is : 97 %\n",
      "[12,   200] loss: 0.041\n",
      "[12,   400] loss: 0.050\n",
      "[12,   600] loss: 0.042\n",
      "[12,   800] loss: 0.025\n",
      "[12,  1000] loss: 0.044\n",
      "[12,  1200] loss: 0.046\n",
      "[12,  1400] loss: 0.038\n",
      "[12,  1600] loss: 0.041\n",
      "[12,  1800] loss: 0.044\n",
      "[12,  2000] loss: 0.033\n",
      "result of epoch 11accuracy is : 96 %\n",
      "[13,   200] loss: 0.041\n",
      "[13,   400] loss: 0.059\n",
      "[13,   600] loss: 0.030\n",
      "[13,   800] loss: 0.030\n",
      "[13,  1000] loss: 0.033\n",
      "[13,  1200] loss: 0.030\n",
      "[13,  1400] loss: 0.036\n",
      "[13,  1600] loss: 0.034\n",
      "[13,  1800] loss: 0.032\n",
      "[13,  2000] loss: 0.033\n",
      "result of epoch 12accuracy is : 96 %\n",
      "[14,   200] loss: 0.032\n",
      "[14,   400] loss: 0.030\n",
      "[14,   600] loss: 0.032\n",
      "[14,   800] loss: 0.032\n",
      "[14,  1000] loss: 0.018\n",
      "[14,  1200] loss: 0.026\n",
      "[14,  1400] loss: 0.043\n",
      "[14,  1600] loss: 0.026\n",
      "[14,  1800] loss: 0.033\n",
      "[14,  2000] loss: 0.044\n",
      "result of epoch 13accuracy is : 97 %\n",
      "[15,   200] loss: 0.028\n",
      "[15,   400] loss: 0.020\n",
      "[15,   600] loss: 0.027\n",
      "[15,   800] loss: 0.028\n",
      "[15,  1000] loss: 0.041\n",
      "[15,  1200] loss: 0.027\n",
      "[15,  1400] loss: 0.024\n",
      "[15,  1600] loss: 0.021\n",
      "[15,  1800] loss: 0.016\n",
      "[15,  2000] loss: 0.041\n",
      "result of epoch 14accuracy is : 97 %\n",
      "[16,   200] loss: 0.019\n",
      "[16,   400] loss: 0.033\n",
      "[16,   600] loss: 0.035\n",
      "[16,   800] loss: 0.026\n",
      "[16,  1000] loss: 0.028\n",
      "[16,  1200] loss: 0.016\n",
      "[16,  1400] loss: 0.023\n",
      "[16,  1600] loss: 0.018\n",
      "[16,  1800] loss: 0.019\n",
      "[16,  2000] loss: 0.028\n",
      "result of epoch 15accuracy is : 96 %\n",
      "[17,   200] loss: 0.020\n",
      "[17,   400] loss: 0.020\n",
      "[17,   600] loss: 0.018\n",
      "[17,   800] loss: 0.032\n",
      "[17,  1000] loss: 0.021\n",
      "[17,  1200] loss: 0.019\n",
      "[17,  1400] loss: 0.018\n",
      "[17,  1600] loss: 0.021\n",
      "[17,  1800] loss: 0.019\n",
      "[17,  2000] loss: 0.017\n",
      "result of epoch 16accuracy is : 97 %\n",
      "[20,  1400] loss: 0.020\n",
      "[20,  1600] loss: 0.011\n",
      "[20,  1800] loss: 0.015\n",
      "[20,  2000] loss: 0.019\n",
      "result of epoch 19accuracy is : 96 %\n",
      "key油耗\n",
      "Finished Training\n",
      "Net(\n",
      "  (bilstm): LSTM(100, 100, bidirectional=True)\n",
      "  (fch): Linear(in_features=200, out_features=100, bias=True)\n",
      "  (fcv): Linear(in_features=100, out_features=100, bias=True)\n",
      "  (fcw): Linear(in_features=200, out_features=1, bias=True)\n",
      "  (fcwp): Linear(in_features=200, out_features=50, bias=True)\n",
      "  (fcwh): Linear(in_features=200, out_features=50, bias=True)\n",
      "  (fc1): Linear(in_features=3750, out_features=120, bias=True)\n",
      "  (fc2): Linear(in_features=120, out_features=50, bias=True)\n",
      "  (fc3): Linear(in_features=50, out_features=4, bias=True)\n",
      "  (embeddings): Embedding(19791, 100)\n",
      ")\n",
      "[1,   200] loss: 0.938\n",
      "[1,   400] loss: 0.864\n",
      "[1,   600] loss: 0.693\n",
      "[1,   800] loss: 0.618\n",
      "[1,  1000] loss: 0.539\n",
      "[1,  1200] loss: 0.528\n",
      "[1,  1400] loss: 0.514\n",
      "[1,  1600] loss: 0.480\n",
      "[1,  1800] loss: 0.515\n",
      "[1,  2000] loss: 0.510\n",
      "-------------cur max is ::::----------83.0\n",
      "result of epoch 0accuracy is : 83 %\n",
      "[2,   200] loss: 0.473\n",
      "[2,   400] loss: 0.429\n",
      "[2,   600] loss: 0.407\n",
      "[2,   800] loss: 0.448\n",
      "[2,  1000] loss: 0.422\n",
      "[2,  1200] loss: 0.396\n",
      "[2,  1400] loss: 0.475\n",
      "[2,  1600] loss: 0.501\n",
      "[2,  1800] loss: 0.500\n",
      "[2,  2000] loss: 0.491\n",
      "-------------cur max is ::::----------84.0\n",
      "result of epoch 1accuracy is : 84 %\n",
      "[3,   200] loss: 0.381\n",
      "[3,   400] loss: 0.427\n",
      "[3,   600] loss: 0.405\n",
      "[3,   800] loss: 0.386\n",
      "[3,  1000] loss: 0.423\n",
      "[3,  1200] loss: 0.449\n",
      "[3,  1400] loss: 0.428\n",
      "[3,  1600] loss: 0.463\n",
      "[3,  1800] loss: 0.400\n",
      "[3,  2000] loss: 0.412\n",
      "result of epoch 2accuracy is : 84 %\n",
      "[4,   200] loss: 0.353\n",
      "[4,   400] loss: 0.393\n",
      "[4,   600] loss: 0.428\n",
      "[4,   800] loss: 0.367\n",
      "[4,  1000] loss: 0.349\n",
      "[4,  1200] loss: 0.345\n",
      "[4,  1400] loss: 0.390\n",
      "[4,  1600] loss: 0.382\n",
      "[4,  1800] loss: 0.377\n",
      "[4,  2000] loss: 0.378\n",
      "result of epoch 3accuracy is : 84 %\n",
      "[5,   200] loss: 0.355\n",
      "[5,   400] loss: 0.397\n",
      "[5,   600] loss: 0.377\n",
      "[5,   800] loss: 0.312\n",
      "[5,  1000] loss: 0.346\n",
      "[5,  1200] loss: 0.290\n",
      "[5,  1400] loss: 0.343\n",
      "[5,  1600] loss: 0.310\n",
      "[5,  1800] loss: 0.365\n",
      "[5,  2000] loss: 0.317\n",
      "-------------cur max is ::::----------86.0\n",
      "result of epoch 4accuracy is : 86 %\n",
      "[6,   200] loss: 0.315\n",
      "[6,   400] loss: 0.348\n",
      "[6,   600] loss: 0.308\n",
      "[6,   800] loss: 0.283\n",
      "[6,  1000] loss: 0.274\n",
      "[6,  1200] loss: 0.332\n",
      "[6,  1400] loss: 0.345\n",
      "[6,  1600] loss: 0.287\n",
      "[6,  1800] loss: 0.286\n",
      "[6,  2000] loss: 0.298\n",
      "result of epoch 5accuracy is : 83 %\n",
      "[7,   200] loss: 0.261\n",
      "[7,   400] loss: 0.292\n",
      "[7,   600] loss: 0.283\n",
      "[7,   800] loss: 0.263\n",
      "[7,  1000] loss: 0.292\n",
      "[7,  1200] loss: 0.292\n",
      "[7,  1400] loss: 0.267\n",
      "[7,  1600] loss: 0.270\n",
      "[7,  1800] loss: 0.295\n",
      "[7,  2000] loss: 0.263\n",
      "result of epoch 6accuracy is : 84 %\n",
      "[8,   200] loss: 0.242\n",
      "[8,   400] loss: 0.288\n",
      "[8,   600] loss: 0.231\n",
      "[8,   800] loss: 0.238\n",
      "[8,  1000] loss: 0.252\n",
      "[8,  1200] loss: 0.271\n",
      "[8,  1400] loss: 0.204\n",
      "[8,  1600] loss: 0.246\n",
      "[8,  1800] loss: 0.251\n",
      "[8,  2000] loss: 0.237\n",
      "result of epoch 7accuracy is : 80 %\n",
      "[9,   200] loss: 0.240\n",
      "[9,   400] loss: 0.181\n",
      "[9,   600] loss: 0.239\n",
      "[9,   800] loss: 0.201\n",
      "[9,  1000] loss: 0.212\n",
      "[9,  1200] loss: 0.251\n",
      "[9,  1400] loss: 0.224\n",
      "[9,  1600] loss: 0.241\n",
      "[9,  1800] loss: 0.186\n",
      "[9,  2000] loss: 0.182\n",
      "result of epoch 8accuracy is : 80 %\n",
      "[10,   200] loss: 0.191\n",
      "[10,   400] loss: 0.203\n",
      "[10,   600] loss: 0.196\n",
      "[10,   800] loss: 0.211\n",
      "[10,  1000] loss: 0.186\n",
      "[10,  1200] loss: 0.136\n",
      "[10,  1400] loss: 0.156\n",
      "[10,  1600] loss: 0.165\n",
      "[10,  1800] loss: 0.176\n",
      "[10,  2000] loss: 0.168\n",
      "result of epoch 9accuracy is : 77 %\n",
      "[11,   200] loss: 0.163\n",
      "[11,   400] loss: 0.149\n",
      "[11,   600] loss: 0.132\n",
      "[11,   800] loss: 0.180\n",
      "[11,  1000] loss: 0.144\n",
      "[11,  1200] loss: 0.152\n",
      "[11,  1400] loss: 0.146\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[11,  1600] loss: 0.139\n",
      "[11,  1800] loss: 0.128\n",
      "[11,  2000] loss: 0.127\n",
      "result of epoch 10accuracy is : 77 %\n",
      "[12,   200] loss: 0.112\n",
      "[12,   400] loss: 0.105\n",
      "[12,   600] loss: 0.134\n",
      "[12,   800] loss: 0.124\n",
      "[12,  1000] loss: 0.130\n",
      "[12,  1200] loss: 0.115\n",
      "[12,  1400] loss: 0.140\n",
      "[12,  1600] loss: 0.125\n",
      "[12,  1800] loss: 0.135\n",
      "[12,  2000] loss: 0.117\n",
      "result of epoch 11accuracy is : 74 %\n",
      "[13,   200] loss: 0.125\n",
      "[13,   400] loss: 0.097\n",
      "[13,   600] loss: 0.109\n",
      "[13,   800] loss: 0.079\n",
      "[13,  1000] loss: 0.115\n",
      "[13,  1200] loss: 0.097\n",
      "[13,  1400] loss: 0.106\n",
      "[13,  1600] loss: 0.088\n",
      "[13,  1800] loss: 0.103\n",
      "[13,  2000] loss: 0.094\n",
      "result of epoch 12accuracy is : 75 %\n",
      "[14,   200] loss: 0.082\n",
      "[14,   400] loss: 0.097\n",
      "[14,   600] loss: 0.113\n",
      "[14,   800] loss: 0.086\n",
      "[14,  1000] loss: 0.093\n",
      "[14,  1200] loss: 0.058\n",
      "[14,  1400] loss: 0.074\n",
      "[14,  1600] loss: 0.099\n",
      "[14,  1800] loss: 0.076\n",
      "[14,  2000] loss: 0.094\n",
      "result of epoch 13accuracy is : 74 %\n",
      "[15,   200] loss: 0.072\n",
      "[15,   400] loss: 0.080\n",
      "[15,   600] loss: 0.082\n",
      "[15,   800] loss: 0.066\n",
      "[15,  1000] loss: 0.074\n",
      "[15,  1200] loss: 0.088\n",
      "[15,  1400] loss: 0.069\n",
      "[15,  1600] loss: 0.093\n",
      "[15,  1800] loss: 0.088\n",
      "[15,  2000] loss: 0.072\n",
      "result of epoch 14accuracy is : 72 %\n",
      "[16,   200] loss: 0.084\n",
      "[16,   400] loss: 0.068\n",
      "[16,   600] loss: 0.064\n",
      "[16,   800] loss: 0.075\n",
      "[16,  1000] loss: 0.069\n",
      "[16,  1200] loss: 0.076\n",
      "[16,  1400] loss: 0.071\n",
      "[16,  1600] loss: 0.066\n",
      "[16,  1800] loss: 0.041\n",
      "[16,  2000] loss: 0.049\n",
      "result of epoch 15accuracy is : 71 %\n",
      "[17,   200] loss: 0.058\n",
      "[17,   400] loss: 0.062\n",
      "[17,   600] loss: 0.071\n",
      "[17,   800] loss: 0.056\n",
      "[17,  1000] loss: 0.051\n",
      "[17,  1200] loss: 0.065\n",
      "[17,  1400] loss: 0.055\n",
      "[17,  1600] loss: 0.069\n",
      "[17,  1800] loss: 0.049\n",
      "[17,  2000] loss: 0.071\n",
      "result of epoch 16accuracy is : 71 %\n",
      "[18,   200] loss: 0.050\n",
      "[18,   400] loss: 0.068\n",
      "[18,   600] loss: 0.063\n",
      "[18,   800] loss: 0.048\n",
      "[18,  1000] loss: 0.042\n",
      "[18,  1200] loss: 0.044\n",
      "[18,  1400] loss: 0.050\n",
      "[18,  1600] loss: 0.066\n",
      "[18,  1800] loss: 0.052\n",
      "[18,  2000] loss: 0.063\n",
      "result of epoch 17accuracy is : 72 %\n",
      "[19,   200] loss: 0.056\n",
      "[19,   400] loss: 0.046\n",
      "[19,   600] loss: 0.047\n",
      "[19,   800] loss: 0.051\n",
      "[19,  1000] loss: 0.045\n",
      "[19,  1200] loss: 0.051\n",
      "[19,  1400] loss: 0.043\n",
      "[19,  1600] loss: 0.051\n",
      "[19,  1800] loss: 0.033\n",
      "[19,  2000] loss: 0.055\n",
      "result of epoch 18accuracy is : 69 %\n",
      "[20,   200] loss: 0.045\n",
      "[20,   400] loss: 0.055\n",
      "[20,   600] loss: 0.043\n",
      "[20,   800] loss: 0.058\n",
      "[20,  1000] loss: 0.047\n",
      "[20,  1200] loss: 0.047\n",
      "[20,  1400] loss: 0.046\n",
      "[20,  1600] loss: 0.049\n",
      "[20,  1800] loss: 0.031\n",
      "[20,  2000] loss: 0.036\n",
      "result of epoch 19accuracy is : 72 %\n",
      "key动力\n",
      "Finished Training\n",
      "Net(\n",
      "  (bilstm): LSTM(100, 100, bidirectional=True)\n",
      "  (fch): Linear(in_features=200, out_features=100, bias=True)\n",
      "  (fcv): Linear(in_features=100, out_features=100, bias=True)\n",
      "  (fcw): Linear(in_features=200, out_features=1, bias=True)\n",
      "  (fcwp): Linear(in_features=200, out_features=50, bias=True)\n",
      "  (fcwh): Linear(in_features=200, out_features=50, bias=True)\n",
      "  (fc1): Linear(in_features=3750, out_features=120, bias=True)\n",
      "  (fc2): Linear(in_features=120, out_features=50, bias=True)\n",
      "  (fc3): Linear(in_features=50, out_features=4, bias=True)\n",
      "  (embeddings): Embedding(19791, 100)\n",
      ")\n",
      "[1,   200] loss: 0.366\n",
      "[1,   400] loss: 0.278\n",
      "[1,   600] loss: 0.289\n",
      "[1,   800] loss: 0.320\n",
      "[1,  1000] loss: 0.265\n",
      "[1,  1200] loss: 0.254\n",
      "[1,  1400] loss: 0.336\n",
      "[1,  1600] loss: 0.356\n",
      "[1,  1800] loss: 0.299\n",
      "[1,  2000] loss: 0.313\n",
      "-------------cur max is ::::----------97.0\n",
      "result of epoch 0accuracy is : 97 %\n",
      "[2,   200] loss: 0.320\n",
      "[2,   400] loss: 0.286\n",
      "[2,   600] loss: 0.323\n",
      "[2,   800] loss: 0.298\n",
      "[2,  1000] loss: 0.254\n",
      "[2,  1200] loss: 0.243\n",
      "[2,  1400] loss: 0.331\n",
      "[2,  1600] loss: 0.320\n",
      "[2,  1800] loss: 0.286\n",
      "[2,  2000] loss: 0.268\n",
      "result of epoch 1accuracy is : 97 %\n",
      "[3,   200] loss: 0.294\n",
      "[3,   400] loss: 0.194\n",
      "[3,   600] loss: 0.264\n",
      "[3,   800] loss: 0.243\n",
      "[3,  1000] loss: 0.243\n",
      "[3,  1200] loss: 0.224\n",
      "[3,  1400] loss: 0.163\n",
      "[3,  1600] loss: 0.164\n",
      "[3,  1800] loss: 0.126\n",
      "[3,  2000] loss: 0.185\n",
      "result of epoch 2accuracy is : 97 %\n",
      "[4,   200] loss: 0.118\n",
      "[4,   400] loss: 0.139\n",
      "[4,   600] loss: 0.127\n",
      "[4,   800] loss: 0.132\n",
      "[4,  1000] loss: 0.114\n",
      "[4,  1200] loss: 0.103\n",
      "[4,  1400] loss: 0.131\n",
      "[4,  1600] loss: 0.114\n",
      "[4,  1800] loss: 0.091\n",
      "[4,  2000] loss: 0.131\n",
      "result of epoch 3accuracy is : 97 %\n",
      "[5,   200] loss: 0.105\n",
      "[5,   400] loss: 0.092\n",
      "[5,   600] loss: 0.089\n",
      "[5,   800] loss: 0.088\n",
      "[5,  1000] loss: 0.074\n",
      "[5,  1200] loss: 0.096\n",
      "[5,  1400] loss: 0.127\n",
      "[5,  1600] loss: 0.111\n",
      "[5,  1800] loss: 0.088\n",
      "[5,  2000] loss: 0.097\n",
      "result of epoch 4accuracy is : 97 %\n",
      "[6,   200] loss: 0.077\n",
      "[6,   400] loss: 0.099\n",
      "[6,   600] loss: 0.086\n",
      "[6,   800] loss: 0.107\n",
      "[6,  1000] loss: 0.066\n",
      "[6,  1200] loss: 0.089\n",
      "[6,  1400] loss: 0.074\n",
      "[6,  1600] loss: 0.070\n",
      "[6,  1800] loss: 0.070\n",
      "[6,  2000] loss: 0.088\n",
      "result of epoch 5accuracy is : 96 %\n",
      "[7,   200] loss: 0.085\n",
      "[7,   400] loss: 0.076\n",
      "[7,   600] loss: 0.060\n",
      "[7,   800] loss: 0.096\n",
      "[7,  1000] loss: 0.066\n",
      "[7,  1200] loss: 0.072\n",
      "[7,  1400] loss: 0.062\n",
      "[7,  1600] loss: 0.064\n",
      "[7,  1800] loss: 0.067\n",
      "[7,  2000] loss: 0.081\n",
      "result of epoch 6accuracy is : 97 %\n",
      "[8,   200] loss: 0.055\n",
      "[8,   400] loss: 0.076\n",
      "[8,   600] loss: 0.059\n",
      "[8,   800] loss: 0.058\n",
      "[8,  1000] loss: 0.073\n",
      "[8,  1200] loss: 0.068\n",
      "[8,  1400] loss: 0.075\n",
      "[8,  1600] loss: 0.061\n",
      "[8,  1800] loss: 0.046\n",
      "[8,  2000] loss: 0.061\n",
      "result of epoch 7accuracy is : 97 %\n",
      "[9,   200] loss: 0.046\n",
      "[9,   400] loss: 0.046\n",
      "[9,   600] loss: 0.057\n",
      "[9,   800] loss: 0.057\n",
      "[9,  1000] loss: 0.068\n",
      "[9,  1200] loss: 0.049\n",
      "[9,  1400] loss: 0.060\n",
      "[9,  1600] loss: 0.058\n",
      "[9,  1800] loss: 0.068\n",
      "[9,  2000] loss: 0.052\n",
      "result of epoch 8accuracy is : 97 %\n",
      "[10,   200] loss: 0.057\n",
      "[10,   400] loss: 0.058\n",
      "[10,   600] loss: 0.056\n",
      "[10,   800] loss: 0.038\n",
      "[10,  1000] loss: 0.038\n",
      "[10,  1200] loss: 0.051\n",
      "[10,  1400] loss: 0.049\n",
      "[10,  1600] loss: 0.053\n",
      "[10,  1800] loss: 0.038\n",
      "[10,  2000] loss: 0.041\n",
      "result of epoch 9accuracy is : 97 %\n",
      "[11,   200] loss: 0.036\n",
      "[11,   400] loss: 0.050\n",
      "[11,   600] loss: 0.028\n",
      "[11,   800] loss: 0.047\n",
      "[11,  1000] loss: 0.040\n",
      "[11,  1200] loss: 0.049\n",
      "[11,  1400] loss: 0.036\n",
      "[11,  1600] loss: 0.060\n",
      "[11,  1800] loss: 0.052\n",
      "[11,  2000] loss: 0.045\n",
      "result of epoch 10accuracy is : 97 %\n",
      "[12,   200] loss: 0.036\n",
      "[12,   400] loss: 0.030\n",
      "[12,   600] loss: 0.033\n",
      "[12,   800] loss: 0.033\n",
      "[12,  1000] loss: 0.031\n",
      "[12,  1200] loss: 0.047\n",
      "[12,  1400] loss: 0.030\n",
      "[12,  1600] loss: 0.042\n",
      "[12,  1800] loss: 0.047\n",
      "[12,  2000] loss: 0.054\n",
      "result of epoch 11accuracy is : 97 %\n",
      "[13,   200] loss: 0.025\n",
      "[13,   400] loss: 0.041\n",
      "[13,   600] loss: 0.033\n",
      "[13,   800] loss: 0.031\n",
      "[13,  1000] loss: 0.033\n",
      "[13,  1200] loss: 0.019\n",
      "[13,  1400] loss: 0.032\n",
      "[13,  1600] loss: 0.039\n",
      "[13,  1800] loss: 0.040\n",
      "[13,  2000] loss: 0.029\n",
      "result of epoch 12accuracy is : 97 %\n",
      "[14,   200] loss: 0.030\n",
      "[14,   400] loss: 0.027\n",
      "[14,   600] loss: 0.029\n",
      "[14,   800] loss: 0.028\n",
      "[14,  1000] loss: 0.022\n",
      "[14,  1200] loss: 0.042\n",
      "[14,  1400] loss: 0.026\n",
      "[14,  1600] loss: 0.033\n",
      "[14,  1800] loss: 0.037\n",
      "[14,  2000] loss: 0.032\n",
      "result of epoch 13accuracy is : 97 %\n",
      "[15,   200] loss: 0.018\n",
      "[15,   400] loss: 0.021\n",
      "[15,   600] loss: 0.028\n",
      "[15,   800] loss: 0.037\n",
      "[15,  1000] loss: 0.016\n",
      "[15,  1200] loss: 0.043\n",
      "[15,  1400] loss: 0.025\n",
      "[15,  1600] loss: 0.024\n",
      "[15,  1800] loss: 0.026\n",
      "[15,  2000] loss: 0.024\n",
      "result of epoch 14accuracy is : 97 %\n",
      "[16,   200] loss: 0.020\n",
      "[16,   400] loss: 0.025\n",
      "[16,   600] loss: 0.015\n",
      "[16,   800] loss: 0.026\n",
      "[16,  1000] loss: 0.016\n",
      "[16,  1200] loss: 0.032\n",
      "[16,  1400] loss: 0.019\n",
      "[16,  1600] loss: 0.024\n",
      "[16,  1800] loss: 0.026\n",
      "[16,  2000] loss: 0.023\n",
      "result of epoch 15accuracy is : 97 %\n",
      "[17,   200] loss: 0.012\n",
      "[17,   400] loss: 0.016\n",
      "[17,   600] loss: 0.036\n",
      "[17,   800] loss: 0.020\n",
      "[17,  1000] loss: 0.017\n",
      "[17,  1200] loss: 0.014\n",
      "[17,  1400] loss: 0.024\n",
      "[17,  1600] loss: 0.018\n",
      "[17,  1800] loss: 0.022\n",
      "[17,  2000] loss: 0.014\n",
      "-------------cur max is ::::----------98.0\n",
      "result of epoch 16accuracy is : 98 %\n",
      "[18,   200] loss: 0.017\n",
      "[18,   400] loss: 0.019\n",
      "[18,   600] loss: 0.019\n",
      "[18,   800] loss: 0.022\n",
      "[18,  1000] loss: 0.015\n",
      "[18,  1200] loss: 0.024\n",
      "[18,  1400] loss: 0.031\n",
      "[18,  1600] loss: 0.014\n",
      "[18,  1800] loss: 0.011\n",
      "[18,  2000] loss: 0.015\n",
      "result of epoch 17accuracy is : 98 %\n",
      "[19,   200] loss: 0.019\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[19,   400] loss: 0.025\n",
      "[19,   600] loss: 0.015\n",
      "[19,   800] loss: 0.015\n",
      "[19,  1000] loss: 0.012\n",
      "[19,  1200] loss: 0.019\n",
      "[19,  1400] loss: 0.010\n",
      "[19,  1600] loss: 0.015\n",
      "[19,  1800] loss: 0.012\n",
      "[19,  2000] loss: 0.018\n",
      "result of epoch 18accuracy is : 98 %\n",
      "[20,   200] loss: 0.011\n",
      "[20,   400] loss: 0.014\n",
      "[20,   600] loss: 0.012\n",
      "[20,   800] loss: 0.021\n",
      "[20,  1000] loss: 0.010\n",
      "[20,  1200] loss: 0.024\n",
      "[20,  1400] loss: 0.012\n",
      "[20,  1600] loss: 0.008\n",
      "[20,  1800] loss: 0.015\n",
      "[20,  2000] loss: 0.014\n",
      "result of epoch 19accuracy is : 97 %\n",
      "key内饰\n",
      "Finished Training\n",
      "Net(\n",
      "  (bilstm): LSTM(100, 100, bidirectional=True)\n",
      "  (fch): Linear(in_features=200, out_features=100, bias=True)\n",
      "  (fcv): Linear(in_features=100, out_features=100, bias=True)\n",
      "  (fcw): Linear(in_features=200, out_features=1, bias=True)\n",
      "  (fcwp): Linear(in_features=200, out_features=50, bias=True)\n",
      "  (fcwh): Linear(in_features=200, out_features=50, bias=True)\n",
      "  (fc1): Linear(in_features=3750, out_features=120, bias=True)\n",
      "  (fc2): Linear(in_features=120, out_features=50, bias=True)\n",
      "  (fc3): Linear(in_features=50, out_features=4, bias=True)\n",
      "  (embeddings): Embedding(19791, 100)\n",
      ")\n",
      "[1,   200] loss: 0.348\n",
      "[1,   400] loss: 0.312\n",
      "[1,   600] loss: 0.328\n",
      "[1,   800] loss: 0.306\n",
      "[1,  1000] loss: 0.321\n",
      "[1,  1200] loss: 0.325\n",
      "[1,  1400] loss: 0.237\n",
      "[1,  1600] loss: 0.366\n",
      "[1,  1800] loss: 0.307\n",
      "[1,  2000] loss: 0.298\n",
      "-------------cur max is ::::----------90.0\n",
      "result of epoch 0accuracy is : 90 %\n",
      "[2,   200] loss: 0.253\n",
      "[2,   400] loss: 0.333\n",
      "[2,   600] loss: 0.295\n",
      "[2,   800] loss: 0.246\n",
      "[2,  1000] loss: 0.245\n",
      "[2,  1200] loss: 0.234\n",
      "[2,  1400] loss: 0.195\n",
      "[2,  1600] loss: 0.187\n",
      "[2,  1800] loss: 0.209\n",
      "[2,  2000] loss: 0.192\n",
      "result of epoch 1accuracy is : 90 %\n",
      "[3,   200] loss: 0.164\n",
      "[3,   400] loss: 0.151\n",
      "[3,   600] loss: 0.126\n",
      "[3,   800] loss: 0.156\n",
      "[3,  1000] loss: 0.178\n",
      "[3,  1200] loss: 0.165\n",
      "[3,  1400] loss: 0.161\n",
      "[3,  1600] loss: 0.123\n",
      "[3,  1800] loss: 0.133\n",
      "[3,  2000] loss: 0.121\n",
      "-------------cur max is ::::----------91.0\n",
      "result of epoch 2accuracy is : 91 %\n",
      "[4,   200] loss: 0.120\n",
      "[4,   400] loss: 0.107\n",
      "[4,   600] loss: 0.122\n",
      "[4,   800] loss: 0.137\n",
      "[4,  1000] loss: 0.101\n",
      "[4,  1200] loss: 0.101\n",
      "[4,  1400] loss: 0.119\n",
      "[4,  1600] loss: 0.096\n",
      "[4,  1800] loss: 0.110\n",
      "[4,  2000] loss: 0.126\n",
      "result of epoch 3accuracy is : 90 %\n",
      "[5,   200] loss: 0.105\n",
      "[5,   400] loss: 0.068\n",
      "[5,   600] loss: 0.100\n",
      "[5,   800] loss: 0.114\n",
      "[5,  1000] loss: 0.090\n",
      "[5,  1200] loss: 0.102\n",
      "[5,  1400] loss: 0.098\n",
      "[5,  1600] loss: 0.085\n",
      "[5,  1800] loss: 0.088\n",
      "[5,  2000] loss: 0.106\n",
      "result of epoch 4accuracy is : 91 %\n",
      "[6,   200] loss: 0.090\n",
      "[6,   400] loss: 0.101\n",
      "[6,   600] loss: 0.082\n",
      "[6,   800] loss: 0.078\n",
      "[6,  1000] loss: 0.079\n",
      "[6,  1200] loss: 0.081\n",
      "[6,  1400] loss: 0.098\n",
      "[6,  1600] loss: 0.068\n",
      "[6,  1800] loss: 0.080\n",
      "[6,  2000] loss: 0.086\n",
      "result of epoch 5accuracy is : 89 %\n",
      "[7,   200] loss: 0.105\n",
      "[7,   400] loss: 0.070\n",
      "[7,   600] loss: 0.057\n",
      "[7,   800] loss: 0.081\n",
      "[9,  1400] loss: 0.054\n",
      "[9,  1600] loss: 0.033\n",
      "[9,  1800] loss: 0.055\n",
      "[9,  2000] loss: 0.063\n",
      "result of epoch 8accuracy is : 87 %\n",
      "[10,   200] loss: 0.047\n",
      "[10,   400] loss: 0.054\n",
      "[10,   600] loss: 0.058\n",
      "[10,   800] loss: 0.043\n",
      "[10,  1000] loss: 0.059\n",
      "[10,  1200] loss: 0.031\n",
      "[10,  1400] loss: 0.038\n",
      "[10,  1600] loss: 0.036\n",
      "[10,  1800] loss: 0.037\n",
      "[10,  2000] loss: 0.053\n",
      "result of epoch 9accuracy is : 89 %\n",
      "[11,   200] loss: 0.041\n",
      "[11,   400] loss: 0.048\n",
      "[11,   600] loss: 0.047\n",
      "[11,   800] loss: 0.052\n",
      "[11,  1000] loss: 0.030\n",
      "[11,  1200] loss: 0.033\n",
      "[11,  1400] loss: 0.042\n",
      "[11,  1600] loss: 0.034\n",
      "[11,  1800] loss: 0.041\n",
      "[11,  2000] loss: 0.032\n",
      "result of epoch 10accuracy is : 87 %\n",
      "[12,   200] loss: 0.029\n",
      "[12,   400] loss: 0.029\n",
      "[12,   600] loss: 0.038\n",
      "[12,   800] loss: 0.039\n",
      "[12,  1000] loss: 0.042\n",
      "[12,  1200] loss: 0.020\n",
      "[12,  1400] loss: 0.043\n",
      "[12,  1600] loss: 0.024\n",
      "[12,  1800] loss: 0.020\n",
      "[12,  2000] loss: 0.034\n",
      "result of epoch 11accuracy is : 87 %\n",
      "[13,   200] loss: 0.022\n",
      "[13,   400] loss: 0.020\n",
      "[13,   600] loss: 0.036\n",
      "[13,   800] loss: 0.036\n",
      "[13,  1000] loss: 0.033\n",
      "[13,  1200] loss: 0.036\n",
      "[13,  1400] loss: 0.030\n",
      "[13,  1600] loss: 0.028\n",
      "[13,  1800] loss: 0.023\n",
      "[13,  2000] loss: 0.032\n",
      "result of epoch 12accuracy is : 89 %\n",
      "[14,   200] loss: 0.033\n",
      "[14,   400] loss: 0.022\n",
      "[14,   600] loss: 0.027\n",
      "[14,   800] loss: 0.019\n",
      "[14,  1000] loss: 0.028\n",
      "[14,  1200] loss: 0.026\n",
      "[14,  1400] loss: 0.027\n",
      "[14,  1600] loss: 0.029\n",
      "[14,  1800] loss: 0.028\n",
      "[14,  2000] loss: 0.030\n",
      "result of epoch 13accuracy is : 89 %\n",
      "[15,   200] loss: 0.021\n",
      "[15,   400] loss: 0.030\n",
      "[15,   600] loss: 0.024\n",
      "[15,   800] loss: 0.029\n",
      "[15,  1000] loss: 0.026\n",
      "[15,  1200] loss: 0.015\n",
      "[15,  1400] loss: 0.019\n",
      "[15,  1600] loss: 0.030\n",
      "[15,  1800] loss: 0.027\n",
      "[15,  2000] loss: 0.019\n",
      "result of epoch 14accuracy is : 87 %\n",
      "[16,   200] loss: 0.023\n",
      "[16,   400] loss: 0.019\n",
      "[16,   600] loss: 0.018\n",
      "[16,   800] loss: 0.022\n",
      "[16,  1000] loss: 0.016\n",
      "[16,  1200] loss: 0.019\n",
      "[16,  1400] loss: 0.023\n",
      "[16,  1600] loss: 0.028\n",
      "[16,  1800] loss: 0.018\n",
      "[16,  2000] loss: 0.014\n",
      "result of epoch 15accuracy is : 87 %\n",
      "[17,   200] loss: 0.030\n",
      "[17,   400] loss: 0.013\n",
      "[17,   600] loss: 0.014\n",
      "[17,   800] loss: 0.016\n",
      "[17,  1000] loss: 0.022\n",
      "[17,  1200] loss: 0.020\n",
      "[17,  1400] loss: 0.012\n",
      "[17,  1600] loss: 0.026\n",
      "[17,  1800] loss: 0.011\n",
      "[17,  2000] loss: 0.014\n",
      "result of epoch 16accuracy is : 87 %\n",
      "[18,   200] loss: 0.021\n",
      "[18,   400] loss: 0.016\n",
      "[18,   600] loss: 0.011\n",
      "[18,   800] loss: 0.008\n",
      "[18,  1000] loss: 0.017\n",
      "[18,  1200] loss: 0.020\n",
      "[18,  1400] loss: 0.024\n",
      "[18,  1600] loss: 0.018\n",
      "[18,  1800] loss: 0.020\n",
      "[18,  2000] loss: 0.019\n",
      "result of epoch 17accuracy is : 87 %\n",
      "[19,   200] loss: 0.015\n",
      "[19,   400] loss: 0.024\n",
      "[19,   600] loss: 0.014\n",
      "[19,   800] loss: 0.014\n",
      "[19,  1000] loss: 0.016\n",
      "[19,  1200] loss: 0.007\n",
      "[19,  1400] loss: 0.015\n",
      "[19,  1600] loss: 0.021\n",
      "[19,  1800] loss: 0.015\n",
      "[19,  2000] loss: 0.007\n",
      "result of epoch 18accuracy is : 87 %\n",
      "[20,   200] loss: 0.020\n",
      "[20,   400] loss: 0.017\n",
      "[20,   600] loss: 0.014\n",
      "[20,   800] loss: 0.011\n",
      "[20,  1000] loss: 0.012\n",
      "[20,  1200] loss: 0.007\n",
      "[20,  1400] loss: 0.017\n",
      "[20,  1600] loss: 0.019\n",
      "[20,  1800] loss: 0.005\n",
      "[20,  2000] loss: 0.013\n",
      "result of epoch 19accuracy is : 89 %\n",
      "key安全性\n",
      "Finished Training\n",
      "Net(\n",
      "  (bilstm): LSTM(100, 100, bidirectional=True)\n",
      "  (fch): Linear(in_features=200, out_features=100, bias=True)\n",
      "  (fcv): Linear(in_features=100, out_features=100, bias=True)\n",
      "  (fcw): Linear(in_features=200, out_features=1, bias=True)\n",
      "  (fcwp): Linear(in_features=200, out_features=50, bias=True)\n",
      "  (fcwh): Linear(in_features=200, out_features=50, bias=True)\n",
      "  (fc1): Linear(in_features=3750, out_features=120, bias=True)\n",
      "  (fc2): Linear(in_features=120, out_features=50, bias=True)\n",
      "  (fc3): Linear(in_features=50, out_features=4, bias=True)\n",
      "  (embeddings): Embedding(19791, 100)\n",
      ")\n",
      "[1,   200] loss: 0.290\n",
      "[1,   400] loss: 0.237\n",
      "[1,   600] loss: 0.237\n",
      "[1,   800] loss: 0.276\n",
      "[1,  1000] loss: 0.297\n",
      "[1,  1200] loss: 0.254\n",
      "[1,  1400] loss: 0.266\n",
      "[1,  1600] loss: 0.247\n",
      "[1,  1800] loss: 0.229\n",
      "[1,  2000] loss: 0.227\n",
      "-------------cur max is ::::----------92.0\n",
      "result of epoch 0accuracy is : 92 %\n",
      "[2,   200] loss: 0.259\n",
      "[2,   400] loss: 0.210\n",
      "[2,   600] loss: 0.228\n",
      "[2,   800] loss: 0.192\n",
      "[2,  1000] loss: 0.190\n",
      "[2,  1200] loss: 0.146\n",
      "[2,  1400] loss: 0.138\n",
      "[2,  1600] loss: 0.117\n",
      "[2,  1800] loss: 0.137\n",
      "[2,  2000] loss: 0.126\n",
      "-------------cur max is ::::----------95.0\n",
      "result of epoch 1accuracy is : 95 %\n",
      "[3,   200] loss: 0.111\n",
      "[3,   400] loss: 0.104\n",
      "[3,   600] loss: 0.118\n",
      "[3,   800] loss: 0.104\n",
      "[3,  1000] loss: 0.101\n",
      "[3,  1200] loss: 0.117\n",
      "[3,  1400] loss: 0.088\n",
      "[3,  1600] loss: 0.079\n",
      "[3,  1800] loss: 0.086\n",
      "[3,  2000] loss: 0.143\n",
      "result of epoch 2accuracy is : 95 %\n",
      "[4,   200] loss: 0.089\n",
      "[4,   400] loss: 0.104\n",
      "[4,   600] loss: 0.105\n",
      "[4,   800] loss: 0.079\n",
      "[4,  1000] loss: 0.085\n",
      "[4,  1200] loss: 0.095\n",
      "[4,  1400] loss: 0.095\n",
      "[4,  1600] loss: 0.077\n",
      "[4,  1800] loss: 0.084\n",
      "[4,  2000] loss: 0.085\n",
      "-------------cur max is ::::----------97.0\n",
      "result of epoch 3accuracy is : 97 %\n",
      "[5,   200] loss: 0.084\n",
      "[5,   400] loss: 0.090\n",
      "[5,   600] loss: 0.107\n",
      "[5,   800] loss: 0.077\n",
      "[5,  1000] loss: 0.079\n",
      "[5,  1200] loss: 0.084\n",
      "[5,  1400] loss: 0.081\n",
      "[5,  1600] loss: 0.065\n",
      "[5,  1800] loss: 0.078\n",
      "[5,  2000] loss: 0.054\n",
      "result of epoch 4accuracy is : 96 %\n",
      "[6,   200] loss: 0.068\n",
      "[6,   400] loss: 0.075\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[6,   600] loss: 0.070\n",
      "[6,   800] loss: 0.082\n",
      "[6,  1000] loss: 0.060\n",
      "[6,  1200] loss: 0.074\n",
      "[6,  1400] loss: 0.068\n",
      "[6,  1600] loss: 0.052\n",
      "[6,  1800] loss: 0.064\n",
      "[6,  2000] loss: 0.071\n",
      "result of epoch 5accuracy is : 95 %\n",
      "[7,   200] loss: 0.060\n",
      "[7,   400] loss: 0.051\n",
      "[7,   600] loss: 0.072\n",
      "[7,   800] loss: 0.064\n",
      "[7,  1000] loss: 0.049\n",
      "[7,  1200] loss: 0.069\n",
      "[7,  1400] loss: 0.064\n",
      "[7,  1600] loss: 0.058\n",
      "[7,  1800] loss: 0.056\n",
      "[7,  2000] loss: 0.057\n",
      "result of epoch 6accuracy is : 97 %\n",
      "[8,   200] loss: 0.053\n",
      "[8,   400] loss: 0.070\n",
      "[8,   600] loss: 0.061\n",
      "[8,   800] loss: 0.051\n",
      "[8,  1000] loss: 0.052\n",
      "[8,  1200] loss: 0.055\n",
      "[8,  1400] loss: 0.037\n",
      "[8,  1600] loss: 0.047\n",
      "[8,  1800] loss: 0.057\n",
      "[8,  2000] loss: 0.052\n",
      "result of epoch 7accuracy is : 95 %\n",
      "[9,   200] loss: 0.047\n",
      "[9,   400] loss: 0.044\n",
      "[9,   600] loss: 0.043\n",
      "[9,   800] loss: 0.046\n",
      "[9,  1000] loss: 0.047\n",
      "[9,  1200] loss: 0.045\n",
      "[9,  1400] loss: 0.055\n",
      "[9,  1600] loss: 0.045\n",
      "[12,   600] loss: 0.031\n",
      "[12,   800] loss: 0.034\n",
      "[12,  1000] loss: 0.029\n",
      "[12,  1200] loss: 0.023\n",
      "[12,  1400] loss: 0.024\n",
      "[12,  1600] loss: 0.033\n",
      "[12,  1800] loss: 0.029\n",
      "[12,  2000] loss: 0.024\n",
      "result of epoch 11accuracy is : 96 %\n",
      "[13,   200] loss: 0.031\n",
      "[13,   400] loss: 0.024\n",
      "[13,   600] loss: 0.022\n",
      "[13,   800] loss: 0.020\n",
      "[13,  1000] loss: 0.026\n",
      "[13,  1200] loss: 0.038\n",
      "[13,  1400] loss: 0.034\n",
      "[13,  1600] loss: 0.022\n",
      "[13,  1800] loss: 0.025\n",
      "[13,  2000] loss: 0.026\n",
      "result of epoch 12accuracy is : 96 %\n",
      "[14,   200] loss: 0.029\n",
      "[14,   400] loss: 0.023\n",
      "[14,   600] loss: 0.027\n",
      "[14,   800] loss: 0.023\n",
      "[14,  1000] loss: 0.019\n",
      "[14,  1200] loss: 0.019\n",
      "[14,  1400] loss: 0.025\n",
      "[14,  1600] loss: 0.018\n",
      "[14,  1800] loss: 0.017\n",
      "[14,  2000] loss: 0.019\n",
      "result of epoch 13accuracy is : 96 %\n",
      "[15,   200] loss: 0.020\n",
      "[15,   400] loss: 0.023\n",
      "[15,   600] loss: 0.017\n",
      "[15,   800] loss: 0.015\n",
      "[15,  1000] loss: 0.027\n",
      "[15,  1200] loss: 0.013\n",
      "[15,  1400] loss: 0.018\n",
      "[15,  1600] loss: 0.018\n",
      "[15,  1800] loss: 0.014\n",
      "[15,  2000] loss: 0.018\n",
      "result of epoch 14accuracy is : 95 %\n",
      "[16,   200] loss: 0.022\n",
      "[16,   400] loss: 0.020\n",
      "[16,   600] loss: 0.017\n",
      "[16,   800] loss: 0.020\n",
      "[16,  1000] loss: 0.009\n",
      "[16,  1200] loss: 0.014\n",
      "[16,  1400] loss: 0.017\n",
      "[16,  1600] loss: 0.011\n",
      "[16,  1800] loss: 0.014\n",
      "[16,  2000] loss: 0.013\n",
      "result of epoch 15accuracy is : 96 %\n",
      "[17,   200] loss: 0.008\n",
      "[17,   400] loss: 0.015\n",
      "[17,   600] loss: 0.010\n",
      "[17,   800] loss: 0.019\n",
      "[17,  1000] loss: 0.016\n",
      "[17,  1200] loss: 0.014\n",
      "[17,  1400] loss: 0.015\n",
      "[17,  1600] loss: 0.012\n",
      "[17,  1800] loss: 0.023\n",
      "[17,  2000] loss: 0.011\n",
      "result of epoch 16accuracy is : 96 %\n",
      "[18,   200] loss: 0.022\n",
      "[18,   400] loss: 0.016\n",
      "[18,   600] loss: 0.013\n",
      "[18,   800] loss: 0.018\n",
      "[18,  1000] loss: 0.022\n",
      "[18,  1200] loss: 0.007\n",
      "[18,  1400] loss: 0.013\n",
      "[18,  1600] loss: 0.010\n",
      "[18,  1800] loss: 0.013\n",
      "[18,  2000] loss: 0.010\n",
      "result of epoch 17accuracy is : 96 %\n",
      "[19,   200] loss: 0.008\n",
      "[19,   400] loss: 0.007\n",
      "[19,   600] loss: 0.016\n",
      "[19,   800] loss: 0.015\n",
      "[19,  1000] loss: 0.012\n",
      "[19,  1200] loss: 0.012\n",
      "[19,  1400] loss: 0.010\n",
      "[19,  1600] loss: 0.014\n",
      "[19,  1800] loss: 0.007\n",
      "[19,  2000] loss: 0.011\n",
      "result of epoch 18accuracy is : 96 %\n",
      "[20,   200] loss: 0.009\n",
      "[20,   400] loss: 0.012\n",
      "[20,   600] loss: 0.006\n",
      "[20,   800] loss: 0.007\n",
      "[20,  1000] loss: 0.007\n",
      "[20,  1200] loss: 0.009\n",
      "[20,  1400] loss: 0.015\n",
      "[20,  1600] loss: 0.009\n",
      "[20,  1800] loss: 0.009\n",
      "[20,  2000] loss: 0.013\n",
      "result of epoch 19accuracy is : 96 %\n",
      "key空间\n",
      "Finished Training\n",
      "Net(\n",
      "  (bilstm): LSTM(100, 100, bidirectional=True)\n",
      "  (fch): Linear(in_features=200, out_features=100, bias=True)\n",
      "  (fcv): Linear(in_features=100, out_features=100, bias=True)\n",
      "  (fcw): Linear(in_features=200, out_features=1, bias=True)\n",
      "  (fcwp): Linear(in_features=200, out_features=50, bias=True)\n",
      "  (fcwh): Linear(in_features=200, out_features=50, bias=True)\n",
      "  (fc1): Linear(in_features=3750, out_features=120, bias=True)\n",
      "  (fc2): Linear(in_features=120, out_features=50, bias=True)\n",
      "  (fc3): Linear(in_features=50, out_features=4, bias=True)\n",
      "  (embeddings): Embedding(19791, 100)\n",
      ")\n",
      "[1,   200] loss: 0.241\n",
      "[1,   400] loss: 0.303\n",
      "[1,   600] loss: 0.281\n",
      "[1,   800] loss: 0.295\n",
      "[1,  1000] loss: 0.284\n",
      "[1,  1200] loss: 0.323\n",
      "[1,  1400] loss: 0.321\n",
      "[1,  1600] loss: 0.270\n",
      "[1,  1800] loss: 0.225\n",
      "[1,  2000] loss: 0.310\n",
      "-------------cur max is ::::----------92.0\n",
      "result of epoch 0accuracy is : 92 %\n",
      "[2,   200] loss: 0.300\n",
      "[2,   400] loss: 0.269\n",
      "[2,   600] loss: 0.264\n",
      "[2,   800] loss: 0.275\n",
      "[2,  1000] loss: 0.224\n",
      "[2,  1200] loss: 0.274\n",
      "[2,  1400] loss: 0.213\n",
      "[2,  1600] loss: 0.316\n",
      "[2,  1800] loss: 0.260\n",
      "[2,  2000] loss: 0.266\n",
      "result of epoch 1accuracy is : 92 %\n",
      "[3,   200] loss: 0.223\n",
      "[3,   400] loss: 0.286\n",
      "[3,   600] loss: 0.195\n",
      "[3,   800] loss: 0.175\n",
      "[3,  1000] loss: 0.219\n",
      "[3,  1200] loss: 0.128\n",
      "[3,  1400] loss: 0.155\n",
      "[3,  1600] loss: 0.127\n",
      "[3,  1800] loss: 0.155\n",
      "[3,  2000] loss: 0.125\n",
      "-------------cur max is ::::----------95.0\n",
      "result of epoch 2accuracy is : 95 %\n",
      "[4,   200] loss: 0.137\n",
      "[4,   400] loss: 0.120\n",
      "[4,   600] loss: 0.082\n",
      "[4,   800] loss: 0.101\n",
      "[4,  1000] loss: 0.119\n",
      "[4,  1200] loss: 0.107\n",
      "[4,  1400] loss: 0.103\n",
      "[4,  1600] loss: 0.078\n",
      "[4,  1800] loss: 0.070\n",
      "[4,  2000] loss: 0.133\n",
      "result of epoch 3accuracy is : 95 %\n",
      "[5,   200] loss: 0.086\n",
      "[5,   400] loss: 0.106\n",
      "[5,   600] loss: 0.079\n",
      "[5,   800] loss: 0.058\n",
      "[5,  1000] loss: 0.093\n",
      "[5,  1200] loss: 0.098\n",
      "[5,  1400] loss: 0.095\n",
      "[5,  1600] loss: 0.085\n",
      "[5,  1800] loss: 0.095\n",
      "[5,  2000] loss: 0.068\n",
      "result of epoch 4accuracy is : 95 %\n",
      "[6,   200] loss: 0.058\n",
      "[6,   400] loss: 0.073\n",
      "[6,   600] loss: 0.077\n",
      "[6,   800] loss: 0.073\n",
      "[6,  1000] loss: 0.090\n",
      "[6,  1200] loss: 0.075\n",
      "[6,  1400] loss: 0.063\n",
      "[6,  1600] loss: 0.083\n",
      "[6,  1800] loss: 0.101\n",
      "[6,  2000] loss: 0.075\n",
      "result of epoch 5accuracy is : 95 %\n",
      "[7,   200] loss: 0.079\n",
      "[7,   400] loss: 0.064\n",
      "[7,   600] loss: 0.065\n",
      "[7,   800] loss: 0.090\n",
      "[7,  1000] loss: 0.064\n",
      "[7,  1200] loss: 0.067\n",
      "[7,  1400] loss: 0.068\n",
      "[7,  1600] loss: 0.071\n",
      "[7,  1800] loss: 0.059\n",
      "[7,  2000] loss: 0.062\n",
      "result of epoch 6accuracy is : 95 %\n",
      "[8,   200] loss: 0.061\n",
      "[8,   400] loss: 0.053\n",
      "[8,   600] loss: 0.071\n",
      "[8,   800] loss: 0.057\n",
      "[8,  1000] loss: 0.088\n",
      "[8,  1200] loss: 0.072\n",
      "[8,  1400] loss: 0.053\n",
      "[8,  1600] loss: 0.051\n",
      "[8,  1800] loss: 0.065\n",
      "[8,  2000] loss: 0.080\n",
      "-------------cur max is ::::----------96.0\n",
      "result of epoch 7accuracy is : 96 %\n",
      "[9,   200] loss: 0.072\n",
      "[9,   400] loss: 0.072\n",
      "[9,   600] loss: 0.084\n",
      "[9,   800] loss: 0.064\n",
      "[9,  1000] loss: 0.051\n",
      "[9,  1200] loss: 0.065\n",
      "[9,  1400] loss: 0.060\n",
      "[9,  1600] loss: 0.046\n",
      "[9,  1800] loss: 0.057\n",
      "[9,  2000] loss: 0.050\n",
      "result of epoch 8accuracy is : 96 %\n",
      "[10,   200] loss: 0.061\n",
      "[10,   400] loss: 0.052\n",
      "[10,   600] loss: 0.059\n",
      "[10,   800] loss: 0.047\n",
      "[10,  1000] loss: 0.055\n",
      "[10,  1200] loss: 0.059\n",
      "[10,  1400] loss: 0.050\n",
      "[10,  1600] loss: 0.068\n",
      "[10,  1800] loss: 0.069\n",
      "[10,  2000] loss: 0.063\n",
      "result of epoch 9accuracy is : 96 %\n",
      "[11,   200] loss: 0.056\n",
      "[11,   400] loss: 0.063\n",
      "[11,   600] loss: 0.054\n",
      "[11,   800] loss: 0.060\n",
      "[11,  1000] loss: 0.065\n",
      "[11,  1200] loss: 0.039\n",
      "[11,  1400] loss: 0.048\n",
      "[11,  1600] loss: 0.053\n",
      "[11,  1800] loss: 0.053\n",
      "[11,  2000] loss: 0.058\n",
      "result of epoch 10accuracy is : 96 %\n",
      "[12,   200] loss: 0.048\n",
      "[12,   400] loss: 0.057\n",
      "[12,   600] loss: 0.043\n",
      "[12,   800] loss: 0.038\n",
      "[12,  1000] loss: 0.059\n",
      "[12,  1200] loss: 0.050\n",
      "[12,  1400] loss: 0.058\n",
      "[12,  1600] loss: 0.047\n",
      "[12,  1800] loss: 0.049\n",
      "[12,  2000] loss: 0.056\n",
      "result of epoch 11accuracy is : 96 %\n",
      "[13,   200] loss: 0.053\n",
      "[13,   400] loss: 0.034\n",
      "[13,   600] loss: 0.046\n",
      "[13,   800] loss: 0.054\n",
      "[13,  1000] loss: 0.047\n",
      "[13,  1200] loss: 0.034\n",
      "[13,  1400] loss: 0.050\n",
      "[13,  1600] loss: 0.054\n",
      "[13,  1800] loss: 0.051\n",
      "[13,  2000] loss: 0.049\n",
      "-------------cur max is ::::----------97.0\n",
      "result of epoch 12accuracy is : 97 %\n",
      "[14,   200] loss: 0.049\n",
      "[14,   400] loss: 0.053\n",
      "[14,   600] loss: 0.042\n",
      "[14,   800] loss: 0.041\n",
      "[14,  1000] loss: 0.049\n",
      "[14,  1200] loss: 0.031\n",
      "[14,  1400] loss: 0.037\n",
      "[14,  1600] loss: 0.053\n",
      "[14,  1800] loss: 0.046\n",
      "[14,  2000] loss: 0.035\n",
      "result of epoch 13accuracy is : 96 %\n",
      "[15,   200] loss: 0.030\n",
      "[15,   400] loss: 0.028\n",
      "[15,   600] loss: 0.042\n",
      "[15,   800] loss: 0.037\n",
      "[15,  1000] loss: 0.032\n",
      "[15,  1200] loss: 0.035\n",
      "[15,  1400] loss: 0.036\n",
      "[15,  1600] loss: 0.028\n",
      "[15,  1800] loss: 0.038\n",
      "[15,  2000] loss: 0.041\n",
      "result of epoch 14accuracy is : 96 %\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[16,   200] loss: 0.040\n",
      "[16,   400] loss: 0.031\n",
      "[16,   600] loss: 0.023\n",
      "[16,   800] loss: 0.037\n",
      "[16,  1000] loss: 0.025\n",
      "[16,  1200] loss: 0.039\n",
      "[16,  1400] loss: 0.020\n",
      "[16,  1600] loss: 0.029\n",
      "[16,  1800] loss: 0.030\n",
      "[16,  2000] loss: 0.021\n",
      "result of epoch 15accuracy is : 96 %\n",
      "[17,   200] loss: 0.025\n",
      "[17,   400] loss: 0.027\n",
      "[17,   600] loss: 0.026\n",
      "[17,   800] loss: 0.033\n",
      "[17,  1000] loss: 0.026\n",
      "[17,  1200] loss: 0.023\n",
      "[17,  1400] loss: 0.016\n",
      "[17,  1600] loss: 0.016\n",
      "[17,  1800] loss: 0.019\n",
      "[17,  2000] loss: 0.023\n",
      "result of epoch 16accuracy is : 95 %\n",
      "[18,   200] loss: 0.018\n",
      "[18,   400] loss: 0.011\n",
      "[18,   600] loss: 0.022\n",
      "[18,   800] loss: 0.017\n",
      "[18,  1000] loss: 0.017\n",
      "[18,  1200] loss: 0.024\n",
      "[18,  1400] loss: 0.021\n",
      "[18,  1600] loss: 0.019\n",
      "[18,  1800] loss: 0.016\n",
      "[18,  2000] loss: 0.027\n",
      "result of epoch 17accuracy is : 96 %\n",
      "[19,   200] loss: 0.012\n",
      "[19,   400] loss: 0.023\n",
      "[19,   600] loss: 0.024\n",
      "[19,   800] loss: 0.019\n",
      "[19,  1000] loss: 0.012\n",
      "[19,  1200] loss: 0.009\n",
      "[19,  1400] loss: 0.015\n",
      "[19,  1600] loss: 0.017\n",
      "[19,  1800] loss: 0.019\n",
      "[19,  2000] loss: 0.019\n",
      "result of epoch 18accuracy is : 96 %\n",
      "[20,   200] loss: 0.018\n",
      "[20,   400] loss: 0.013\n",
      "[20,   600] loss: 0.011\n",
      "[20,   800] loss: 0.012\n",
      "[20,  1000] loss: 0.013\n",
      "[20,  1200] loss: 0.012\n",
      "[20,  1400] loss: 0.020\n",
      "[20,  1600] loss: 0.015\n",
      "[20,  1800] loss: 0.015\n",
      "[20,  2000] loss: 0.017\n",
      "result of epoch 19accuracy is : 96 %\n",
      "key外观\n",
      "Finished Training\n"
     ]
    }
   ],
   "source": [
    "ii = 0\n",
    "import time\n",
    "for key in sub_set:\n",
    "    if ii == 10:\n",
    "        break\n",
    "    ii += 1\n",
    "    net = Net(pretrained, len(pretrained))\n",
    "    cur_max_acc = 0.0\n",
    "    print(net)\n",
    "    from torch import optim\n",
    "    criterion = nn.CrossEntropyLoss() # 交叉熵损失函数\n",
    "    optimizer = optim.Adagrad(net.parameters(), lr=0.01)#, momentum=0.9)\n",
    "    train_x, test_x, train_y, test_y = train_test_split(han_x, sub_set[key], test_size=0.01, random_state=42)\n",
    "    trainset = [(train_x[i], train_y[i]) for i in range(len(train_x))]\n",
    "    testset = [(test_x[i], test_y[i]) for i in range(len(test_x))]\n",
    "    trainloader = torch.utils.data.DataLoader(\n",
    "                        trainset, \n",
    "                        batch_size=4,\n",
    "                        shuffle=True, \n",
    "                        num_workers=2)\n",
    "    testloader = torch.utils.data.DataLoader(\n",
    "                        testset, \n",
    "                        batch_size=4,\n",
    "                        shuffle=False, \n",
    "                        num_workers=2)\n",
    "    torch.set_num_threads(8)\n",
    "    for epoch in range(20):  \n",
    "\n",
    "        running_loss = 0.0\n",
    "        for i, data in enumerate(trainloader, 0):\n",
    "\n",
    "            # 输入数据\n",
    "            inputs, labels = data\n",
    "            # 梯度清零\n",
    "            optimizer.zero_grad()\n",
    "            # forward + backward \n",
    "            va = [[word2ind[key]]]\n",
    "            va = torch.from_numpy(np.array(va))\n",
    "            outputs = net(inputs, va)\n",
    "            loss = criterion(outputs, labels)\n",
    "            loss.backward()   \n",
    "\n",
    "            # 更新参数 \n",
    "            optimizer.step()\n",
    "\n",
    "            # 打印log信息\n",
    "            # loss 是一个scalar,需要使用loss.item()来获取数值，不能使用loss[0]\n",
    "            running_loss += loss.item()\n",
    "            if i % 200 == 199: # 每200个batch打印一下训练状态\n",
    "                print('[%d, %5d] loss: %.3f' \\\n",
    "                      % (epoch+1, i+1, running_loss / 200))\n",
    "                running_loss = 0.0\n",
    "                \n",
    "        with torch.no_grad():\n",
    "            correct, total = 0, 0\n",
    "            for data in testloader:\n",
    "                images, labels = data\n",
    "                va = [[word2ind[key]]]\n",
    "                va = torch.from_numpy(np.array(va))\n",
    "                outputs = net(images,va)\n",
    "                _, predicted = torch.max(outputs, 1)\n",
    "                #import ipdb;ipdb.set_trace()\n",
    "                #res = res + [map_[int(predicted[i])] for i in range(len(predicted))]\n",
    "                total += labels.size(0)\n",
    "                correct += (predicted == labels).sum()\n",
    "            if cur_max_acc < float(100 * correct / total):\n",
    "                print('-------------cur max is ::::----------'+str(float(100 * correct / total)))\n",
    "                cur_max_acc = float(100 * correct / total)\n",
    "                torch.save(net, 'net++' + key + '.pkl')  # 保存整个网络\n",
    "            print('result of epoch ' + str(epoch) + 'accuracy is : %d %%' % (100 * correct / total))\n",
    "\n",
    "    print('key' + key)\n",
    "    #net2 = torch.load('net.pkl')\n",
    "    #prediction = net2(x)\n",
    "    print('Finished Training')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "价格\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/works/dl-tools/anaconda2/envs/yxvenv/lib/python3.6/site-packages/ipykernel/__main__.py:73: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "配置\n",
      "操控\n",
      "舒适性\n",
      "油耗\n",
      "动力\n",
      "内饰\n",
      "安全性\n",
      "空间\n",
      "外观\n"
     ]
    }
   ],
   "source": [
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "result_set = {}\n",
    "testset = han_x_test\n",
    "testloader = torch.utils.data.DataLoader(\n",
    "                    testset, \n",
    "                    batch_size=4,\n",
    "                    shuffle=False, \n",
    "                    num_workers=2)\n",
    "for key in sub_set:\n",
    "    print(key)\n",
    "    res = []\n",
    "    with torch.no_grad():\n",
    "        correct, total = 0, 0\n",
    "        for data in testloader:\n",
    "            images = data\n",
    "            va = [[word2ind[key]]]\n",
    "            va = torch.from_numpy(np.array(va))\n",
    "            net = torch.load('net++' + key + '.pkl')\n",
    "            outputs = net(images,va)\n",
    "            _, predicted = torch.max(outputs, 1)\n",
    "            res = res + [map_[int(predicted[i])] for i in range(len(predicted))]\n",
    "    result_set[key] = res\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "价格1273\n",
      "1014\n",
      "145\n",
      "114\n",
      "配置853\n",
      "579\n",
      "154\n",
      "120\n",
      "操控1036\n",
      "606\n",
      "124\n",
      "306\n",
      "舒适性931\n",
      "564\n",
      "256\n",
      "111\n",
      "油耗1082\n",
      "793\n",
      "138\n",
      "151\n",
      "动力2732\n",
      "1970\n",
      "378\n",
      "384\n",
      "内饰536\n",
      "271\n",
      "150\n",
      "115\n",
      "安全性573\n",
      "380\n",
      "93\n",
      "100\n",
      "空间442\n",
      "221\n",
      "67\n",
      "154\n",
      "外观489\n",
      "263\n",
      "111\n",
      "115\n"
     ]
    }
   ],
   "source": [
    "data = pd.read_csv('../../data/df_sen_sub/train.csv')\n",
    "uni_sub = data['subject'].unique()\n",
    "for key in uni_sub:\n",
    "    print(key + str(len(data[data['subject'] == key])))\n",
    "    ttt = data[data['subject'] == key]\n",
    "    print(len(ttt[ttt['sentiment_value'] == 0]))\n",
    "    print(len(ttt[ttt['sentiment_value'] == -1]))\n",
    "    print(len(ttt[ttt['sentiment_value'] == 1]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "real_pred = {}\n",
    "content_ids = []\n",
    "subjects = []\n",
    "sentiment_values = []\n",
    "sentiment_words = []\n",
    "contents = []\n",
    "#content_id,subject,sentiment_value,sentiment_word\n",
    "for i in range(len(test_data)):\n",
    "    content_id = test_data.loc[i, 'content_id']\n",
    "    flag = 0\n",
    "    for key in result_set:\n",
    "        if result_set[key][i] != '2':\n",
    "            flag = 1\n",
    "            content_ids.append(str(content_id))\n",
    "            subjects.append(key)\n",
    "            sentiment_values.append(int(result_set[key][i]))\n",
    "            sentiment_words.append(\"\")\n",
    "            contents.append(str(test_data.loc[i, 'content']))\n",
    "    if flag == 0:\n",
    "        content_ids.append(str(content_id))\n",
    "        subjects.append('动力')\n",
    "        sentiment_values.append(0)\n",
    "        sentiment_words.append(\"\")   \n",
    "        contents.append(str(test_data.loc[i, 'content']))\n",
    "real_pred = {\"content_id\":content_ids, \"subject\":subjects, \"sentiment_value\":sentiment_values, \"sentiment_word\":sentiment_words}\n",
    "real_df = pd.DataFrame(real_pred)\n",
    "real_df.to_csv('final_result++.csv', encoding = \"utf-8\", index = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(2628, 2364)"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(real_df), len(test_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "real_pred['content'] = contents\n",
    "\n",
    "dtt = pd.DataFrame(real_pred)\n",
    "dtt.to_csv('see_final_result++.csv', encoding = \"utf-8\", index = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "36"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(dtt[dtt['sentiment_value'] == -1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:yxvenv]",
   "language": "python",
   "name": "conda-env-yxvenv-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
